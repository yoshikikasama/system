# CloudLicence

## 01.

- Apache Hive メタストア　 → 　 AWS Glue Data Catalog に移行できる。

- AWS Lambda と RDS のプライベート通信:

  - Lambda 関数にも RDS にも同じ SG を設定し、SG の設定で同じセキュリティグループからの通信を許可する。
  - Lambda 関数と RDS はどちらも同じ MySecurityGroup に所属しているため、この自己参照ルールにより、セキュリティグループに属するリソース間で安全に通信できるようになります。
  - セキュリティグループはデフォルトで全ての通信をブロックします。したがって、Lambda から RDS への通信が必要な場合は、「どこからの通信を許可するか」を明示的に設定する必要があります。自己参照ルールを設定しないと、同じセキュリティグループ内であっても、その通信は許可されません。
    - 例えば、RDS が使うポート 3306（MySQL の場合）へのアクセスを許可するためのルールを、送信元（ソース）として MySecurityGroup 自体を指定します。

- AWS Glue DataBrew: Excel のような GUI 上でデータを加工するサービス。
- Redshift Data API: Redshift にデータをロードするための手段を提供。リアルタイムデータアクセス可能。
- AWS Data Exchange: サードパーティーのデータセットを検索、購入、そして使用するためのサービスです。このサービスを利用することで、ユーザーは API 呼び出しを通じて簡単にデータセットにアクセスし、これを自身のアプリケーションや分析ツールと統合することができます。
- AWS DataSync: 主にオンプレミスと AWS 環境間、または AWS サービス間でのデータ転送を自動化するサービス
- Redshift Spectrum:
  - ![image](https://github.com/user-attachments/assets/1eceb24d-5d29-46ec-8a85-bde3a148603d)
- Apache Parquet 形式: 列指向フォーマットであり、必要な列のみに対して効率的にクエリを実行し、コスト効率が高い。Amazon Athena は列指向のクエリエンジンであり、Apache Parquet 形式のデータを使用すると、ファイル全体をスキャンする代わりに必要な列のみを読み込むことができます。これにより、データ転送量が削減され、クエリ実行時間が短縮されます。さらに、Parquet はデータの圧縮とエンコーディングをサポートしており、ストレージコストの削減にも寄与します。
- Apache Avro, csv : 行指向フォーマット。クエリが特定の列のみに対して実行される場合でも、ファイル全体をスキャンする必要がある。

## 02.

- Redshift 同時スケーリング:
  - 有効にすることで読み取りと香き込みのキャパシティを動的に拡張できます。具体的には、Amazon Redshift のワークロード管理（WLM）は、クラスター内のリソースを効率的に配分するための機能であり、キューレベルで同時実行スケーリングを有効にすることで、ユーザー定義のキューの待機時間が一定以上になった場合に、自動的に追加のコンピューティングリソースをプロビジョニングします。これにより、需要の変動に応じて読み取りと香き込みのキャパシティを自動で拡張し、クラスターのパフォーマンスを最適化することができます。この機能は、特に大規模なデータウェアハウス操作において、性能の向上とリソースの効率的な利用を実現します。
  - 同時実行スケーリングが有効になっている場合、Amazon Redshift は自動的に新たなクラスターキャパシティーを追加し、読み取りと書き込み両方でクエリの増加に対応します。クエリをメインクラスターと同時実行スケーリングクラスターのどちらで実行しても、ユーザーには最新のデータが表示されます。WLM キューを設定することで、どのクエリを同時実行スケーリングクラスターに送するかを管理できます。同時実行スケーリングを有効にすると、対象となるクエリはキュー内に待機することなく、同時実行スケーリングクラスターに送信されるようになります。
- Boto3 AWS Glue create_partition API: Amazon S3 にデータを書き込む際に Boto3 AWS Glue create_partition API を呼び出すことで、AWS Glue Data Catalog が S3 ストレージと即時に同期できます。これにより、データエンジニアは新しいパーティションが追加されるたびに手動で介入することなく、AWS Glue Data Catalog が常に最新の状態を保つことを保証できます。この方法は、レイテンシーを最小限に抑えることができます。

- AWS Glue ワークフロー: データの ETL（抽出、変換、ロード）プロセスを自動化し、管理するためのサービスであり、複数の ETL ジョブと前提条件を一つのワークフローとして組み合わせることができます。この機能により、Microsoft SQL Server からデータを抽出し、変換して Amazon S3 バケットにロードするプロセスを簡単に設定できます。さらに、データパイプラインの調整が必要な場合にも、AWS Glue ワークフローを使用することで、複雑なスクリプトや外部の調整ツールを用いずに、プロセスの管理と調塾を行うことができるため、コストと労力の両面で効率的です。AWS Glue では、ワークフローを使用して、複数のクローラ、ジョブ、トリガーが関与する複雑な ETL（抽出、変換、ロード）アクティビティを作成および視覚化できます。各ワークフローは、そのすべてのジョブとクローラーの実行と監視を管理します。ワークフローは各コンポーネントを実行すると、実行の進行状況とステータスを記録します。これにより、より大きなタスクの概要と各ステップの詳細が得られます。AWS Glue コンソールは、ワークフローをグラフとして視覚的に表現します。
- AWS Step Functions と Amazon Managed Workflows for Apache Airflow （Amazon MWAA）: 複数の AWS サービスや外部サービス間でのタスクの調整や自動化に特化したサービスです。これらのサービスは、ワークフローの管理やタスク間の依存関係の設定などを効率的に行うことができますが、データの ETL （抽出、変換、ロード）を直接実行する機能は持っていません。ETL プロセスを実行するには、AWS Glue や他のデータ処理サービスを組み合わせて使用する必要があります

- Amazon EBS: ボリュームタイプの変更はデータの複製や移行を伴わずにアップグレードできる。(例: gp2 → gp3)
- AWS Lake Formation:

  - [lake formation 説明](https://qiita.com/sot528/items/8a4c3adf9ba5c2da3fa9)
  - AWS でデータレイクを構築・運用するためのマネージドサービス
  - 実体は、ほぼ AWS の各種サービスをラップしたもの(Glue, IAM, S3, etc..)
  - データレイク専用にアクセス制御を行うために、IAM とは別に独自の権限管理機構を持つ
  - Lake Formation を使用して AWS アカウント間でピアツーピアのデータ共有を可能にします。

    - データ コンシューマーがデータセットへのアクセスを要求します。
    - データ所有者は、アクセス要求を承認することでアクセスを許可します。データ所有者は、アクセス要求の承認をデータ管理者に委任できます。
    - アクセス要求が承認されると、プロデューサー アカウントの Lake Formation 内の特定のデータセットに新しい権限が追加されます。

  - Amazon S3 のパスを AWS Lake Formation のロケーションとして登録することにより、データの組織化とアクセスの管理を効率化します。この方法により、データエンジニアリングチームは、必要なデータへのアクセスを正確に制御し、人事部門がそのリージョン内の従業員のみのレコードにアクセスできるようにすることができます。
  - データレイクへの Amazon S3 ロケーションの追加

    - Amazon S3 のロケーションをテータレイク内のストレージとして追加するには、そのロケーションを AWS Lake Formation に含録します。その後、Lake Formation のアクセス許可を使用して、この場所を指す AWS Glue データ カタログ オブジェクトと、その場所の基礎となるデータに対するきめ細かいアクセス制御を行うことができます。

  - AWS Lake Formation のきめ細かなアクセス制御を有効にすることで、各リージョンのデータに対するきめ細かなアクセス制御が可能になります。データフィルターを追加することで、各人事部門が自部門のリージョン内の従業貝レコードのみにアクセスできるように制限し、この要件を満たすために必要な運用上のオーバーヘッドを最小限に抑えることができます
  - ![image](https://github.com/user-attachments/assets/0d22378a-3372-4f4c-a4c8-8e89dfd742e7)
  - ![image](https://github.com/user-attachments/assets/0a4f347a-692b-4c0d-a35b-2e2b5a664483)

## 03.

- AWS Lambda の同時実行数
  - Lambda での同時実行とは、関数が同時に処理できるリクエストの数のことです。利用できる同時実行コントロールには、次の 2 種類があります。
  - 予約済み同時実行：予約済み同時実行は、関数の同時インスタンスの最大数を保証します。ある関数が予約済同時実行数を使用している場合、他の関数はその同時実行数を使用できません。関数に対して予約済み同時実行を設定する場合には料金はかかりません。
  - プロビジョニング済み同時実行：プロビジョニング済み同時実行は、リクエストされた数の実行環境を初期化して、関数の呼び出しに即座に応答する準備をします。プロビジョニングされた同時実行を設定すると、AWS アカウントに課金が発生することに注意してください。
- コールドスタート: Lambda が関数のインスタンスを割り当てると、ランタイムは関数のコードをロードし、ハンドラの外部で定義された初期化コードを実行します。コードと依存関係が大きい場合、または初期化中に SDK クライアントを作成する場合、このプロセスには時間がかかることがあります。関数がしばらく使用されていない場合、スケールアップする必要がある場合、または更新する場合、Lambda は新しい実行環境を作成します。これにより、新しいインスタンスによって処理されるリクエストの部分は、残りの部分よりもレイテンシーが長くなります。
- 呼び出しの増加前にプロビジョニングされた同時実行数を割り当てることにより、すべてのリクエストが、短いレイテンシーで、初期化されたインスタンスによって処理されるようにできます。プロビジョニングされた同時実行で設定された Lambda 関数は、一貫性のあるスタートアップレイテンシーで実行されるため、インタラクティブなモバイルまたはウェブバックエンド、レイテンシーの影響を受けやすいマイクロサービス、同期的に呼び出される API の構築に最適です。Lambda は Application Auto Scaling と統合するので、スケジュールに従って、または使用率に基づいて、プロビジョニングされた同時実行数を管理できます。

- Redshift STL システムビュー: システムの履歴を提供するために Amazon Redshift ログファイルから生成されます。これらのファイルは、データウェアハウスクラスター内の各ノードに置かれます。STL ビューは、ログから取得した情報を、システム管理者が使用できる形式のビューにしたものです。STL システムビューは 7 日間のログ限歴を保持します。ログの保持は、すべてのクラスターサイズとノードタイプで保証されており、クラスターワークロードの変化による影響を受けません。また、ログの保持は、クラスターの一時停止などのクラスターの状態からも影響を受けません。クラスターが新しい場合のみ、ログ履歴が 7 日未満になります。ログの保持にお客様によるアクションは不要ですが、ログデータを 7 日以上保持する場合は、ログを定期的に他のテーブルにコピーするか、Amazon S3 にアンロードする必要があります。
- STL_ALERT_EVENT_LOG - クエリ実行中にクエリオプティマイザが特定した潜在的なパフォーマンスの問題を記録します。これにより、データエンジニアは長時間実行されるクエリに起因するパフォーマンスの問題を効果的に識別し、対処することができます。
- STL PLAN INFO: クエリプランに関する情報を提供
- STL QUERY METRICS: クエリのパフォーマンスメトリクスを提供
- STL USAGE_CONTROL: リソース使用量を制御するための設定を記録するために使用される。

-　 AWS DataSync: オンプレミスのデータセンターから Amazon S3 バケットへのデータ転送を自動化し、スケジュール設定が可能であり、データの定期的な更新が要求される状況に最適。AWS Datasync ロケーション間で定期的にデータを転送するようにタスクを設定できます。スケジュールされたタスクは、最低 1 時間の間隔で設定した頻度で自動的に実行されます。

- Amazon S3 Transfer Acceleration: インターネット経由で　 Amazon S3 へのファイル転送を加速する機能。大量データの転送に有効だが、データ更新の自動化やスケジューリングには対応していない。
- Athena のワークグループ: ワークグループと IAM ポリシーを使用することで、クエリプロセスとクエリ履歴へのアクセスを分離する権限制御が実現できる。具体的には、Amazon Athena のワークグループをユースケースごとに作成することで、クエリ実行環境を分離します。さらに、ワークグループにタグを適用し、これらのタグを基にした IAM ポリシーを作成することで、適切なユーザー、チーム、またはアプリケーションが特定のワークグループへのアクセスを制御できます。この方法により、同じ AWS アカウント内の異なるエンティティ間でクエリプロセス とクエリ履歴へのアクセスを効果的に分離できます
- Athena のワークグループには、以下の特徴があります。
  - デフォルトでは、各アカウントにはプライマリワークグループがあり、デフォルトのアクセス許可により認証されたすべてのユーザーがこのワークグループにアクセスできます。プライマリワークグループは削除できません。
  - 作成した各ワークグループには、そこで実行されたクエリについてのみ保存されたクエリおよびクエリ履歴が表示され、アカウントのすべてのクエリは表示されません。これにより、アカウント内の他のクエリからクエリが分離され、自分が保存したクエリおよび履歴内のクエリを見つけることがより効率的になります。
  - ワークグループを無効にすると、有効にするまでクエリは実行されなくなります。無効なワークグループに送信されたクエリは、再び有効にするまで失敗します。
  - アクセス権限がある場合は、空のワークグループと、保存したクエリを含むワークグループを削除できます。この場合、ワークグループを削除する前に、保存されたクエリが削除されることを Athena が告します。他のユーザーがアクセスできるワークグループを削除する前に、そのユーザーが引き続きクエリを実行できる他のワークグループにアクセスできることを確認してください。
  - ワークグループ全体の設定をセットアップし、ワークグループで実行されるすべてのクエリでその使用を強制することができます。設定には、Amazon S3 にあるクエリ結果、予測されるバケット所有者、暗号化、クエリ結果バケットに昔き込まれたオブジェクトのコントロールが含まれます。
  - ![image](https://github.com/user-attachments/assets/a8cbc55a-0694-455b-bb52-42a670defe08)

## 05.

- AWS Glue Data Catalog: AWS の中央メタデータリポジトリとして機能し、構造化および半構造化データソースのメタデータを一元管理する機能を提供します。このサービスは、Amazon RDS や Amazon Redshift などの構造化ソース、そして Amazon S3 に保存された JSON ファイルや.xml ファイルなどの半構造化ソースのメタデータをカタログ化できます。AWS Glue クローラーは、これらのデータソースに自動的に接続し、メタデータの変更を検出してデータカタログを更新します。クローラーを定期的に実行することによって、データカタログは常に最新の状態に保たれます。
- ![image](https://github.com/user-attachments/assets/5d384837-a125-433d-bc66-d0e1d70d75f1)

- Kinesis Data Streams を使用したクロスアカウントクロスリージョンログデータ共有:

- CloudWatch サブスクリプションフィルター: 特定のログストリームからリアルタイムでログデータを別のサービスに転送するために使用されます。サブスクリプションフィルターを使うことで、CloudWatch Logs に保存されるログを Amazon Kinesis Data Streams、Amazon Kinesis Data Firehose、または AWS Lambda にリアルタイムで転送できます。本番アカウントの CloudWatch Logs グループでサブスクリプションフィルターを作成し、そのログをセキュリティアカウントにある Kinesis Data Streams に送る設定を行う。フィルターを使って、特定の条件に合致するログだけを転送することが可能です。

- Amazon Athena のフェデレーテッド・クエリ: AWS Lambda で実行されるデータソースコネクタを使用します。データソースコネクタは、ターゲットデータソースと Athena 間での変換を実行できるコードです。コネクタは、Athena のクエリエンジンの拡張機能として考えることができます。事前構築された Athena データソースコネクタは、Amazon CloudWatch Logs、Amazon DynamoDB、 Amazon DocumentDB、 Amazon RDS、および MySQL や Apache 2.0 ライセンスに基づく PostgresQL などの JDBC 準拠のリレーショナルデータソースといったデータソース用のものです。Athena Query Federation SDK を使用してカスタムコネクタを記述することもできます。データソースコネクタを選択し、設定し、アカウントにデプロイするには、Athena および Lambda コンソールまたは AWS Serverless Application Repository を使用できます。データソースコネクタをデプロイした後、コネクタは SQL クエリで指定できるカタログに関連付けられます。複数のカタログの SQL ステートメントを組み合わせて、1 つのクエリの範囲に複数のデータソースを入れることができます。
  - ![image](https://github.com/user-attachments/assets/0663368e-4d7b-431e-bec8-e3931361b713)
- フェデレーテッド（Federated）: 直訳すると「連合」や「統合」という意味を持ちます。IT やデータベースの分野では、「フェデレーテッド」は、複数の異なるシステムやデータソースを統合して、あたかも一つのシステムのように動作させる概念を指します。

## 06.

- Redshift:

  - ゾーンマップ
    - Amazon Redshift はカラムごとに「ブロック」単位でディスクにデータを格納。１ブロック＝１ MB
    - ブロック内の最小値と最大値をメモリに保存
    - 不要なブロックを読み飛ばすことが可能
  - ソートキー
    - カラムのデータをあらかじめソートしておけば、ゾーンマップによる読み込みブロックの絞り込みを効果的に行うことが可能
    - クエリで頻繁に絞り込みを行う列をソートキーとして指定することで、データロードやメンテナンス時にデータをソートしておくことができる
  - 分散スタイル
    - ![image](https://github.com/user-attachments/assets/8860aa0a-9d20-4642-bb2f-c90188354cc8)

- EBS: ルートボリュームに設定すると EC2 インスタンス終了時にデータが消えるため、2nd としてアタッチして、保存したいデータは EBS に保存する。
- AWS Glue DataBrew:
- AWS Glue スキーマ変更:
- AWS Glue Data Catalog:
- AWS Glue Crawler:
