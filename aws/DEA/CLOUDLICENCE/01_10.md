# CloudLicence

## 01.

- Apache Hive メタストア　 → 　 AWS Glue Data Catalog に移行できる。

- AWS Lambda と RDS のプライベート通信:

  - Lambda 関数にも RDS にも同じ SG を設定し、SG の設定で同じセキュリティグループからの通信を許可する。
  - Lambda 関数と RDS はどちらも同じ MySecurityGroup に所属しているため、この自己参照ルールにより、セキュリティグループに属するリソース間で安全に通信できるようになります。
  - セキュリティグループはデフォルトで全ての通信をブロックします。したがって、Lambda から RDS への通信が必要な場合は、「どこからの通信を許可するか」を明示的に設定する必要があります。自己参照ルールを設定しないと、同じセキュリティグループ内であっても、その通信は許可されません。
    - 例えば、RDS が使うポート 3306（MySQL の場合）へのアクセスを許可するためのルールを、送信元（ソース）として MySecurityGroup 自体を指定します。

- AWS Glue DataBrew: Excel のような GUI 上でデータを加工するサービス。
- Redshift Data API: Redshift にデータをロードするための手段を提供。リアルタイムデータアクセス可能。
- AWS Data Exchange: サードパーティーのデータセットを検索、購入、そして使用するためのサービスです。このサービスを利用することで、ユーザーは API 呼び出しを通じて簡単にデータセットにアクセスし、これを自身のアプリケーションや分析ツールと統合することができます。
- AWS Glue FLEX 実行クラス: ジョブを実行するために必要なリソースを動的にスケーリングする。緊急ではないデータ統合ワークロード（本番前のジョブ、テスト、データロードなど）のコストを最大 35%削減できる柔軟な実行ジョブクラスです。Glue には、スタンダードとフレキシブルの 2 つのジョブ実行クラスがあります。スタンダード実行クラスは、ジョブの高速起動と専用リソースを必要とする、時間に敏感なワークロードに最適です。フレキシブル実行クラスは、開始時刻と完了時刻が異なる可能性がある緊急でないジョブに適しています。AWS Glue Flex は、時間に左右されないワークロード（夜間のバッチ ETL ジョブ、週末のジョブ、1 回限りの一括データインジェストジョブなど）のコストを削減できます
- AWS Glue FindMatches ML 変換: 一致するレコードを特定するカスタム機械学習変換である。AWS Glue でデータセット (識別子のないものを含む) 全体から、一致するレコードを検索できます。
- AWS DataSync: 主にオンプレミスと AWS 環境間、または AWS サービス間でのデータ転送を自動化するサービス
- Redshift Spectrum:
  - ![image](https://github.com/user-attachments/assets/1eceb24d-5d29-46ec-8a85-bde3a148603d)
- Apache Parquet 形式: 列指向フォーマットであり、必要な列のみに対して効率的にクエリを実行し、コスト効率が高い。Amazon Athena は列指向のクエリエンジンであり、Apache Parquet 形式のデータを使用すると、ファイル全体をスキャンする代わりに必要な列のみを読み込むことができます。これにより、データ転送量が削減され、クエリ実行時間が短縮されます。さらに、Parquet はデータの圧縮とエンコーディングをサポートしており、ストレージコストの削減にも寄与します。
- Apache Avro, csv : 行指向フォーマット。クエリが特定の列のみに対して実行される場合でも、ファイル全体をスキャンする必要がある。

## 02.

- Redshift 同時スケーリング:
  - 有効にすることで読み取りと香き込みのキャパシティを動的に拡張できます。具体的には、Amazon Redshift のワークロード管理（WLM）は、クラスター内のリソースを効率的に配分するための機能であり、キューレベルで同時実行スケーリングを有効にすることで、ユーザー定義のキューの待機時間が一定以上になった場合に、自動的に追加のコンピューティングリソースをプロビジョニングします。これにより、需要の変動に応じて読み取りと香き込みのキャパシティを自動で拡張し、クラスターのパフォーマンスを最適化することができます。この機能は、特に大規模なデータウェアハウス操作において、性能の向上とリソースの効率的な利用を実現します。
  - 同時実行スケーリングが有効になっている場合、Amazon Redshift は自動的に新たなクラスターキャパシティーを追加し、読み取りと書き込み両方でクエリの増加に対応します。クエリをメインクラスターと同時実行スケーリングクラスターのどちらで実行しても、ユーザーには最新のデータが表示されます。WLM キューを設定することで、どのクエリを同時実行スケーリングクラスターに送するかを管理できます。同時実行スケーリングを有効にすると、対象となるクエリはキュー内に待機することなく、同時実行スケーリングクラスターに送信されるようになります。
- Boto3 AWS Glue create_partition API: Amazon S3 にデータを書き込む際に Boto3 AWS Glue create_partition API を呼び出すことで、AWS Glue Data Catalog が S3 ストレージと即時に同期できます。これにより、データエンジニアは新しいパーティションが追加されるたびに手動で介入することなく、AWS Glue Data Catalog が常に最新の状態を保つことを保証できます。この方法は、レイテンシーを最小限に抑えることができます。

- AWS Glue ワークフロー: データの ETL（抽出、変換、ロード）プロセスを自動化し、管理するためのサービスであり、複数の ETL ジョブと前提条件を一つのワークフローとして組み合わせることができます。この機能により、Microsoft SQL Server からデータを抽出し、変換して Amazon S3 バケットにロードするプロセスを簡単に設定できます。さらに、データパイプラインの調整が必要な場合にも、AWS Glue ワークフローを使用することで、複雑なスクリプトや外部の調整ツールを用いずに、プロセスの管理と調塾を行うことができるため、コストと労力の両面で効率的です。AWS Glue では、ワークフローを使用して、複数のクローラ、ジョブ、トリガーが関与する複雑な ETL（抽出、変換、ロード）アクティビティを作成および視覚化できます。各ワークフローは、そのすべてのジョブとクローラーの実行と監視を管理します。ワークフローは各コンポーネントを実行すると、実行の進行状況とステータスを記録します。これにより、より大きなタスクの概要と各ステップの詳細が得られます。AWS Glue コンソールは、ワークフローをグラフとして視覚的に表現します。
- AWS Step Functions と Amazon Managed Workflows for Apache Airflow （Amazon MWAA）: 複数の AWS サービスや外部サービス間でのタスクの調整や自動化に特化したサービスです。これらのサービスは、ワークフローの管理やタスク間の依存関係の設定などを効率的に行うことができますが、データの ETL （抽出、変換、ロード）を直接実行する機能は持っていません。ETL プロセスを実行するには、AWS Glue や他のデータ処理サービスを組み合わせて使用する必要があります

- Amazon EBS: ボリュームタイプの変更はデータの複製や移行を伴わずにアップグレードできる。(例: gp2 → gp3)
- AWS Lake Formation:

  - [lake formation 説明](https://qiita.com/sot528/items/8a4c3adf9ba5c2da3fa9)
  - ![image](https://github.com/user-attachments/assets/4d79f998-ec2c-41a4-b2e5-2ed2f08e1f2a)

  - AWS でデータレイクを構築・運用するためのマネージドサービス
  - 実体は、ほぼ AWS の各種サービスをラップしたもの(Glue, IAM, S3, etc..)
  - データレイク専用にアクセス制御を行うために、IAM とは別に独自の権限管理機構を持つ
  - Lake Formation を使用して AWS アカウント間でピアツーピアのデータ共有を可能にします。
    - データ コンシューマーがデータセットへのアクセスを要求します。
    - データ所有者は、アクセス要求を承認することでアクセスを許可します。データ所有者は、アクセス要求の承認をデータ管理者に委任できます。
    - アクセス要求が承認されると、プロデューサー アカウントの Lake Formation 内の特定のデータセットに新しい権限が追加されます。
  - Amazon S3 のパスを AWS Lake Formation のロケーションとして登録することにより、データの組織化とアクセスの管理を効率化します。この方法により、データエンジニアリングチームは、必要なデータへのアクセスを正確に制御し、人事部門がそのリージョン内の従業員のみのレコードにアクセスできるようにすることができます。
  - データレイクへの Amazon S3 ロケーションの追加
    - Amazon S3 のロケーションをテータレイク内のストレージとして追加するには、そのロケーションを AWS Lake Formation に含録します。その後、Lake Formation のアクセス許可を使用して、この場所を指す AWS Glue データ カタログ オブジェクトと、その場所の基礎となるデータに対するきめ細かいアクセス制御を行うことができます。
  - AWS Lake Formation のきめ細かなアクセス制御を有効にすることで、各リージョンのデータに対するきめ細かなアクセス制御が可能になります。データフィルターを追加することで、各人事部門が自部門のリージョン内の従業貝レコードのみにアクセスできるように制限し、この要件を満たすために必要な運用上のオーバーヘッドを最小限に抑えることができます
  - ![image](https://github.com/user-attachments/assets/0d22378a-3372-4f4c-a4c8-8e89dfd742e7)
  - ![image](https://github.com/user-attachments/assets/0a4f347a-692b-4c0d-a35b-2e2b5a664483)
  - 機能:
    - AWS Glue の拡張機能。
      - ![image](https://github.com/user-attachments/assets/6b336aa6-72db-4ae0-95f0-76597a4eb27a)
    - データ取込みと構造化 → ブループリント：汎用的なデータ取り込みテンプレートを使い、自動的なデータ取り込みと構造化を実現。ブループリント上で必要なパラメータを入力し Lake Formation のワークフローを作成することで、Glue のトリガー、ワークフロー、クローラー、ジョブを自動で生成します。
    - セキュリティ＆コントロール → パーミッション：SQL ライクな Grant/Revoke でシンプルなアクセス制御を実現。Glue のアクセス許可モデルは IAM を介してアクセスを許可するのに対して、Lake Formation は IAM を使ったアクセス制御を簡単に設定できる。tag を使ってグルーピングされたものに対して、列や行単位でアクセス管理が簡単にできる。
    - 協調&利用 → データカタログ：スキーマやロケーションなどのデータのメタ情報を管理し、ファセット検索で探したいデータセットを探しやすく。Glue データカタログと統合。
    - 監視&監査 → ロギング：コンソールによる直近のアクティビティの詳細を確認

## 03.

- AWS Lambda の同時実行数
  - Lambda での同時実行とは、関数が同時に処理できるリクエストの数のことです。利用できる同時実行コントロールには、次の 2 種類があります。
  - 予約済み同時実行：予約済み同時実行は、関数の同時インスタンスの最大数を保証します。ある関数が予約済同時実行数を使用している場合、他の関数はその同時実行数を使用できません。関数に対して予約済み同時実行を設定する場合には料金はかかりません。
  - プロビジョニング済み同時実行：プロビジョニング済み同時実行は、リクエストされた数の実行環境を初期化して、関数の呼び出しに即座に応答する準備をします。プロビジョニングされた同時実行を設定すると、AWS アカウントに課金が発生することに注意してください。
- コールドスタート: Lambda が関数のインスタンスを割り当てると、ランタイムは関数のコードをロードし、ハンドラの外部で定義された初期化コードを実行します。コードと依存関係が大きい場合、または初期化中に SDK クライアントを作成する場合、このプロセスには時間がかかることがあります。関数がしばらく使用されていない場合、スケールアップする必要がある場合、または更新する場合、Lambda は新しい実行環境を作成します。これにより、新しいインスタンスによって処理されるリクエストの部分は、残りの部分よりもレイテンシーが長くなります。
- 呼び出しの増加前にプロビジョニングされた同時実行数を割り当てることにより、すべてのリクエストが、短いレイテンシーで、初期化されたインスタンスによって処理されるようにできます。プロビジョニングされた同時実行で設定された Lambda 関数は、一貫性のあるスタートアップレイテンシーで実行されるため、インタラクティブなモバイルまたはウェブバックエンド、レイテンシーの影響を受けやすいマイクロサービス、同期的に呼び出される API の構築に最適です。Lambda は Application Auto Scaling と統合するので、スケジュールに従って、または使用率に基づいて、プロビジョニングされた同時実行数を管理できます。

- Redshift STL システムビュー: システムの履歴を提供するために Amazon Redshift ログファイルから生成されます。これらのファイルは、データウェアハウスクラスター内の各ノードに置かれます。STL ビューは、ログから取得した情報を、システム管理者が使用できる形式のビューにしたものです。STL システムビューは 7 日間のログ限歴を保持します。ログの保持は、すべてのクラスターサイズとノードタイプで保証されており、クラスターワークロードの変化による影響を受けません。また、ログの保持は、クラスターの一時停止などのクラスターの状態からも影響を受けません。クラスターが新しい場合のみ、ログ履歴が 7 日未満になります。ログの保持にお客様によるアクションは不要ですが、ログデータを 7 日以上保持する場合は、ログを定期的に他のテーブルにコピーするか、Amazon S3 にアンロードする必要があります。
- STL_ALERT_EVENT_LOG - クエリ実行中にクエリオプティマイザが特定した潜在的なパフォーマンスの問題を記録します。これにより、データエンジニアは長時間実行されるクエリに起因するパフォーマンスの問題を効果的に識別し、対処することができます。
- STL PLAN INFO: クエリプランに関する情報を提供
- STL QUERY METRICS: クエリのパフォーマンスメトリクスを提供
- STL USAGE_CONTROL: リソース使用量を制御するための設定を記録するために使用される。

-　 AWS DataSync: オンプレミスのデータセンターから Amazon S3 バケットへのデータ転送を自動化し、スケジュール設定が可能であり、データの定期的な更新が要求される状況に最適。AWS Datasync ロケーション間で定期的にデータを転送するようにタスクを設定できます。スケジュールされたタスクは、最低 1 時間の間隔で設定した頻度で自動的に実行されます。

- Amazon S3 Transfer Acceleration: インターネット経由で　 Amazon S3 へのファイル転送を加速する機能。大量データの転送に有効だが、データ更新の自動化やスケジューリングには対応していない。
- Athena のワークグループ: ワークグループと IAM ポリシーを使用することで、クエリプロセスとクエリ履歴へのアクセスを分離する権限制御が実現できる。具体的には、Amazon Athena のワークグループをユースケースごとに作成することで、クエリ実行環境を分離します。さらに、ワークグループにタグを適用し、これらのタグを基にした IAM ポリシーを作成することで、適切なユーザー、チーム、またはアプリケーションが特定のワークグループへのアクセスを制御できます。この方法により、同じ AWS アカウント内の異なるエンティティ間でクエリプロセス とクエリ履歴へのアクセスを効果的に分離できます
- Athena のワークグループには、以下の特徴があります。

  - デフォルトでは、各アカウントにはプライマリワークグループがあり、デフォルトのアクセス許可により認証されたすべてのユーザーがこのワークグループにアクセスできます。プライマリワークグループは削除できません。
  - 作成した各ワークグループには、そこで実行されたクエリについてのみ保存されたクエリおよびクエリ履歴が表示され、アカウントのすべてのクエリは表示されません。これにより、アカウント内の他のクエリからクエリが分離され、自分が保存したクエリおよび履歴内のクエリを見つけることがより効率的になります。
  - ワークグループを無効にすると、有効にするまでクエリは実行されなくなります。無効なワークグループに送信されたクエリは、再び有効にするまで失敗します。
  - アクセス権限がある場合は、空のワークグループと、保存したクエリを含むワークグループを削除できます。この場合、ワークグループを削除する前に、保存されたクエリが削除されることを Athena が告します。他のユーザーがアクセスできるワークグループを削除する前に、そのユーザーが引き続きクエリを実行できる他のワークグループにアクセスできることを確認してください。
  - ワークグループ全体の設定をセットアップし、ワークグループで実行されるすべてのクエリでその使用を強制することができます。設定には、Amazon S3 にあるクエリ結果、予測されるバケット所有者、暗号化、クエリ結果バケットに昔き込まれたオブジェクトのコントロールが含まれます。
  - ![image](https://github.com/user-attachments/assets/a8cbc55a-0694-455b-bb52-42a670defe08)

- Amazon EMR: YARN、HDFS、Apache Spark、 Apache HBase、 Apache Hive などの多彩なマルチマスターアプリケーション用の高可用性をワンクリックで設定できます。マルチマスターサポートを備えると、EMR によってこれらのアプリケーションが高可用性で設定されます。障害発生時には、予備のマスターに自動的にフェイルオーバーして、クラスターの破損を防げます。また、異なるラックにマスターノードを置き換え、同時障害のリスクを軽減できます。ホストをモニタリングして障害を検知し、問題が検出された場合、新しいホストがプロビジョニングされ、自動的にクラスターに追加されます。

## 05.

- AWS Glue Data Catalog: AWS の中央メタデータリポジトリとして機能し、構造化および半構造化データソースのメタデータを一元管理する機能を提供します。このサービスは、Amazon RDS や Amazon Redshift などの構造化ソース、そして Amazon S3 に保存された JSON ファイルや.xml ファイルなどの半構造化ソースのメタデータをカタログ化できます。AWS Glue クローラーは、これらのデータソースに自動的に接続し、メタデータの変更を検出してデータカタログを更新します。クローラーを定期的に実行することによって、データカタログは常に最新の状態に保たれます。
- ![image](https://github.com/user-attachments/assets/5d384837-a125-433d-bc66-d0e1d70d75f1)

- Kinesis Data Streams を使用したクロスアカウントクロスリージョンログデータ共有:

- CloudWatch サブスクリプションフィルター:

  - 特定のログストリームからリアルタイムでログデータを別のサービスに転送するために使用されます。サブスクリプションフィルターを使うことで、CloudWatch Logs に保存されるログを Amazon Kinesis Data Streams、Amazon Kinesis Data Firehose、または AWS Lambda にリアルタイムで転送できます。本番アカウントの CloudWatch Logs グループでサブスクリプションフィルターを作成し、そのログをセキュリティアカウントにある Kinesis Data Streams に送る設定を行う。フィルターを使って、特定の条件に合致するログだけを転送することが可能です。
  - 具体的には、セキュリティログをセキュリティ AWS アカウントで収集し分析する必要があるため、Amazon Kinesis Data Streams はセキュリティ AWS アカウントで作成する必要があります。また、本番環境の AWS アカウントの CloudWatch Logs はセキュリティ AWS アカウントにログを送信するためのクロスアカウントアクセスを許可する必要があります。サブスクリプションフィルターは、ログを Amazon Kinesis Data Streams に送信するために、本番の AWS アカウントで作成される必要があります。

- Amazon Athena のフェデレーテッド・クエリ: AWS Lambda で実行されるデータソースコネクタを使用します。データソースコネクタは、ターゲットデータソースと Athena 間での変換を実行できるコードです。コネクタは、Athena のクエリエンジンの拡張機能として考えることができます。事前構築された Athena データソースコネクタは、Amazon CloudWatch Logs、Amazon DynamoDB、 Amazon DocumentDB、 Amazon RDS、および MySQL や Apache 2.0 ライセンスに基づく PostgresQL などの JDBC 準拠のリレーショナルデータソースといったデータソース用のものです。Athena Query Federation SDK を使用してカスタムコネクタを記述することもできます。データソースコネクタを選択し、設定し、アカウントにデプロイするには、Athena および Lambda コンソールまたは AWS Serverless Application Repository を使用できます。データソースコネクタをデプロイした後、コネクタは SQL クエリで指定できるカタログに関連付けられます。複数のカタログの SQL ステートメントを組み合わせて、1 つのクエリの範囲に複数のデータソースを入れることができます。
  - ![image](https://github.com/user-attachments/assets/0663368e-4d7b-431e-bec8-e3931361b713)
- フェデレーテッド（Federated）: 直訳すると「連合」や「統合」という意味を持ちます。IT やデータベースの分野では、「フェデレーテッド」は、複数の異なるシステムやデータソースを統合して、あたかも一つのシステムのように動作させる概念を指します。

## 06.

- Redshift:

  - Redshift は、クラスタ ＞ ノード ＞ スライス　の構成
    - 各ノードは並列で動く
    - データは各スライスに分割して持つ
    - データが偏っちゃうと働かないノードがでてくるのでもったいない
    - 別のノードが持っているデータが必要になると、データを再分散しないといけないので時間がかかる
  - ![image](https://github.com/user-attachments/assets/21fb90a7-afdc-4fa2-a99f-d77a35c8fe76)
  - ゾーンマップ
    - Amazon Redshift はカラムごとに「ブロック」単位でディスクにデータを格納。１ブロック＝１ MB
    - ブロック内の最小値と最大値をメモリに保存
    - 不要なブロックを読み飛ばすことが可能
  - ソートキー
    - カラムのデータをあらかじめソートしておけば、ゾーンマップによる読み込みブロックの絞り込みを効果的に行うことが可能
    - クエリで頻繁に絞り込みを行う列をソートキーとして指定することで、データロードやメンテナンス時にデータをソートしておくことができる
  - 分散スタイル
    - AUTO 分散: Amazon Redshift はテーブルデータのサイズに基づいて最適な分散スタイルを割り当てます。例えば、AUTO 分散スタイルが指定された場合、Amazon Redshift ではまず、ALL 分散スタイルを小さなテーブルに割り当てます。テーブルが大きくなると、Amazon Redshift は分散スタイルを KEY に変更し、プライマリキー (または複合プライマリキーの列) を分散キーとして選択する場合があります。テーブルが大きくなり、分散キーに適した列がない場合、Amazon Redshift は分散スタイルを EVEN に変更します。
    - EVEN 分散: リーダーノードは、特定の列の値に含まれている値にかかわらず、ラウンドロビン方式によって複数のスライス間で行を分散させます。テーブルが結合に参加しない場合は、EVEN ディストリビューションが適切です。
    - キー分散: 行の分散は、特定の列に含まれている値に従って行われます。リーダーノードは、複数の一致する値を同じノードスライスに配置します。結合キーに基づいてテーブルのペアを分散する場合、リーダーノードは、結合列に含まれている値に従って行をスライスにコロケーションします。このようにして、共通の列から一致する値が物理的に一緒に保存されます。
    - ALL 分散: テーブル全体のコピーがすべてのノードに分散されます。EVEN 分散または KEY 分散によってテーブルの一部の行のみが各ノードに配置されている場合、ALL 分散を行うと、テーブルが関与しているあらゆる結合ですべての行が確実にコロケーションされるようになります。
    - ![image](https://github.com/user-attachments/assets/8860aa0a-9d20-4642-bb2f-c90188354cc8)
  - フェデレーテッドクエリ
    - RDS/Aurora の PostgreSQL/MySQL に対して直接クエリ可能
  - Amazon Redshift Data Sharing
    - Redshift クラスター間でセキュアに簡単にデータを共有することが可能
  - 結果セットのキャッシュ
    - ![image](https://github.com/user-attachments/assets/e7513dc5-53c0-4317-9c18-f9da61c55030)

- Materialized View

  - ビューは参照の度に SQL を実行するのに対し、マテリアライズド・ビューは保持している SQL の結果を返却するため、複雑な集計処理に際してはマテリアライズド・ビューが圧倒的なパフォーマンスを発揮します。
  - マテリアライズド・ビューにできて、バッチでは実現できないこと、それは変化点のみの更新（高速リフレッシュ）です。厳密にいうとこれもバッチでできないことはありません。更新日時や更新済みフラグなどを用いて変化点のみを更新することは可能です。ただ、あるデータが「変化したかどうか」をムダな判定処理が入るのも事実です。変化点のみに着目した更新が可能となるため、例えば大量データの集計処理であっても集計結果を高速に算出することが可能です。

- EBS: ルートボリュームに設定すると EC2 インスタンス終了時にデータが消えるため、2nd としてアタッチして、保存したいデータは EBS に保存する。
- Athena:

  - Athena は、AWS Glue の一機能である Glue Data Catalog（メタデータストア） と統合しています。Athena を利用して分析をしているつもりでも、その裏側では S3 データに関するテーブルメタデータの保存と取得に AWS Glue Data Catalog を使用しています。
  - ![image](https://github.com/user-attachments/assets/c4c81644-d2bf-478a-8ba7-9d9258e84b3b)

- AWS Glue DataBrew: 視覚的なデータ準備ツールであり、データアナリストやデータサイエンティストはデータをより簡単にクリーンアップおよび正規化し、分析や機械学習（ML）の準備をすることができます。250 を超える事前構築された変換から選択して、コードを記述することなくデータ準備タスクを自動化できます。異常のフィルタリング、標準形式へのデータの変換、無効な値の修正などのタスクを自動化できます。AWS Glue JOB や Athena より楽に設定できる。
- AWS Glue スキーマ変更:
  - Glue Data catalog をスキャンすることでスキーマ変更を検知。
- AWS Glue Crawler:
  - Glue Data Catalog にメタデータを作成するプログラムです。S3 のデータからデータベースとテーブルのスキーマを自動的に推論し、関連するメタデータを AWS Glue Data Catalog に保存します。
- AWS Glue Data Quality:
  - ユーザーが定義したルールに従ってデータの品質検査を実施できる機能。
  - 利用パターン
    - Glue Data Catalog に登録されたテーブルに対してデータ品質検査ルールを実行。取り込み後データのチェックに便利
    - Glue ETL JOB の中に組み込み形でデータ品質検査ルールを実行。取り込み前のデータチェックに便利。

## 07.

- Amazon AppFlow: サードパーティーの Saas アプリケーションから Amazon S3 へデータを直接転送し、それを Amazon Redshift に連携することで、データに基づいた分析を実行できます。この方法は、運用上のオーバーヘッドを最小限に抑えつつ、必要なデータ収集と分析の要件を満たします。Amazon AppFlow はノーコードで簡単に設定でき、複雑なデータパイプラインをコーディングする必要がないため、メディア企業が運用の複雑さを増すことなく、効率的にデータを収集し分析することを可能にします

- 変更されたデータを最もコスト効率よくキャプチャできるソリューション:
  - オープンソースのデータレイク形式を利用することで、大規模な半構造化データファイルに対して効率的に変更データキャプチャ （CDC）を実行し、Amazon S3 に保存されたデータソースを効率的に統合し、新しいデータを追加して既存のデータを更新します。この方法は変更されたデータのみを処理するため、ストレージと計算のコストを最小限に抑えることができ、コスト効率の良いデータの変更管理を実現します。
  - 処理フロー
    - 1.データソースが毎日完全なスナップショットを JSON ファイルとして生成し、Amazon S3 にアップロードします。
    - 2.CDC 操作を実行し、前回のスナップショットと今回のスナップショットを比較して変更されたデータを特定します。
    - 3.オープンソースのデータレイク形式（例 ：Apache Hudi, Delta Lake, Apache Iceberg）を使用して、特定された変更データをデータレイクに取り込みます。
    - 4.新しいデータは追加され、既存のデータは更新されます。
- 変更データキャプチャ （CDC）: データベース内の変更（挿入、更新、削除）を追跡し、これらの変更をデータレイクに取り込むための技術です。CDC は、データソースの完全なスナップショットを JSON ファイルとして Amazon S3 に保存し、その変更分をデータレイクに反映させるために使用されます。

- オープンソースのデータレイク形式

  - Apache Hudi： データレイクの変更データキャプチャとデータのバージョン管理を提供します。データのき込みと読み取りのパフォーマンスが高く、増分データを効率的に処理します。
  - Delta Lake： データの ACID トランザクション、スケーラブルなメタデータ処理、および変更データキャプチャをサポートするオープンソースプロジェクトです。これにより、信頼性の高いデータレイクを構築できます。
  - Apache Iceberg： データのスナップショットや増分処理を効率的に行うためのテーブル形式を提供します。大規模なデータセットの処理に適しています

- DynamoDB
  - プロビジョニング + AWS Application Auto Scaling: 予測可能なリクエスト量 + 一時的な負荷。コスト低。
  - オンデマンド: 予測不可能なリクエスト量。コスト高

### 08.

-　 AWS DMS:

- データベースを AWS に迅速かつ安全に移行するのに役立ちます。移行中でもソースデータベースは完全に利用可能な状態に保たれ、データベースを利用するアプリケーションのダウンタイムは最小限に抑えられます。 AWS Database Migration Service は、広く普及しているほとんどの商用データベースとオープンソースデータベース間のデータ移行でご利用いただけます。
- Oracle から Oracle のような同種のデータベース間の移行も、Oracle または Microsoft SQL から Amazon Aurora といった異なるデータベースプラットフォーム間の移行もサボートされます。また、AWS Database Migration Service を使用すると、サポートされているあらゆるソースからサポートされているあらゆるターゲットに、低レイテンシーで継続的にデータをレプリケートすることができます。例えば、複数のソースから Amazon S3 にレプリケートすることで、高可用性のスケーラブルなデータレイクソリューションを構築することができます。また、Amazon Redshift にデータをストリーミングすることで、データベースをペタバイト規模のデータウェアハウスに統合することもできます。
- AWS DataSync: オンプレミスのファイルシステムと AWS 間でのデータの同期を行うシステム。DB 間ではない。
- Amazon S3 Intelligent-Tiering:

  - ![image](https://github.com/user-attachments/assets/40f98b20-3730-4cd6-9fa0-4c99ac223511)
  - 高頻度アクセス階層（自動）: S3 Intelligent-Tiering で作成されたオブジェクトや S3 Intelligent-Tiering に移行したオブジェクトのライフサイクルを開始するデフォルトのアクセス階層です。オブジェクトは、アクセスされている限り、この階層に残ります。高頻度アクセス階層は、低レイテンシーと高スループットのパフォーマンスを提供します。
  - 低頻度アクセス階層 (自動): オブジェクトが 30 日間連続してアクセスされない場合、オブジェクトは低頻度アクセス階層に移行します。低頻度アクセス階層は、低レイテンシーと高スループットのパフォーマンスを提供します。
  - アーカイブインスタントアクセス階層 (自動): オブジェクトが 90 日間連続してアクセスされない場合、オブジェクトはアーカイブインスタントアクセス階層に移行します。アーカイブインスタントアクセス階層は、低レイテンシーと高スループットのパフォーマンスを提供します。
  - アーカイブアクセス階層（オプション）: S3 Intelligent-Tiering では、非同期的にアクセスできるデータのためにアーカイブアクセス層をアクティブ化するオプションが提供されます。アクティブ化された後、アーカイブアクセス階層は 90 日間以上してアクセスされなかったオブジェクトを自動的にアーカイブします。アーカイブの最終アクセス時間は、最大 730 日間まで延長できます。アーカイブアクセス階層は、S3 Glacier Flexible Retrieval ストレージクラスと同じパフォーマンスです。
  - ディープアーカイブアクセス階層（オプション）: S3 Intelligent-Tiering では、非同期的にアクセスできるデータのために ディープアーカイブアクセス階層をアクティブ化するオプションが提供されます。アクティブ化後、ディープアーカイブアクセス階層は 180 日間連続してアクセスされなかったオブジェクトを自動的にアーカイブします。アーカイブの最終アクセス時間は、最大 730 日間まで延長できます。ディープアーカイブアクセス階層のパフォーマンスは、S3 Glacier Deep Archive ストレージクラスと同じです。

- Amazon Athena クエリ結果再利用: Athena でクエリを再実行する場合、オプションで最後に保存されたクエリ結果を再利用できる。これにより、パフォーマンスが向上し、スキャンされるバイト数にコストが削減される。

## 09.

- AWS Glue Schema Registry: データ構造が変更された際にスキーマの変更を自動的に補足し、データの整合性を保つ。
- AWS Glue JOB スケーリング: 変換が複雑な ETL ジョブはメモリを大量に消費し、垂直スケーリング（たとえば G.1X から G.2X ワーカータイプへの移行）が必要です。大量のデータを含む計算負荷の高い ETL ジョブの場合、AWS Glue は複数のノードでそのデータを並列処理するように設計されているため、水平スケーリングをお勧めします。
- AWS Glue パーティションインデックス: Amazon Athena が必要なデータを迅速に見つけることができる。不必要なデータのスキャンを避け、クエリのパフォーマンスが向上し、クエリプランニングの時間が短縮される。
  - パーティションインデックスがない場合
    - パーティションインデックスがない場合、AWS Glue は GetPartitions API を呼び出し、すべてのパーティション情報を一度に取得します。
    - つまり、クエリが指定した条件 (year=2022 AND month=05) に関係なく、2021 年から 2023 年までの 全パーティション を最初に読み込んでから、その中でクエリ条件に一致するパーティションをフィルタリングします。
    - パーティション数が数百や数千になると、この全パーティションのロードにかかる時間が増え、クエリの実行が非常に遅くなります。
  - パーティションインデックスがある場合
    - パーティションインデックスが有効化されている場合、AWS Glue は指定されたパーティションキーに基づいて、特定のサブセットのパーティションだけを読み込みます。つまり、クエリ条件にマッチするパーティションだけが最初から読み込まれるため、無駄なパーティションの読み込みが省かれます。
    - GetPartitions API が、すべてのパーティションをロードするのではなく、インデックスされたパーティションのみをロードすることで、クエリ実行時間が大幅に短縮されます。
- Athena パーティション射影:

  - クエリ時にメタデータを動的に生成する機能であり、 AWS Glue Data Catalog や外部 Hive メタストアのテーブルプロパティを通じて設定されます。これにより、クエリの実行時間が短縮され、パーティション管理が自動化されます。
  - パーティションプルーニングは、メタデータを収集し、クエリに適用されるパーティションのみに「プルーニング」します。多くの場合、これによってクエリが高速化されます。Athena は、パーティション射影用に設定されたテーブルなどのパーティション列があるすべてのテーブルに対してパーティションプルーニングを使用します。
  - 通常、クエリを処理する場合、Athena はパーティションプルーニングを実行する前に AWS Glue Data Catalog に対して GetPartitions 呼び出しを行います。テーブルに多数のパーティションがある場合、GetPartitions を使用すると、パフォーマンスに悪影響が及ぶ可能性があります。
  - これを回避するには、パーティション射影を使用します。パーティション射影を設定すると、Athena が独自にパーティションを構築するために必要なすべての情報を得ることができるため、GetPartitions を呼び出す必要がなくなります。
  - パーティション射影がない場合
    - パーティション射影がない場合、Athena はクエリを実行する際、パーティションメタデータを AWS Glue Data Catalog から取得する必要があります。これには以下のステップが含まれます。
      - メタデータの読み込み: Athena はクエリ実行の前に、指定されたパーティションのメタデータを Glue Data Catalog から読み込む必要があります。
      - すべてのパーティションの取得: メタデータに基づいて、すべてのパーティション情報（例えば、year, month, day の各パーティション値）を確認します。
      - フィルタリング: クエリで指定された条件に一致するパーティションだけを選択します。例えば、100,000 パーティションあるデータセットに対して year=2023 の条件でクエリを実行した場合、Athena は最初に Glue Data Catalog から 100,000 パーティションのメタデータを取得し、そこから year=2023 に該当するパーティションをフィルタリングします。このメタデータ取得プロセスに時間がかかり、クエリが遅延する原因になります。
  - パーティション射影がある場合
    - パーティション射影を設定すると、Athena は Glue Data Catalog のパーティションメタデータを取得せずに、テーブルプロパティを使用してクエリ時に必要なパーティションを動的に生成します。
    - メタデータ取得の回避: Glue Data Catalog に保存されたパーティションメタデータをロードするのではなく、Athena はテーブルプロパティを使って、必要なパーティション値を動的に計算します。
    - 射影されたパーティションの使用: クエリ条件（例: year=2023）に基づき、該当するパーティションのサブセットを即座に決定します。
    - テーブル作成時にパーティション射影のプロパティを設定する:
      - テーブルを作成する際に、PARTITIONED BY によってパーティション化されるカラムを指定し、TBLPROPERTIES を使ってパーティション射影のプロパティを設定します。
    - 既存のテーブルにパーティション射影のプロパティを追加する:
      - すでに存在するテーブルにも ALTER TABLE コマンドでパーティション射影プロパティを追加することが可能です。
    - 例)
    - ```CREATE EXTERNAL TABLE logs (
              event string,
              user_id string
          )
          PARTITIONED BY (year string, month string, day string)
          STORED AS PARQUET
          LOCATION 's3://my-bucket/logs/'
          TBLPROPERTIES (
              'projection.enabled'='true',
              'projection.year.type'='integer',            -- year パーティションの型
              'projection.year.range'='2020,2023',         -- year の値の範囲
              'projection.month.type'='integer',           -- month パーティションの型
              'projection.month.range'='1,12',             -- month の値の範囲
              'projection.day.type'='integer',             -- day パーティションの型
              'projection.day.range'='1,31',               -- day の値の範囲
              'storage.location.template'='s3://my-bucket/logs/year=${year}/month=${month}/day=${day}/'  -- S3上のパス
          );
      ```

- Amazon Redshift ストリーミング取り込み: Amazon Kinesis Data Streams から直接データを取り込めます。さらにマテリアライズドビューを使用して、迅速に結果をダッシュボードに表示できます。

## 10.

- Amazon Managed Service for Apache Flink （旧日名称 Amazon Kinesis Data Analytics ）を利用することで、リアルタイムでのデータストリーム処理ができます。Apache Flink のコネクタを使用して、データを Amazon Timestream データベースにき込むことができます。この時系列データベースは、リアルタイム処理と低レイテンシーでのクエリ実行に最適化されており、データの遅延を最小限に抑えることができます。また、Amazon Timestream からデータを取得し、Grafana を使用してダッシュボードを作成することで、データの視覚化とリアルタイム分析を効率的に行うことができます。この方法は、製造施設の大型スクリーンに業務効率のリアルタイムビューを提供し、最低レイテンシーでのデータ表示と分析の要件を満たします。
- Amazon Managed Service for Apache Flink: Amazon Managed Service for Apache Flink では、Apache Fink を使用してストリーミングデータをリアルタイムで変換および分析し、アプリケーションを他の AWS サービスと統合できます。
- Amazon Timestream: データ収集、視覚化、および機械学習のための一般的なサービスと統合されているため、既存、および新しいアプリケーションでの使用が簡単です。例えば、AWS IoT Core、Apache Flink 向けの Amazon Managed Service for Apache Flink、AWS IoT Greengrass、および Amazon MSK から直接データを取り込むことができます。

- インターリーブ:
  - 複数の列を同時に重視してデータをソートする方法です。通常、ソートキーは特定の 1 つの列を基準にしてデータを並べますが、インターリーブされたソートキーでは、複数の列に対して平等に重要度を持たせてソートします。この方法によって、複数の異なる列を使ったクエリを効率的に実行できるようになります。
  - たとえば、Orders というテーブルに「注文日」「顧客 ID」「商品カテゴリ」という 3 つの列があり、それぞれをソートキーにするとします。インターリーブされたソートキーを使うことで、これら 3 つの列がどのクエリでも重要視されるようにデータが並べられます。つまり、どの列を使って検索しても、全体的に効率的な検索ができるようになります。
  - ただし、このような並び替えは時間が経つにつれ効率が落ちてくることがあります。特にデータの更新や削除が頻繁に行われる場合には、データの並び順が崩れてしまい、パフォーマンスが低下する可能性があります。そこで「VACUUM REINDEX」コマンドを使って、再びデータを整列し、効率的にクエリを実行できるようにする必要があります。
- VACUUM REINDEX: 特にインターリーブされたソートキーを持つテーブルに効果的で、削除された行のスペースを回収し、テーブル内のデータの並び順を再構築することで、データベースのパフォーマンスを改善します。

- Amazon EMR Graviton インスタンス: ARM ベースの独自設計で、コスト効率とパフォーマンスの両面で従来の x86 プロセッサに比べて優れている。

- AWS Glue Python shell: 100MB 未満のファイル処理であれば、pandas で OK

- QuickSight:
  - Athena と簡単に統合でき、Athena のクエリ結果をダッシュボードやレポートとして視覚的に表現できます。この組み合わせは、特に S3 に保存されたデータに対するデータレイク型の分析や、ビジネスインテリジェンスのニーズに応じた迅速な意思決定に役立ちます。
  - QuickSight から、Athena をデータソースとして接続します。QuickSight から Athena にクエリを発行することで、Athena のクエリ結果を直接 QuickSight に取り込むことができます。
  - QuickSight では、Athena によって抽出されたデータを視覚化し、インタラクティブなダッシュボードやレポートを作成することが可能です。
  - QuickSight の SPICE（Super-fast, Parallel, In-memory Calculation Engine） を使用して、Athena から取り込んだデータをメモリ内にキャッシュし、非常に高速なデータ分析を行います。
  - SPICE を使うことで、Athena に毎回クエリを発行せずとも、インメモリでデータを効率的に分析でき、クエリ実行の負荷や時間を削減できます。
