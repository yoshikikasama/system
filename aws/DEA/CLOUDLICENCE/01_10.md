# CloudLicence

## 01.

- Apache Hive メタストア　 → 　 AWS Glue Data Catalog に移行できる。

- AWS Lambda と RDS のプライベート通信:

  - Lambda 関数にも RDS にも同じ SG を設定し、SG の設定で同じセキュリティグループからの通信を許可する。
  - Lambda 関数と RDS はどちらも同じ MySecurityGroup に所属しているため、この自己参照ルールにより、セキュリティグループに属するリソース間で安全に通信できるようになります。
  - セキュリティグループはデフォルトで全ての通信をブロックします。したがって、Lambda から RDS への通信が必要な場合は、「どこからの通信を許可するか」を明示的に設定する必要があります。自己参照ルールを設定しないと、同じセキュリティグループ内であっても、その通信は許可されません。
    - 例えば、RDS が使うポート 3306（MySQL の場合）へのアクセスを許可するためのルールを、送信元（ソース）として MySecurityGroup 自体を指定します。

- AWS Glue DataBrew: Excel のような GUI 上でデータを加工するサービス。
- Redshift Data API: Redshift にデータをロードするための手段を提供。リアルタイムデータアクセス可能。
- AWS Data Exchange: サードパーティーのデータセットを検索、購入、そして使用するためのサービスです。このサービスを利用することで、ユーザーは API 呼び出しを通じて簡単にデータセットにアクセスし、これを自身のアプリケーションや分析ツールと統合することができます。
- AWS Glue FLEX 実行クラス: ジョブを実行するために必要なリソースを動的にスケーリングする。緊急ではないデータ統合ワークロード（本番前のジョブ、テスト、データロードなど）のコストを最大 35%削減できる柔軟な実行ジョブクラスです。Glue には、スタンダードとフレキシブルの 2 つのジョブ実行クラスがあります。スタンダード実行クラスは、ジョブの高速起動と専用リソースを必要とする、時間に敏感なワークロードに最適です。フレキシブル実行クラスは、開始時刻と完了時刻が異なる可能性がある緊急でないジョブに適しています。AWS Glue Flex は、時間に左右されないワークロード（夜間のバッチ ETL ジョブ、週末のジョブ、1 回限りの一括データインジェストジョブなど）のコストを削減できます
- AWS Glue FindMatches ML 変換: 一致するレコードを特定するカスタム機械学習変換である。AWS Glue でデータセット (識別子のないものを含む) 全体から、一致するレコードを検索できます。
- AWS DataSync: 主にオンプレミスと AWS 環境間、または AWS サービス間でのデータ転送を自動化するサービス
- Redshift Spectrum:
  - ![image](https://github.com/user-attachments/assets/1eceb24d-5d29-46ec-8a85-bde3a148603d)
- Apache Parquet 形式: 列指向フォーマットであり、必要な列のみに対して効率的にクエリを実行し、コスト効率が高い。Amazon Athena は列指向のクエリエンジンであり、Apache Parquet 形式のデータを使用すると、ファイル全体をスキャンする代わりに必要な列のみを読み込むことができます。これにより、データ転送量が削減され、クエリ実行時間が短縮されます。さらに、Parquet はデータの圧縮とエンコーディングをサポートしており、ストレージコストの削減にも寄与します。
- Apache Avro, csv : 行指向フォーマット。クエリが特定の列のみに対して実行される場合でも、ファイル全体をスキャンする必要がある。

## 02.

- Redshift 同時スケーリング:
  - 有効にすることで読み取りと香き込みのキャパシティを動的に拡張できます。具体的には、Amazon Redshift のワークロード管理（WLM）は、クラスター内のリソースを効率的に配分するための機能であり、キューレベルで同時実行スケーリングを有効にすることで、ユーザー定義のキューの待機時間が一定以上になった場合に、自動的に追加のコンピューティングリソースをプロビジョニングします。これにより、需要の変動に応じて読み取りと香き込みのキャパシティを自動で拡張し、クラスターのパフォーマンスを最適化することができます。この機能は、特に大規模なデータウェアハウス操作において、性能の向上とリソースの効率的な利用を実現します。
  - 同時実行スケーリングが有効になっている場合、Amazon Redshift は自動的に新たなクラスターキャパシティーを追加し、読み取りと書き込み両方でクエリの増加に対応します。クエリをメインクラスターと同時実行スケーリングクラスターのどちらで実行しても、ユーザーには最新のデータが表示されます。WLM キューを設定することで、どのクエリを同時実行スケーリングクラスターに送するかを管理できます。同時実行スケーリングを有効にすると、対象となるクエリはキュー内に待機することなく、同時実行スケーリングクラスターに送信されるようになります。
- Boto3 AWS Glue create_partition API: Amazon S3 にデータを書き込む際に Boto3 AWS Glue create_partition API を呼び出すことで、AWS Glue Data Catalog が S3 ストレージと即時に同期できます。これにより、データエンジニアは新しいパーティションが追加されるたびに手動で介入することなく、AWS Glue Data Catalog が常に最新の状態を保つことを保証できます。この方法は、レイテンシーを最小限に抑えることができます。

- AWS Glue ワークフロー: データの ETL（抽出、変換、ロード）プロセスを自動化し、管理するためのサービスであり、複数の ETL ジョブと前提条件を一つのワークフローとして組み合わせることができます。この機能により、Microsoft SQL Server からデータを抽出し、変換して Amazon S3 バケットにロードするプロセスを簡単に設定できます。さらに、データパイプラインの調整が必要な場合にも、AWS Glue ワークフローを使用することで、複雑なスクリプトや外部の調整ツールを用いずに、プロセスの管理と調塾を行うことができるため、コストと労力の両面で効率的です。AWS Glue では、ワークフローを使用して、複数のクローラ、ジョブ、トリガーが関与する複雑な ETL（抽出、変換、ロード）アクティビティを作成および視覚化できます。各ワークフローは、そのすべてのジョブとクローラーの実行と監視を管理します。ワークフローは各コンポーネントを実行すると、実行の進行状況とステータスを記録します。これにより、より大きなタスクの概要と各ステップの詳細が得られます。AWS Glue コンソールは、ワークフローをグラフとして視覚的に表現します。
- AWS Step Functions と Amazon Managed Workflows for Apache Airflow （Amazon MWAA）: 複数の AWS サービスや外部サービス間でのタスクの調整や自動化に特化したサービスです。これらのサービスは、ワークフローの管理やタスク間の依存関係の設定などを効率的に行うことができますが、データの ETL （抽出、変換、ロード）を直接実行する機能は持っていません。ETL プロセスを実行するには、AWS Glue や他のデータ処理サービスを組み合わせて使用する必要があります

- Amazon EBS: ボリュームタイプの変更はデータの複製や移行を伴わずにアップグレードできる。(例: gp2 → gp3)
- AWS Lake Formation:

  - [lake formation 説明](https://qiita.com/sot528/items/8a4c3adf9ba5c2da3fa9)
  - ![image](https://github.com/user-attachments/assets/4d79f998-ec2c-41a4-b2e5-2ed2f08e1f2a)

  - AWS でデータレイクを構築・運用するためのマネージドサービス
  - 実体は、ほぼ AWS の各種サービスをラップしたもの(Glue, IAM, S3, etc..)
  - データレイク専用にアクセス制御を行うために、IAM とは別に独自の権限管理機構を持つ
  - Lake Formation を使用して AWS アカウント間でピアツーピアのデータ共有を可能にします。
    - データ コンシューマーがデータセットへのアクセスを要求します。
    - データ所有者は、アクセス要求を承認することでアクセスを許可します。データ所有者は、アクセス要求の承認をデータ管理者に委任できます。
    - アクセス要求が承認されると、プロデューサー アカウントの Lake Formation 内の特定のデータセットに新しい権限が追加されます。
  - Amazon S3 のパスを AWS Lake Formation のロケーションとして登録することにより、データの組織化とアクセスの管理を効率化します。この方法により、データエンジニアリングチームは、必要なデータへのアクセスを正確に制御し、人事部門がそのリージョン内の従業員のみのレコードにアクセスできるようにすることができます。
  - データレイクへの Amazon S3 ロケーションの追加
    - Amazon S3 のロケーションをテータレイク内のストレージとして追加するには、そのロケーションを AWS Lake Formation に含録します。その後、Lake Formation のアクセス許可を使用して、この場所を指す AWS Glue データ カタログ オブジェクトと、その場所の基礎となるデータに対するきめ細かいアクセス制御を行うことができます。
  - AWS Lake Formation のきめ細かなアクセス制御を有効にすることで、各リージョンのデータに対するきめ細かなアクセス制御が可能になります。データフィルターを追加することで、各人事部門が自部門のリージョン内の従業貝レコードのみにアクセスできるように制限し、この要件を満たすために必要な運用上のオーバーヘッドを最小限に抑えることができます
  - ![image](https://github.com/user-attachments/assets/0d22378a-3372-4f4c-a4c8-8e89dfd742e7)
  - ![image](https://github.com/user-attachments/assets/0a4f347a-692b-4c0d-a35b-2e2b5a664483)
  - 機能:
    - AWS Glue の拡張機能。
      - ![image](https://github.com/user-attachments/assets/6b336aa6-72db-4ae0-95f0-76597a4eb27a)
    - データ取込みと構造化 → ブループリント：汎用的なデータ取り込みテンプレートを使い、自動的なデータ取り込みと構造化を実現。ブループリント上で必要なパラメータを入力し Lake Formation のワークフローを作成することで、Glue のトリガー、ワークフロー、クローラー、ジョブを自動で生成します。
    - セキュリティ＆コントロール → パーミッション：SQL ライクな Grant/Revoke でシンプルなアクセス制御を実現。Glue のアクセス許可モデルは IAM を介してアクセスを許可するのに対して、Lake Formation は IAM を使ったアクセス制御を簡単に設定できる。tag を使ってグルーピングされたものに対して、列や行単位でアクセス管理が簡単にできる。
    - 協調&利用 → データカタログ：スキーマやロケーションなどのデータのメタ情報を管理し、ファセット検索で探したいデータセットを探しやすく。Glue データカタログと統合。
    - 監視&監査 → ロギング：コンソールによる直近のアクティビティの詳細を確認

## 03.

- AWS Lambda の同時実行数
  - Lambda での同時実行とは、関数が同時に処理できるリクエストの数のことです。利用できる同時実行コントロールには、次の 2 種類があります。
  - 予約済み同時実行：予約済み同時実行は、関数の同時インスタンスの最大数を保証します。ある関数が予約済同時実行数を使用している場合、他の関数はその同時実行数を使用できません。関数に対して予約済み同時実行を設定する場合には料金はかかりません。
  - プロビジョニング済み同時実行：プロビジョニング済み同時実行は、リクエストされた数の実行環境を初期化して、関数の呼び出しに即座に応答する準備をします。プロビジョニングされた同時実行を設定すると、AWS アカウントに課金が発生することに注意してください。
- コールドスタート: Lambda が関数のインスタンスを割り当てると、ランタイムは関数のコードをロードし、ハンドラの外部で定義された初期化コードを実行します。コードと依存関係が大きい場合、または初期化中に SDK クライアントを作成する場合、このプロセスには時間がかかることがあります。関数がしばらく使用されていない場合、スケールアップする必要がある場合、または更新する場合、Lambda は新しい実行環境を作成します。これにより、新しいインスタンスによって処理されるリクエストの部分は、残りの部分よりもレイテンシーが長くなります。
- 呼び出しの増加前にプロビジョニングされた同時実行数を割り当てることにより、すべてのリクエストが、短いレイテンシーで、初期化されたインスタンスによって処理されるようにできます。プロビジョニングされた同時実行で設定された Lambda 関数は、一貫性のあるスタートアップレイテンシーで実行されるため、インタラクティブなモバイルまたはウェブバックエンド、レイテンシーの影響を受けやすいマイクロサービス、同期的に呼び出される API の構築に最適です。Lambda は Application Auto Scaling と統合するので、スケジュールに従って、または使用率に基づいて、プロビジョニングされた同時実行数を管理できます。

- Redshift STL システムビュー: システムの履歴を提供するために Amazon Redshift ログファイルから生成されます。これらのファイルは、データウェアハウスクラスター内の各ノードに置かれます。STL ビューは、ログから取得した情報を、システム管理者が使用できる形式のビューにしたものです。STL システムビューは 7 日間のログ限歴を保持します。ログの保持は、すべてのクラスターサイズとノードタイプで保証されており、クラスターワークロードの変化による影響を受けません。また、ログの保持は、クラスターの一時停止などのクラスターの状態からも影響を受けません。クラスターが新しい場合のみ、ログ履歴が 7 日未満になります。ログの保持にお客様によるアクションは不要ですが、ログデータを 7 日以上保持する場合は、ログを定期的に他のテーブルにコピーするか、Amazon S3 にアンロードする必要があります。
- STL_ALERT_EVENT_LOG - クエリ実行中にクエリオプティマイザが特定した潜在的なパフォーマンスの問題を記録します。これにより、データエンジニアは長時間実行されるクエリに起因するパフォーマンスの問題を効果的に識別し、対処することができます。
- STL PLAN INFO: クエリプランに関する情報を提供
- STL QUERY METRICS: クエリのパフォーマンスメトリクスを提供
- STL USAGE_CONTROL: リソース使用量を制御するための設定を記録するために使用される。

-　 AWS DataSync: オンプレミスのデータセンターから Amazon S3 バケットへのデータ転送を自動化し、スケジュール設定が可能であり、データの定期的な更新が要求される状況に最適。AWS Datasync ロケーション間で定期的にデータを転送するようにタスクを設定できます。スケジュールされたタスクは、最低 1 時間の間隔で設定した頻度で自動的に実行されます。

- Amazon S3 Transfer Acceleration: インターネット経由で　 Amazon S3 へのファイル転送を加速する機能。大量データの転送に有効だが、データ更新の自動化やスケジューリングには対応していない。
- Athena のワークグループ: ワークグループと IAM ポリシーを使用することで、クエリプロセスとクエリ履歴へのアクセスを分離する権限制御が実現できる。具体的には、Amazon Athena のワークグループをユースケースごとに作成することで、クエリ実行環境を分離します。さらに、ワークグループにタグを適用し、これらのタグを基にした IAM ポリシーを作成することで、適切なユーザー、チーム、またはアプリケーションが特定のワークグループへのアクセスを制御できます。この方法により、同じ AWS アカウント内の異なるエンティティ間でクエリプロセス とクエリ履歴へのアクセスを効果的に分離できます
- Athena のワークグループには、以下の特徴があります。
  - デフォルトでは、各アカウントにはプライマリワークグループがあり、デフォルトのアクセス許可により認証されたすべてのユーザーがこのワークグループにアクセスできます。プライマリワークグループは削除できません。
  - 作成した各ワークグループには、そこで実行されたクエリについてのみ保存されたクエリおよびクエリ履歴が表示され、アカウントのすべてのクエリは表示されません。これにより、アカウント内の他のクエリからクエリが分離され、自分が保存したクエリおよび履歴内のクエリを見つけることがより効率的になります。
  - ワークグループを無効にすると、有効にするまでクエリは実行されなくなります。無効なワークグループに送信されたクエリは、再び有効にするまで失敗します。
  - アクセス権限がある場合は、空のワークグループと、保存したクエリを含むワークグループを削除できます。この場合、ワークグループを削除する前に、保存されたクエリが削除されることを Athena が告します。他のユーザーがアクセスできるワークグループを削除する前に、そのユーザーが引き続きクエリを実行できる他のワークグループにアクセスできることを確認してください。
  - ワークグループ全体の設定をセットアップし、ワークグループで実行されるすべてのクエリでその使用を強制することができます。設定には、Amazon S3 にあるクエリ結果、予測されるバケット所有者、暗号化、クエリ結果バケットに昔き込まれたオブジェクトのコントロールが含まれます。
  - ![image](https://github.com/user-attachments/assets/a8cbc55a-0694-455b-bb52-42a670defe08)

## 05.

- AWS Glue Data Catalog: AWS の中央メタデータリポジトリとして機能し、構造化および半構造化データソースのメタデータを一元管理する機能を提供します。このサービスは、Amazon RDS や Amazon Redshift などの構造化ソース、そして Amazon S3 に保存された JSON ファイルや.xml ファイルなどの半構造化ソースのメタデータをカタログ化できます。AWS Glue クローラーは、これらのデータソースに自動的に接続し、メタデータの変更を検出してデータカタログを更新します。クローラーを定期的に実行することによって、データカタログは常に最新の状態に保たれます。
- ![image](https://github.com/user-attachments/assets/5d384837-a125-433d-bc66-d0e1d70d75f1)

- Kinesis Data Streams を使用したクロスアカウントクロスリージョンログデータ共有:

- CloudWatch サブスクリプションフィルター: 特定のログストリームからリアルタイムでログデータを別のサービスに転送するために使用されます。サブスクリプションフィルターを使うことで、CloudWatch Logs に保存されるログを Amazon Kinesis Data Streams、Amazon Kinesis Data Firehose、または AWS Lambda にリアルタイムで転送できます。本番アカウントの CloudWatch Logs グループでサブスクリプションフィルターを作成し、そのログをセキュリティアカウントにある Kinesis Data Streams に送る設定を行う。フィルターを使って、特定の条件に合致するログだけを転送することが可能です。

- Amazon Athena のフェデレーテッド・クエリ: AWS Lambda で実行されるデータソースコネクタを使用します。データソースコネクタは、ターゲットデータソースと Athena 間での変換を実行できるコードです。コネクタは、Athena のクエリエンジンの拡張機能として考えることができます。事前構築された Athena データソースコネクタは、Amazon CloudWatch Logs、Amazon DynamoDB、 Amazon DocumentDB、 Amazon RDS、および MySQL や Apache 2.0 ライセンスに基づく PostgresQL などの JDBC 準拠のリレーショナルデータソースといったデータソース用のものです。Athena Query Federation SDK を使用してカスタムコネクタを記述することもできます。データソースコネクタを選択し、設定し、アカウントにデプロイするには、Athena および Lambda コンソールまたは AWS Serverless Application Repository を使用できます。データソースコネクタをデプロイした後、コネクタは SQL クエリで指定できるカタログに関連付けられます。複数のカタログの SQL ステートメントを組み合わせて、1 つのクエリの範囲に複数のデータソースを入れることができます。
  - ![image](https://github.com/user-attachments/assets/0663368e-4d7b-431e-bec8-e3931361b713)
- フェデレーテッド（Federated）: 直訳すると「連合」や「統合」という意味を持ちます。IT やデータベースの分野では、「フェデレーテッド」は、複数の異なるシステムやデータソースを統合して、あたかも一つのシステムのように動作させる概念を指します。

## 06.

- Redshift:

  - Redshift は、クラスタ ＞ ノード ＞ スライス　の構成
    - 各ノードは並列で動く
    - データは各スライスに分割して持つ
    - データが偏っちゃうと働かないノードがでてくるのでもったいない
    - 別のノードが持っているデータが必要になると、データを再分散しないといけないので時間がかかる
  - ![image](https://github.com/user-attachments/assets/21fb90a7-afdc-4fa2-a99f-d77a35c8fe76)
  - ゾーンマップ
    - Amazon Redshift はカラムごとに「ブロック」単位でディスクにデータを格納。１ブロック＝１ MB
    - ブロック内の最小値と最大値をメモリに保存
    - 不要なブロックを読み飛ばすことが可能
  - ソートキー
    - カラムのデータをあらかじめソートしておけば、ゾーンマップによる読み込みブロックの絞り込みを効果的に行うことが可能
    - クエリで頻繁に絞り込みを行う列をソートキーとして指定することで、データロードやメンテナンス時にデータをソートしておくことができる
  - 分散スタイル
    - AUTO 分散: Amazon Redshift はテーブルデータのサイズに基づいて最適な分散スタイルを割り当てます。例えば、AUTO 分散スタイルが指定された場合、Amazon Redshift ではまず、ALL 分散スタイルを小さなテーブルに割り当てます。テーブルが大きくなると、Amazon Redshift は分散スタイルを KEY に変更し、プライマリキー (または複合プライマリキーの列) を分散キーとして選択する場合があります。テーブルが大きくなり、分散キーに適した列がない場合、Amazon Redshift は分散スタイルを EVEN に変更します。
    - EVEN 分散: リーダーノードは、特定の列の値に含まれている値にかかわらず、ラウンドロビン方式によって複数のスライス間で行を分散させます。テーブルが結合に参加しない場合は、EVEN ディストリビューションが適切です。
    - キー分散: 行の分散は、特定の列に含まれている値に従って行われます。リーダーノードは、複数の一致する値を同じノードスライスに配置します。結合キーに基づいてテーブルのペアを分散する場合、リーダーノードは、結合列に含まれている値に従って行をスライスにコロケーションします。このようにして、共通の列から一致する値が物理的に一緒に保存されます。
    - ALL 分散: テーブル全体のコピーがすべてのノードに分散されます。EVEN 分散または KEY 分散によってテーブルの一部の行のみが各ノードに配置されている場合、ALL 分散を行うと、テーブルが関与しているあらゆる結合ですべての行が確実にコロケーションされるようになります。
    - ![image](https://github.com/user-attachments/assets/8860aa0a-9d20-4642-bb2f-c90188354cc8)
  - フェデレーテッドクエリ
    - RDS/Aurora の PostgreSQL/MySQL に対して直接クエリ可能
  - Amazon Redshift Data Sharing
    - Redshift クラスター間でセキュアに簡単にデータを共有することが可能
  - 結果セットのキャッシュ
    - ![image](https://github.com/user-attachments/assets/e7513dc5-53c0-4317-9c18-f9da61c55030)

- Materialized View

  - ビューは参照の度に SQL を実行するのに対し、マテリアライズド・ビューは保持している SQL の結果を返却するため、複雑な集計処理に際してはマテリアライズド・ビューが圧倒的なパフォーマンスを発揮します。
  - マテリアライズド・ビューにできて、バッチでは実現できないこと、それは変化点のみの更新（高速リフレッシュ）です。厳密にいうとこれもバッチでできないことはありません。更新日時や更新済みフラグなどを用いて変化点のみを更新することは可能です。ただ、あるデータが「変化したかどうか」をムダな判定処理が入るのも事実です。変化点のみに着目した更新が可能となるため、例えば大量データの集計処理であっても集計結果を高速に算出することが可能です。

- EBS: ルートボリュームに設定すると EC2 インスタンス終了時にデータが消えるため、2nd としてアタッチして、保存したいデータは EBS に保存する。
- Athena:

  - Athena は、AWS Glue の一機能である Glue Data Catalog（メタデータストア） と統合しています。Athena を利用して分析をしているつもりでも、その裏側では S3 データに関するテーブルメタデータの保存と取得に AWS Glue Data Catalog を使用しています。
  - ![image](https://github.com/user-attachments/assets/c4c81644-d2bf-478a-8ba7-9d9258e84b3b)

- AWS Glue DataBrew:
- AWS Glue スキーマ変更:
- AWS Glue Data Catalog:
- AWS Glue Crawler:
  - Glue Data Catalog にメタデータを作成するプログラムです。S3 のデータからデータベースとテーブルのスキーマを自動的に推論し、関連するメタデータを AWS Glue Data Catalog に保存します。

## 07.

- Amazon AppFlow: サードパーティーの Saas アプリケーションから Amazon S3 へデータを直接転送し、それを Amazon Redshift に連携することで、データに基づいた分析を実行できます。この方法は、運用上のオーバーヘッドを最小限に抑えつつ、必要なデータ収集と分析の要件を満たします。Amazon AppFlow はノーコードで簡単に設定でき、複雑なデータパイプラインをコーディングする必要がないため、メディア企業が運用の複雑さを増すことなく、効率的にデータを収集し分析することを可能にします

- 変更されたデータを最もコスト効率よくキャプチャできるソリューション:
  - オープンソースのデータレイク形式を利用することで、大規模な半構造化データファイルに対して効率的に変更データキャプチャ （CDC）を実行し、Amazon S3 に保存されたデータソースを効率的に統合し、新しいデータを追加して既存のデータを更新します。この方法は変更されたデータのみを処理するため、ストレージと計算のコストを最小限に抑えることができ、コスト効率の良いデータの変更管理を実現します。
  - 処理フロー
    - 1.データソースが毎日完全なスナップショットを JSON ファイルとして生成し、Amazon S3 にアップロードします。
    - 2.CDC 操作を実行し、前回のスナップショットと今回のスナップショットを比較して変更されたデータを特定します。
    - 3.オープンソースのデータレイク形式（例 ：Apache Hudi, Delta Lake, Apache Iceberg）を使用して、特定された変更データをデータレイクに取り込みます。
    - 4.新しいデータは追加され、既存のデータは更新されます。
- 変更データキャプチャ （CDC）: データベース内の変更（挿入、更新、削除）を追跡し、これらの変更をデータレイクに取り込むための技術です。CDC は、データソースの完全なスナップショットを JSON ファイルとして Amazon S3 に保存し、その変更分をデータレイクに反映させるために使用されます。

- オープンソースのデータレイク形式

  - Apache Hudi： データレイクの変更データキャプチャとデータのバージョン管理を提供します。データのき込みと読み取りのパフォーマンスが高く、増分データを効率的に処理します。
  - Delta Lake： データの ACID トランザクション、スケーラブルなメタデータ処理、および変更データキャプチャをサポートするオープンソースプロジェクトです。これにより、信頼性の高いデータレイクを構築できます。
  - Apache Iceberg： データのスナップショットや増分処理を効率的に行うためのテーブル形式を提供します。大規模なデータセットの処理に適しています

- DynamoDB
  - プロビジョニング + AWS Application Auto Scaling: 予測可能なリクエスト量 + 一時的な負荷。コスト低。
  - オンデマンド: 予測不可能なリクエスト量。コスト高

-　 AWS DMS:

- データベースを AWS に迅速かつ安全に移行するのに役立ちます。移行中でもソースデータベースは完全に利用可能な状態に保たれ、データベースを利用するアプリケーションのダウンタイムは最小限に抑えられます。 AWS Database Migration Service は、広く普及しているほとんどの商用データベースとオープンソースデータベース間のデータ移行でご利用いただけます。
- Oracle から Oracle のような同種のデータベース間の移行も、Oracle または Microsoft SQL から Amazon Aurora といった異なるデータベースプラットフォーム間の移行もサボートされます。また、AWS Database Migration Service を使用すると、サポートされているあらゆるソースからサポートされているあらゆるターゲットに、低レイテンシーで継続的にデータをレプリケートすることができます。例えば、複数のソースから Amazon S3 にレプリケートすることで、高可用性のスケーラブルなデータレイクソリューションを構築することができます。また、Amazon Redshift にデータをストリーミングすることで、データベースをペタバイト規模のデータウェアハウスに統合することもできます。
- AWS DataSync: オンプレミスのファイルシステムと AWS 間でのデータの同期を行うシステム。DB 間ではない。
- Amazon S3 Intelligent-Tiering:
  - 高頻度アクセス階層（自動）: S3 Intelligent-Tiering で作成されたオブジェクトや S3 Intelligent-Tiering に移行したオブジェクトのライフサイクルを開始するデフォルトのアクセス階層です。オブジェクトは、アクセスされている限り、この階層に残ります。高頻度アクセス階層は、低レイテンシーと高スループットのパフォーマンスを提供します。
  - 低頻度アクセス階層 (自動): オブジェクトが 30 日間連続してアクセスされない場合、オブジェクトは低頻度アクセス階層に移行します。低頻度アクセス階層は、低レイテンシーと高スループットのパフォーマンスを提供します。
  - アーカイブインスタントアクセス階層 (自動): オブジェクトが 90 日間連続してアクセスされない場合、オブジェクトはアーカイブインスタントアクセス階層に移行します。アーカイブインスタントアクセス階層は、低レイテンシーと高スループットのパフォーマンスを提供します。
  - アーカイブアクセス階層（オプション）: S3 Intelligent-Tiering では、非同期的にアクセスできるデータのためにアーカイブアクセス層をアクティブ化するオプションが提供されます。アクティブ化された後、アーカイブアクセス階層は 90 日間以上してアクセスされなかったオブジェクトを自動的にアーカイブします。アーカイブの最終アクセス時間は、最大 730 日間まで延長できます。アーカイブアクセス階層は、S3 Glacier Flexible Retrieval ストレージクラスと同じパフォーマンスです。
  - ディープアーカイブアクセス階層（オプション）: S3 Intelligent-Tiering では、非同期的にアクセスできるデータのために ディープアーカイブアクセス階層をアクティブ化するオプションが提供されます。アクティブ化後、ディープアーカイブアクセス階層は 180 日間連続してアクセスされなかったオブジェクトを自動的にアーカイブします。アーカイブの最終アクセス時間は、最大 730 日間まで延長できます。ディープアーカイブアクセス階層のパフォーマンスは、S3 Glacier Deep Archive ストレージクラスと同じです。
