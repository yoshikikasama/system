# CloudLicence

## 11.

-　 S3 ストレージクラス比較表

- ![image](https://github.com/user-attachments/assets/2786bd2a-6abd-48e3-85b1-eb46828b61b9)

## 12.

- AWS Glue ジョブのブックマーク機能: AWS Glue ではジョブの実行による状態情報を保持することで、ETL ジョブの以前の実行中にすでに処理されたデータを追跡します。この継続状態の情報は ジョブのブックマーク と呼ばれています。ジョブのブックマークは、AWS GI
  ue で状態情報を保持して、古いデータを再処理しない ために役立ちます。ジョブのブックマークを使用すると、スケジュールされた間隔で再実行する際に新しいデータを処理できます。ジョブのブックマークは、ソース、変換、ターゲットなど、さまざまなジョブの要素で構成されています。例えば、ETL ジョブが Amazon S3 ファイルで新しいパーティションを読み込むとします。AWS Glue は、そのジョブにより正常に処理されたのはどのパーティションなのかを追跡し、処理の重複およびジョブのターゲットデータストアにデータが重複するのを防ぎます

  - ![image](https://github.com/user-attachments/assets/81c896db-06cc-4d8e-b9f0-b7eeb025a7f8)
  - ![image](https://github.com/user-attachments/assets/20cbf9d2-6db6-4d18-8a10-65009be5a973)

- AWS DMS レピリケーション: データのレプリケーションを行う際に、レプリケーションインスタンスをデータ転送先 AWS アカウントの転送先リージョンに設定することが推奨されている。

## 13.

- Amazon Managed Service for Apache Flink のランダムカットフォレストによるリアルタイム異常検出
  - ランダムカットフォレスト (RCF) は、異常検出のユースケースで広く使用されているアルゴリズムの 1 つです。一般的には、入力データに対して RCF アルゴリズムを高いスループットで実行したい場合が多く、ストリーミングデータ処理フレームワークはそのようなケースで役立ちます。Amazon Managed Service for Apache Flink 上で RCF が使用可能になり、ストリーミングデータ処理において異常検出ができるようになりました。Apache Flink は、データストリーム上でリアルタイムでステートフルな計算を行うための人気のオープンソースフレームワークで、高いスループットで RCF を入力ストリームに実行するために使用できます。
  - アーキテクチャは、Amazon Kinesis Data Streams による入力データストリーム、Amazon Managed Service for Apache Flink による Flink ジョブ、Amazon Kinesis Data Streams による出力データストリームの 3 つのコンポーネントで構成されています。データフローに関しては、Python スクリプトを使用して異常な正弦波データを入力データストリームに配信し、そのデータを Flink ジョブで RCF によって処理し、結果の異常スコアを出力データストリームに配信します。
  - ![image](https://github.com/user-attachments/assets/c08270da-43f0-41e0-9a6c-e16103bdcb54)

## 14.

- Amazon S3 のサーバーサイド暗号化のオプション 二重層サーバーサイド暗号化 (DSSE-KMS)
  - FIPS 準拠のための CNSSP 15 と DAR CP バージョン 5.0 ガイダンスを満たすよう設計されており、データに複数層の暗号化を適用する規制要件に対応できます。米国国防総省（DoD）の顧客など、高度に規制された業界の厳格なセキュリティ基準も簡単に満たせます。
- AWS DMS を使用した継続的なレプリケーションのタスク

  - ソースデータストアから継続的な変更をキャプチャする AWS DMS タスクを作成できます。このキャプチャはデータの移行中に実行できます。サポートされているターゲットデータストアへの初めての (フルロード) 移行が完了した後に、継続的な変更をキャプチャするタスクを作成することもできます。このプロセスは継続的なレプリケーションまたは変更データキャプチャ (CDC) と呼ばれます。AWS DMS では、このプロセスを使用してソースデータストアの継続的な変更をレプリケートします。データベースエンジンのネイティブ API を使用してデータベースログへの変更を収集することが、このプロセスの仕組みです。
  - ほぼリアルタイムでレプリケートできる。

- Athena
  - EXPLAIN ANALYZE: クエリの実行プランと計算コストの詳細
  - EXPLAIN: クエリの実行プラン

## 15.

- Amazon QuickSight:
  - Query mode
    - 直接クエリ: データベースに対して SELECT ステートメントを直接実行する
    - SPICE:
      - 以前に高速なインメモリデータベースである SPICE ( Super-fast, Parallel, In-memory Calculation Engine ) に保存されていたデータに対して SELECT ステートメントを実行する
      - SPICE はカラムナストレージ、最新のハードウェアイノベーションによるインメモリ技術、自動コード生成を組み合わせて使用しており、大規模データに対してインタラクティブなクエリを実行し、迅速な応答を得ることができます。
      - SPICE を使うことにより結果がキャッシュされ、スケーリングも管理されるため、全体のパフォーマンスを向上させるための最適な方法となります。可能な限り SPICE を使用することをお勧めします。

## 16.

- AWS Glue ジョブのブックマークを有効にしても、ETL ジョブが以前に処理されたデータを再処理している場合
  - ジョブの実行スクリプトが次のコメントで終わることを確認します。`job.commit()`
  - このオブジェクトを含めると、 AWS Glue はジョブ実行のタイムスタンプとパスを記録します。同じパスでジョブを再度実行すると、 AWS Glue は新しいファイルのみを処理します。このオブジェクトを含まず、ジョブのブックマークが有効になっている場合、ジョブはすでに処理されたファイルと共に新しいファイルを再処理して、ジョブのターゲットデータストアで冗長化されます。
- AWS CloudTrail イベント

  - <img width="1245" alt="image" src="https://github.com/user-attachments/assets/eb64fa55-9941-4e77-97b9-b86252960f96">

- AWS Glue FindMatches ML(AWS Lake Formation FindMatches): 、機械学習アルゴリズムを利用して、「一意の識別子がない」場合でも類似レコードを自動的に照合します。FindMatches は、重複データやレコードの照合を容易にするために、データクレンジングやデータ統合の一環として使用されます。ユーザーは、FindMatches 変換をトレーニングすることで、手動で一部のデータの一致パターンを定義し、それをもとに他のレコードを照合させることが可能です。これにより、同社は重複レコードの統合や、クレンジングされたデータを Amazon S3 のデータレイクに保存し、Amazon Athena で効率的にクエリを実行できます。

- Amazon Managed Service for Apache Flink + Amazon Kinesis Data Firehose
  - 5 秒のバッファ間隔でデータを低レイテンシーで Amazon S3 バケットに配信できる
  - 具体的には、Amazon Managed Service for Apache Flink は、リアルタイムのストリーミングデータ処理に特化したフルマネージドサービスです。センサーからのデータは、Apache Flink を使ってリアルタイムで複雑な処理を施し、その後、Amazon Kinesis Data Firehose を使用して Amazon S3 に配備されます。このサービスの強力な点は、スケーラブルなデータ処理を自動的に行い、特定のビジネスロジックに従ってデータを迅速に処理できることです。
  - また、Amazon Kinesis Data Firehose は、処理されたデータを最小 1 秒のバッファ間隔で直接 Amazon S3 に配備可能です。この組み合わせにより、複雑なデータ処理が行われ、かつ短い間隔でデータが迅速に保存されるため、低レイテンシーでのデータ配が実現します。
- Amazon Kinesis Data Streams:
  - データを S3 に直接保存する機能はなく、Amazon Data Firehose のような追加のサービスが必要。
  - Kinesis Data Streams 自体は一時的なストレージとして機能し、データの保持期間は通常 24 時間から最大 7 日間 です。データはこの間にコンシューマーが取り出さない限り、自動的に削除されます。
