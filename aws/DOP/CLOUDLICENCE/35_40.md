# CloudLicence

## 35.

- CloudFormation で作成する Windows ベースの EC2 を既存の AWS Managed Microsoft AD ディレクトリのドメインに参加させる方法：

  - CloudFormation template を使用してタグを伝番させ、AWS::SSM::Association リソースで AWS-JoinDirectoryServiceDomain オートメーションランブックを関連づけることで、EC2 インスタンスを AWS Managed Microsoft AD ドメインに効率的に参加させることができる。
  - AWS::SSM::Association リソースは、AWS Systems Manager の一部である State Manager を用いて、インスタンスに定期的に適用する設定やポリシーを管理します。このリソースを使用すると、SSM ドキュメント（ランブックやコマンドドキュメントなど）を特定のインスタンスやリソースグループに自動的に適用できます。
  - AWS-CreateManagedWindowsInstanceWithApproval: AWS Systems Manager (SSM) オートメーション ドキュメントの一つです。このドキュメントは、承認プロセスを経た後に管理対象の Windows インスタンスを作成するために使用されます。主にガバナンスやコンプライアンス要件を満たすために、インスタンスの作成前に必要な承認を確保する場合に便利です。

- Firewall: 不正なアクセスや通信をブロックするためのネットワークセキュリティ対策に利用されるもの。
- AWS WAF:

  - web application firewall。web アプリレベルでのトラフィック制御、HTTP/HTTPS トラフィックの監視と制御に重点を置いている、
  - CloudFront, ALB, API Gateway が保護リソースとなる。

- AWS Network Firewall:

  - 概要:
    - VPC 単位でパケットの制御が可能。
    - ステートレスパケットフィルタ(5-tuple): 行きと帰りの通信を双方向で許可する必要があるフィルタリング方式。
    - ステートフルパケットフィルタ(5-tuple): 行きの通信のみを定義するだけで帰りの通信は自動的に許可されるフィルタリング方式。
    - ドメインの制御: aaa.jp のようなドメイン制御(ホワイトリスト/ブラックリスト)ができるフィルタリング方式。ドメインの制御はステートフル。
    - Suricata 互換の IPS: シグネチャ型(パターンベース)の IPS が実装可能。
    - 5-tuple: 送信元、送信元ポート番号、宛先 IP、宛先ポート番号、プロトコル番号の 5 つを指定して制御ルールを記載すること。
  - 構成要素:
    - ![Screenshot 2024-04-25 at 7 46 27](https://github.com/yoshikikasama/system/assets/61643054/4975e5aa-1415-4f9b-b253-b18e1abb6d7e)
    - ファイアウォール: AWS Network Firewall 構築時に指定したサブネットに Gateway Load Balancer のエンドポイントが作成されるため、検査対象の通信は一時的に VPC 外へ転送されることになる。
    - ファイアウォールポリシー: AWS Network Firewall で検査する動作を指定する。ファイアウォールルールグループの順序やアクションを管理する。
    - ファイアウォールルールグループ: ファイアウォールルールの順序やアクションを管理する。
      - ステートレスルール: アンマネージド
      - ステートフルルール: アンマネージド、マネージド

- Amazon GuardDuty: Amazon VPC フロー ログ、DNS ログ、 AWS CloudTrail 管理イベント、および AWS CloudTrail S3 データ イベントからのデータを分析および処理する継続的なセキュリティ監視サービスです。このデータに基づいて、GuardDuty は、AWS クラウドの脅威インテリジェンス フィード、シグネチャ、異常検出、機械学習を使用して分析と検出を提供します。

- AWS CodePipeline の承認アクションを管理し証跡を記録:

  - AWS CloudTrail の証跡を作成してログを S3 に配信する。
  - デプロイステップの前に Codepipeline の主導の承認アクションを作成する。承認者にはアクセス権を与えるポリシーを作成する。

- AWS CodePipeline: ソフトウェアのコンパイル、テスト、パッケージを自動化するためのサービス。ソース、ビルド、テスト、ビルド、承認に加えて呼び出しという合計 6 つのアクションが定義されており、それぞれのアクションごとに統合できるサービスが決まっている。

  - ビルドステージで runOrder2 を設定することで既存のビルドアクションに合わせて単体テストを実行するアクションを配置できる。1 つのステージで並行アクションを実行したければ RunOrder パラメータを変更する。
  - [AWS CodePipeline の超詳細解説](https://zenn.dev/tech4anyone/articles/c2105f60eba379#%E3%81%AF%E3%81%98%E3%82%81%E3%81%AB)
  - ![image](https://github.com/yoshikikasama/system/assets/61643054/de6a1cd4-1bf3-45a5-a1dd-d9e63626cc94)
  - ![image](https://github.com/yoshikikasama/system/assets/61643054/c63c2766-b906-42a8-9ac6-75cf85492b50)
  - ![image](https://github.com/yoshikikasama/system/assets/61643054/89cb5d86-efe2-44fe-a3c8-b78241ddb325)
  - ![image](https://github.com/yoshikikasama/system/assets/61643054/6f2e0099-eb5f-43d6-838e-25598ef94e0e)
  - ソース: 使うことが多いのは圧倒的に CodeCommit と ECR です。
  - ビルド: 基本は CodeBuild
  - テスト: 基本は CodeBuild
  - デプロイ: CodeDeploy
  - 承認: 必ず手動で行う必要がある

- AWS CodePipeline におけるアーティファクト: AWS CodePipeline ではアーティファクトを各ステージごとに作成することが可能です。作成されたアーティファクトは S3 に保存され、次のステージに受け継がれます。ただし、ビルドが不要でテストのみ実施するような場合は CodeBuild でアーティファクト不要です。必要に応じて、次のステージに渡したいものをアーティファクトとして S3 に保存してください。

  - ![image](https://github.com/yoshikikasama/system/assets/61643054/e3c07ac3-fbfd-4f8f-baa8-d499e7296053)
  - AWS CodePipeline における「アーティファクト」とは、パイプラインの各ステージを進む中で生成されるファイルやデータの集合を指します。これにはビルドの出力、設定ファイル、デプロイスクリプトなど、後続のステージで使用される情報が含まれています。
  - アーティファクトの役割と使われ方
    - 保存と転送: アーティファクトは通常、ビルドステージでコンパイルされたバイナリや実行可能ファイルなど、重要な成果物を含みます。これらは Amazon S3 に保存され、パイプラインの次のステージへと安全に転送されます。
    - ステージ間の連携: パイプラインのあるステージが完了すると、そのステージで生成されたアーティファクトは次のステージに自動的に引き継がれます。例えば、ビルドステージで生成されたバイナリファイルがテストステージに移され、テストが行われることがあります。
    - バージョン管理とロールバック: 各アーティファクトは S3 に保存される際に特定のバージョンとして管理されます。これにより、何か問題が発生した場合に以前のバージョンのアーティファクトへ簡単にロールバックできるようになります。
    - 自動化と効率化: アーティファクトの自動生成と転送により、手作業でのファイル移動やエラーの可能性が減少し、開発プロセスの自動化と効率化が図られます。

- AWS CodeDeploy: EC2, ECS, Lambda がデプロイ対象
- AWS CodeBuild:

  - フルマネージドなビルドサービスでソースコードのコンパイル、テスト実行、ソフトウェアパッケージの作成を実行。python 環境 install など。
  - imutable な環境のために個々のビルドを新規 Docker コンテナで実行。
  - buildspec.yml: CodeBuild の設定ファイル。
    - version: buildspec の version 指定
    - run-as: コマンドを実行する Linux ユーザー
    - env: 環境変数
    - proxy: プロキシサーバ設定
    - batch: バッチビルド設定。ビルドのジョブを順番に制御したり、同時実行を制御したりする。
    - phases: 実行するコマンド
    - reports: テストレポート作成。pytest などの実行結果を XML などで出力する。
    - artifacts: AWS CodeBuild の出力
    - cache: キャッシュ設定
  - ![image](https://github.com/yoshikikasama/system/assets/61643054/b9b8d889-d8e4-47b6-b034-b8450b4f01bc)

- Amazon ECR でクロスリージョンレプリケーション: ソースリポジトリに 1 回プッシュするだけで、複数の AWS アカウントおよび異なるリージョン間でコンテナイメージを簡単にコピーができます。また異なるリージョンにイメージをコピーすることにより、地理的分散ができるので、ディザスタリカバリの要件を満たすこともできます。

## 36.

- Amazon Timestream:

  - 高速かつスケーラブルなサーバレス時系列データベースサービスです。
  - ![image](https://github.com/yoshikikasama/system/assets/61643054/7efd8d9a-5f75-41c6-a1ba-171f0148976f)
  - 一番大きな単位としてデータベース (Database) があり、その中に複数のテーブル (Table) を持つことができ、そのテーブルの中に複数のタイムシリーズ (Time-Series) が入っています。タイムシリーズ (Time-Series) は時系列に並んだレコード (Record) のまとまりとなっていて、その中にディメンション（Dimension）と呼ばれる測定値を識別するための属性情報とメジャー (Measure) と呼ばれる測定値でテーブル内で一意に決まるものに対して、タイムスタンプごとにレコード (Record) と呼ばれる単一のデータポイントが記録されています。
  - Timestream table に対して毎日クエリを実行する際の最速クエリパフォーマンスについて:
    - バッチ処理書き込み: 複数のログイベントを 1 回の書き込み操作で処理することができ、ネットワーク遅延や書き込み回数によるオーーバーヘッドが軽減されるため、大量のデータ生成において効率的。
    - マルチメジャーレコード: 1 つのレコードに複数のメトリクスを含めることができる。これは 1/10 秒ごとに 5 つの異なるメトリクスを含むログイベントのように、多様なデータポイントを持つログを扱う場合に有効。サーバの CPU、メモリ量、スワップ、ディスクの使用状況を取得するシンプルな監視アプリケーションを作成しました。その際、4 つの測定値はシングルメジャーレコードのデータモデルを利用してそれぞれ別のレコードとして書き込んでいました。これをマルチメジャーレコードを使うと、4 つの測定値は同時に取得されるので、1 つのレコードとして格納され、まとめてクエリを実行する事が出来ます。マルチメジャーレコードを利用すると、テーブルに書き込まれるレコード数を削減する事が出来ます。以前はメジャー毎に 1 つずつ、計 4 レコードを書き込んでいましたが、今回のアップデートで同時に取得した 4 つのメジャー値を 1 行のマルチメジャーレコードとして書き込む事が出来ます。また、ストレージの使用料も減りますが、以前と同じ情報量を保持しています。処理するデータ量が減少する為、マルチメジャーレコードでクエリを実行する方が簡単で効率的です。例えば、結合を使用して同じクエリで複数のメジャーを取得する必要も無い為、全体的なコスト削減にもつながります。
      - ![image](https://github.com/yoshikikasama/system/assets/61643054/03ca76df-efd5-4b43-9d96-3c6f2b75bda1)
      - ![image](https://github.com/yoshikikasama/system/assets/61643054/3ca9c80b-f33e-463e-a1d7-03ab58be3e5a)
    - マグネティックストレージへの書き込み:データのライフサイクルを直近データのメモリストアと履歴データのマグネティックストアという 2 つのストレージ階層で管理しています。メモリストアからマグネティックストアへのデータの移動は設定したポリシーに応じて自動的に実施されます。以前はデータはメモリストアにしかロード出来ず、遅れて到着するデータを格納する為には、メモリストアの保持時間を拡張して対応する必要がありました。今回、直接マグネティックストアに書き込む事が出来るようになり、ストレージコストを削減する事が出来ます。時系列データを扱う場合には、遅れて到着するデータ (タイムスタンプが過去) についても考慮する必要があります。データが遅れて到着する理由は多数ありますが、制御出来ない事が大半です。例えば、アプリケーションやデバイスが停止したり、一時的にネットワークから切断された後、オンラインに戻った際に滞留していたデータが一度に送信するようなケースが考えられます。以前の Timestream ではメモリ保持期間外のデータを書き込むとエラーとして処理していた為、遅延したデータを取り込むには、テーブルのメモリストアの保持期限を増やす必要がありました。今回、テーブルの設定を有効化するだけで、遅れて到着したデータをマグネティックストレージに直接書き込めるようになりました。メモリストアに書き込む場合と同様に、WriteRecord API を利用すると、書き込むデータのタイムスタンプとテーブルのメモリストア保持期間に応じて、メモリ／マグネティックストレージのいずれかに自動的にルーティングされます。
    - メモリストアは頻繁にアクセスされる最新のデータのための高速アクセス層、磁気ストアは長期的なデータ保持とコスト効率の良いクエリパフォーマンスのために設計されている。

| 構成要素名                   | 構成要素説明                                               |
| ---------------------------- | ---------------------------------------------------------- |
| データベース (Database)      | テーブル (Table) を保持するコンテナ                        |
| テーブル (Table)             | タイムシリーズ (Time-Series) を保持するコンテナ            |
| タイムシリーズ (Time-Series) | ある属性値で説明できる、時系列に並んだレコードのまとまり   |
| ディメンション (Dimension)   | 測定値を識別するための属性情報セット                       |
| メジャー (Measure)           | 測定値 (名前 (measure_name) と値 (measure_value) のセット) |
| レコード (Record)            | 単一の時系列のデータポイント                               |

- CloudFormation カスタムリソース: CloudFormation から Lambda や SNS を動かし、その結果を返すことで作成完了とするリソースのことです。上の図では CloudFormation からスタックの作成が行われると、Lambda とそれに必要なロールを作成します。その後カスタムリソースと呼ばれるリソースが Lambda を実行して、その結果をカスタムリソースへ応答オブジェクトとして返却します。カスタムリソースは実体のないリソースで、テンプレート上で Lambda の実行と結果の取得を定義するためのリソースなので、AWS 上には何も作成されない点がちょっと分かりにくいポイントですね。Lambda からのレスポンスとなる応答オブジェクトは、JSON の形式で送信され Lambda の成功/失敗や失敗時の理由、CloudFormation テンプレートに返したい任意のデータなどが含まれます。

  - ![image](https://github.com/yoshikikasama/system/assets/61643054/85861c4e-fb8e-43ca-804a-1fa5b6731e5b)

- 買収した企業の　 AWS アカウント AWS Organizations に招待:

  - デフォルトでは、組織の一部として新規メンバーアカウントを作成すると、AWS はメンバーアカウント内にロールを自動的に作成し、そのロールを引き受けることができる管理アカウントの IAM ユーザーに管理者権限を付与します。デフォルトでは、そのロールの名前は OrganizationAccountAccessRole。
  - 組織に参加するように招待した既存メンバー アカウントには、管理者ロールが自動的に作成されません。次の手順に示すように、これを手動で行う必要があります。これは基本的に、作成されたアカウントに対して自動的に設定されるロールを複製します。OrganizationAccountAccessRole 一貫性と覚えやすさを考慮して、手動で作成したロールには同じ名前 を使用することをお勧めします。

- AWS CodeBuild: ビルド仕様ファイルである buildspec.yml において、JUNITXML フォーマットを出力することで、テスト結果の詳細が含まれたレポートを生成します。このレポートを新しい CodeBuild レポートグループにアップロードすることで企業は Artifact と共にテスト結果を簡単に閲覧できます。

  - ![image](https://github.com/yoshikikasama/system/assets/61643054/28fafebf-a37c-4f9e-8d6f-044d70bc32ed)

- 会社の EC2 インスタンス、IoT デバイス、オンプレミスのインフラ全体で自動化されたパッチと構成の管理:

  - SSM Patch Manager: EC2, AWS IoT Green grass デバイス、オンプレミスサーバーのパッチを System Manager のメンテナンスウィンドウタスクとしてスケジュールする。
  - IAM:
    - EC2 インスタンスにインスタンスプロファイルをアタッチ
    - AWS IoT Green grass デバイス、オンプレミスサーバーに System Manager 用の IAM サービスロールを作成する。SSM Agent をオンプレミスサーバーにインストールし、それを AWS 環境と通信させるために必要な認証情報と権限を提供する。これを実現するために AWS はマネージドインスタンスのアクティベーションという機能を提供している。これを使用するとオンプレミスサーバーや VM を SSM Manager サービスに登録できる。登録する際には、activation code と activation id が生成され、これらを使用して SSM Agent を on-premise のサーバーにインストールする。インストールされた SSM Agent は、特定の IAM Role に関連づけられた権限を使用して、AWS System Manager と通信することができる。

- Data Streams というサービスからデータを読み込み、それを古いスタイルの REST API（ウェブサービス）に送る。AWS Lambda とがデータを REST API に送るけど、送られるデータの 10%ぐらいにエラーがあり、手動で直さないといけない問題が起こっている。エラーが起きた時に、そのエラーデータを別の場所（Amazon SQS のデッドレターキューと呼ばれる場所）に送って保管するように設定されているんだけど、テストをしてみたらエラーのないデータも間違ってこのデッドレターキューにたくさん送られてしまっていることに気付いた。問題の核心は、この間違って送られてしまうデータの数を減らすためには、エンジニアがどう Lambda 関数の設定を変更すればいいかということ。
  - もともと AWS Lambda では、大量のデータを「バッチ」っていう塊で一度に処理することができる。ただ、これらデータの中にエラーがあると、Lambda はその全体のバッチ処理に失敗したと見なし、エラーがあったとして全てのデータ（エラーがあるデータもないデータも）をデッドレターキューに送ることがある。ここで、「エラー発生時にバッチを分割する」設定を使うと、Lambda はエラーを含む大きなバッチを発見したら、そのバッチをより小さいバッチに分けて、もう一度処理を試みる。このプロセスを通じて、Lambda はエラーのないデータとエラーのあるデータをより簡単に区別できるようになる。つまり、バッチが最初にエラーに遭遇したときに、全部をデッドレターキューに送るのではなく、さらに細分化してエラーのないデータとエラーのあるデータを区別する。この結果、問題となっている少数のデータだけが特定され、それだけがデッドレターキューに送られることになる。だから、「バッチに分割すること」で、正常に処理できるデータが誤ってデッドレターキューに送られるのを減らせる。エラーのないデータは正しく処理が完了し、必要ない手動介入を減らせる。

## 37.

- AWS Organizations 管理の AWS アカウントで S3 Bucket に対して転送中の暗号化を強制するためには:

  - S3 では転送中の暗号化と保管時の暗号化が可能です。転送中の暗号化とは HTTPS を指し、保管時の暗号化とはクライアント側またはサーバー側の暗号化を指します。
  - バケットポリシー内の HTTP リクエストまたは HTTPS リクエストを調べるには、"aws:SecureTransport" というキーを確認する条件を使用します。このキーが true の場合、Amazon S3 は HTTPS を介してリクエストを送信します。AWS Config を有効にし、s3-bucket-ssl-requests-only ルールに準拠させるには、リクエストが "aws:SecureTransport": "false" の条件を満たす場合にアクセスを明示的に拒否するバケットポリシーを作成します。
  - AWS Config を有効にし、s3-bucket-ssl-requests-only ルールと AWS System Mangager オートメーションランブックを組み合わせたデプロイをすることで強制できる。Runbook で暗号化がされていない通信を拒否する Bucket policy を強制的に付与します。

- CodeDeploy と Amazon EC2 Auto Scaling:
  - 一度に一つのインスタンスをデプロイし、CPU 使用率が 85%を超えた場合に自動的にロールバックする方法。
  - CodeDeployDefault OneAtTime デプロイ戦略はアプリケーションを一度に一つのインスタンスにデプロイし、残りのフリートがトラフィックに残り続けることを保証する。これはローリングアップデートの一種です。
    - ローリングアップデート: CodeDeploy は「一度に 1 つのインスタンスにデプロイ」する戦略を取ることができるので、アプリケーションの更新中にもサービスの可用性を保ちつつ、段階的に全てのインスタンスを更新できる。
  - CPU 使用率メトリクスに基づくアラームを設定し、このしきい値に違反した場合にデプロイを自動的にロールバックする。
  - 一貫性のある更新: Auto Scaling グループに新しい EC2 インスタンスが加わるたびに、CodeDeploy が自動的に最新のアプリケーションをそのインスタンスにデプロイするから、アプリケーションのバージョンが常に最新で一貫している状態を保てる。
- 自動ロールバック: CPU 使用率などのメトリクスを監視して、デプロイメントが原因でパフォーマンスに問題が生じた場合には、自動的に以前の安定したバージョンにロールバックできるので、リスクを低減できる。
- AWS CodeDeploy が動作する主なタイミング:

  - アプリケーションが更新された時:
    - 開発者がアプリケーションのコードや設定に変更を加え、新しいバージョンをリリースする時。これらの変更を適用するために、AWS CodeDeploy を使用して、新しいバージョンを自動的に既存のサーバーまたはインスタンスへデプロイすることができる。
  - EC2 インスタンスが増えた時:
    - Amazon EC2 Auto Scaling が動作して、トラフィックの増加や負荷の変化に応じて自動的に EC2 インスタンスの数を調整するとき。新しいインスタンスが起動された場合、そのインスタンスに最新のアプリケーションバージョンを自動的にデプロイする必要がある。AWS CodeDeploy は Auto Scaling イベントに基づいて CodeDeploy デプロイメントをトリガーするために、ライフサイクルフックを設定します。この自動デプロイメントをサポートしているため、Auto Scaling によって追加された新しい EC2 インスタンスにも、常に最新のアプリケーションが展開されるようになる。

- CodeDeploy のデプロイ設定(EC2/オンプレミス):

| デプロイ設定                  | インプレース                                                                     | Blue/Green                                                                                                                                         |
| ----------------------------- | -------------------------------------------------------------------------------- | -------------------------------------------------------------------------------------------------------------------------------------------------- |
| CodeDeployDefault.AllAtOnce   | 一度にできる限り多くのインスタンスへデプロイ。1 つでもデプロイできると成功。     | 一度にできる限り多くのインスタンスへデプロイ。すべてのインスタンスへルーティングし、一つでも正常に再ルーティングできれば成功。                     |
| CodeDeployDefault.HalfAtATime | 一度に最大で半分のインスタンスへデプロイ。少なくとも半分デプロイできると成功。   | 一度に最大で半分のインスタンスへデプロイ。一度に最大半分のインスタンスへルーティングし、少なくとも半分のインスタンスへ再ルーティングできれば成功。 |
| CodeDeployDefault.OneAtATime  | 一度に一つのインスタンスへデプロイ。すべてのインスタンスへデプロイできると成功。 | 一度に一つのインスタンスへデプロイ。一度に一つのインスタンスへトラフィックをルーティングし、すべてのインスタンスへ再ルーティングできると成功。     |

- Amazon Route 53 Application Recovery Controller:
  - Readiness Check:　レプリカ環境として条件を満たしているか確認できる機能。

| 項目                             | 内容                                                                                                       |
| -------------------------------- | ---------------------------------------------------------------------------------------------------------- |
| ElbV2TargetGroupsCanServeTraffic | 各 NLB,ALB を検査して、少なくとも 1 つの正常な Amazon EC2 インスタンスがあることを確認します。             |
| Dynamo TableStatus               | 各 DynamoDB テーブルを検査して、ステータスが ACTIVE であることを確認します。                               |
| VpcCidrBlock                     | すべての VPC を検査して、すべての VPC の CIDR ブロックネットワークサイズの値が同じであることを確認します。 |
| VpnConnectionsRoutesCidr         | すべての VPN 接続を検査して、宛先 CIDR ブロックが同じであることを確認します。                              |

- Routing Control:
  - Routing Control: セルに出入りするトラフィックを ON/OFF できるスイッチ。
  - ARC ヘルスチェック: Route53 ヘルスチェックと統合し、各アプリケーションの DNS レコードに紐づいている。ステータスが変更されると ARC はヘルスチェックを更新してトラフィックルーティングを変更する。
- 安全ルール: リカバリー操作によって逆にアプリケーションの可用性が落ちないように設定。1 つ以上のスイッチを ON の状態に保つように設定すれば全断することがなくなる。安全ルールには、アサーションルールとゲートルールの 2 種類があり、これらを使用してフェイルオーバーをさまざまな方法で保護できます。

  - アサーションルール: アサーションルールでは、1 つまたは一連のルーティングコントロールの状態を変更すると、Route 53 ARC はルールを作成したときに設定した基準を満たす必要があります。基準が満たされていない場合、ルーティングコントロールの状態は変更できません。これが役立つ例としては、フェイルオープンシナリオを防ぐ場合です。例えば、あるセルへのトラフィックの流れを停止しても、別のセルへトラフィックの流れが開始しないというシナリオです。これを回避するために、アサーションルールでは、コントロールパネルにある一連のルーティングコントロールのうち、少なくとも 1 つのルーティングコントロールが常時 On に設定されていることを確認します。これにより、トラフィックはアプリケーションの少なくとも 1 つのリージョンまたはアベイラビリティーゾーンに流れるようになります。もし、このルールによって「特定の場所には最低 1 つはトラフィックを送り続ける」って設定をしたら、その設定が守られない場合は、新しいトラフィックの送り方をすることができない。例えば、「サーバー A がダウンした時は、サーバー B にトラフィックを送る」って設定してあったとする。もしサーバー B もダウンしていたら、このルールが「停止！サーバー B には送れないよ！」って警告してくれる。
  - ゲートルール: ゲートルールでは、一連のルーティングコントロールを全体的にオン/オフに切り替えることができるため、ルーティングコントロールの状態が変更できるかどうかは、ルールで指定する一連の基準に基づいて実行されます。最も単純な基準は、スイッチに指定する 1 つのルーティングコントロールが ON もしくは OFF に設定されているかどうかです。これを実装するには、スイッチ全体として使用するゲートルーティングコントロールと、さまざまなリージョンやアベイラビリティーゾーンへのトラフィックフローを制御するターゲットルーティングコントロールを作成します。次に、ゲートルールに設定したターゲットルーティングコントロールの状態が手動または自動で更新されないように、ゲートルーティングコントロールの状態を Off に設定します。更新を許可する場合は On に設定します。全てのサーバーにトラフィックを送る前に、このゲートルールをチェックしてくれよ！」って言ってるみたいなもの。もし、このゲートが「オフ」になっていたら、どんな新しいルールやトラフィックの流れも始められない。でも、「オン」になっていれば、トラフィックの流れを変えることができるようになる
  - 比喩でいうと:
  - アサーションルール：いつも最低 1 つは避難路が開いているように確認してる警備員さんみたいなもの。
  - ゲートルール：ビル全体のメインスイッチのようなもので、これが「オン」でないと何も始まらない。

- Zone Shift: 特定の AZ にトラフィックを流さないという機能。

- AWS Organizations で現在 AWS アカウントでアクティブなサービスのみの使用をサポートする適切な SCP の割り当て:

  - IAM Access Analyzer を使用して現在 AWS アカウントでアクティブなサービスを識別し、それに基づいて SCP を作成、新しい OU を作成して、対象の AWS アカウントをこの OU に移動させることで組織構造を再編する。その後、作成されたカスタム SCP を OU に適用し、デフォルトの FullAWSAccess SCP を削除することでえ、アカウントが承認されたサービスのみを使用するよう制限する。
  - SCP によるポリシーは、設定された組織単位（OU）またはアカウントに適用される。もし、SCP で特定のサービスへのアクセスが許可されていない場合、その OU またはアカウントに含まれるユーザーは指定されたサービスを使用できなくなる。

- AWS のサービスコントロールポリシー（SCP）は、AWS Organizations を使って複数の AWS アカウントを管理するときに、これらのアカウントで使用できる AWS サービスやアクションを制御するためのもの。
  - 特定のサービスを許可するポリシーを作成した場合: SCP で特定のサービスのみを許可した場合、そのポリシーに明示的にリストアップされているサービスのみが使用可能になる。その他のサービスは、デフォルトで使用不可能になる。
    - 例えば、SCP で Amazon S3 と Amazon EC2 のみを許可した場合、これら以外のサービス（例えば、Lambda や DynamoDB など）へのアクセスは原則として拒否される。
  - 特定のサービスを拒否するポリシーを作成した場合:SCP で特定のサービスを拒否した場合、そのポリシーにリストされたサービスのみが使用禁止になる。その他のサービスは、ポリシーにより制限されない限り使用可能となる。
    - 例えば、SCP で Amazon S3 の使用を拒否した場合、S3 は使えなくなるが、それ以外のサービス（EC2、Lambda、DynamoDB など）は引き続き使うことができる。
  - つまり、特定のサービスを許可するポリシーは、そのサービス以外のものを全て拒否する「ホワイトリスト」アプローチ。
  - 一方で、特定のサービスを拒否するポリシーは、そのサービスだけを禁止して、他は許可する「ブラックリスト」アプローチになる。

## 38.

- IAM Identity Center: 複数の AWS アカウントおよびアプリケーションへのアクセスを提供するサービスです。

  - アクセス管理:

    - 複数の AWS アカウントへのアクセス
    - アプリケーションへのアクセス
    - AWS Organizations と統合されており、AWS Organizations 配下のアカウントに対して、アクセス許可セット（権限）をユーザーに割り当てできます。
    - [AWS 入門ブログリレー 2024 〜AWS IAM Identity Center 編〜](https://dev.classmethod.jp/articles/introduction-2024-aws-iam-identity-center/)
    - ![image](https://github.com/yoshikikasama/system/assets/61643054/bbd1583f-69d9-4b7e-b220-4a6f123bb49c)
    - AWS IAM では、インラインポリシーはあまり使わないことが多いと思いますが、AWS IAM Identity Center ではインラインポリシーを使うことも比較的多いです。理由としては、カスタマー管理ポリシーを利用する場合は、アクセス先のアカウントにおいて事前にカスタマー管理ポリシー（IAM ポリシー）を作成しておく必要があるためです。インラインポリシーの場合は AWS IAM Identity Center のアカウントの操作だけで設定が完結します。
    - <img width="925" alt="image" src="https://github.com/yoshikikasama/system/assets/61643054/7ee819f5-3bda-46fa-bbe6-d4d7278c0acb">
    - IAM Identity Center のユーザ・グループは、各アカウントで作成する IAM ユーザ・グループとは異なるため、IAM Identity Center でユーザ・グループを作成しても、各アカウント側には IAM ユーザ・グループは作成されません。接続構成としては IAM Identity Center から各アカウントに内部的にスイッチロールで接続することで、各アカウント側にはユーザ・グループの作成は行われず、IAM Identity Center で集中管理できるようになっているようです。
    - 許可セット: IAM ユーザやグループに割り当てる IAM ポリシーと同等の役割を持つ機能となりますが、違いとしては、1 つの許可セットで複数のアカウントを結びつけることができるため、各アカウント側でいちいち AdministratorAccess ポリシーや ReadOnlyAccess ポリシー等を作成する必要がありません。また、ユーザやグループに許可セットを割り当てる際、複数の許可セットを割り当てることもできるため、例えば設定作業用のフルアクセスポリシーと設定確認用のリードオンリーアクセスポリシー両方を付与して、作業時以外はリードオンリーアクセス権限を持つ許可セットでアクセスし、作業時のみフルアクセスを持つ許可セットでアクセスするといったことも簡単に実装可能です。今までは各アカウントごとに IAM ポリシーを作成していたのが、IAM Identity Center で集約管理することができるので、権限設定の見通しもよく、あるアカウントだけ権限設定を忘れたといった事態も軽減できるかと思います。
    - ![image](https://github.com/yoshikikasama/system/assets/61643054/afcfa95b-3bdb-4399-82b4-174b6483c261)
    - ![image](https://github.com/yoshikikasama/system/assets/61643054/5f9bcd41-fedd-4585-a0ae-d4cd9b0522ff)

- ID 管理（ユーザーの管理）:
  - 独自の ID ストアでユーザー管理
  - Active Directory や 外部 ID プロバイダーとの連携
- 用途: 外部の ID プロバイダと連携して AWS へアクセスする際などに使用する。One login など。
- AWS Control Tower との関係性: AWS Control Tower を利用するときには Control Tower が管理する AWS IAM Identity Center のユーザーやアクセス許可セットが作成されていましたが、2023 年 6 月のアップデートにより、これらの連携の有効化・無効化をユーザーが選択できるようになりました。

- IAM Control Tower:

  - 簡単に言うと複数の AWS アカウント（マルチアカウント）をベストプラクティスに基づいて設定および管理してくれるサービスです。
  - AWS の Organizations、Service Catalog、IAM Identity Center など複数サービスを使ってランディングゾーンを構築する
  - ダッシュボードからランディングゾーンの状態を監視する
  - 組織から OU やアカウントの Control Tower への登録状況を確認でき、OU やアカウントの作成/登録ができる
  - コントロール: 管理・統制からの逸脱（ドリフト）をさせないために OU にコントロールを適用する
    - 組織全体のガバナンス保護や逸脱を検知する機能としてコントロール（統制）が存在します。コントロールは動作の種類と必須度合いを表すガイダンスが決められています。
      - 予防
      - 検出
      - プロアクティブ
      - コントロールのガイダンス
  - Account Factory で新しい AWS アカウントの作成と初期設定を行う
  - ドリフト: 管理を逸脱した状態。
  - ランディングゾーン:マルチアカウントを適切に管理、利用するために整えた環境のことです。ランディングゾーンは、おもに２種類あります。
    - サービスベースドランディングゾーン: サービスとして提供されるランディングゾーンで、Control Tower が作るランディングゾーンはこれに該当します。AWS のセキュリティサービスを組織全体で管理する Audit アカウントやログを一元保管する LogArchive アカウントを用意します。ほかにもアカウントログインに使用する IAM Identity Center の有効化なども含まれます。
    - ![image](https://github.com/yoshikikasama/system/assets/61643054/ff2eed85-56b6-46ad-bea1-21c2499c2da0)
    - 例えるなら空港。新たに空港を作りたいときに、自ら設計・構築するのもひとつの選択肢ですが、ベストプラクティスに応じた設計で構築してくれる。そのようなサービスベースドランディングゾーンを作る機能を Control Tower は持っています。
  - カスタムランディングゾーン: 自身で構築するランディングゾーンです。

- AWS Organizations で組織全体に対してセキュリティ標準を実施し、コンプライアンスにつながる AWS サービスの設定ミスをほぼリアルタイムで特定したい場合:

  - AWS Confg の設定レコーダー: AWS リソースの設定変更を検出し、これらの変更を設定項目として取り込みます。
  - AWS Security HUb: セキュリティに関する情報を一元的に管理できる。

- AWS Config:

  - Configuration Recorder による記録(Record):設定レコーダーはリージョンごとに 1 つのみ作成できます。設定レコーダーでは以下のようなパラメータを指定します。
    - 記録するリソースタイプ (「すべて」 もしくは 「特定のリソースタイプ」)
    - 記録頻度 (「継続的な記録」もしくは「日時記録」)
    - Config データの保持期間
  - Config Rules による評価(Evaluate):「記録している構成情報が 理想的な状態かどうかを評価してくれる機能 」です。 評価の例としては「セキュリティグループで SSH 全開放になっていないか」や 「S3 バケットがパブリック公開されていないか」などがあります。
    - AWS Config マネージドルール: AWS が事前に定義してくれている Config ルールです。 お手軽に展開できます。Config ルールに 修復アクション を関連付けできます これにより非準拠になったリソースに対して、修復を簡単に実行できます。
    - AWS Config はデフォルトで AWS Security Hub と統合 されています。 Security Hub 上で Config ルールの結果を確認できます。
    - 修復アクション: AWS Config ルールに紐づける形で設定します。ルールによる評価の結果「非準拠」になったリソースに対して修復アクション（リソースの設定変更）を行い、「準拠」状態へ遷移させることができます。修復の実行を「自動」で行うか「手動」で行うかを選択可能です。修復アクションは AWS Systems Manager の Automation ドキュメントによって行われます。
    - ![image](https://github.com/yoshikikasama/system/assets/61643054/afb5b4a7-67ae-4629-ba6b-470bccfaf350)
    - ![image](https://github.com/yoshikikasama/system/assets/61643054/ce435d24-270b-4e6f-9bab-f157f5e02d48)
    - AWS Config 適合パック(コンフォーマンスパック): 適合パックは一つのエンティティであり、複数作成することができます。適合パックの中心となるのはテンプレートです。 CloudFormation と同じような記法で一つ以上の AWS Config ルール（および必要に応じて修復アクション）を定義し、一括でデプロイすることができます。デプロイされた Config ルールは個別に作成された場合と同様に管理することもできますし、適合パックというグループの中で管理することもできます。
    - ![image](https://github.com/yoshikikasama/system/assets/61643054/693339fc-79a2-4ed9-abe2-0e41db6f67dd)
    - 適合パックは Organizations とも連携可能なため、以下のような形でマスターアカウント配下の AWS アカウントにデプロイすることができます。このような一元管理にも対応しています。
    - ![image](https://github.com/yoshikikasama/system/assets/61643054/14ba8cea-8ce1-4cf9-a98c-e8c69e6f453d)
      - 組織内のメンバーアカウントによって設定変更できないので、組織全体でコンプライアンスを管理するのに役だつ。AWS System Manager オートメーションランブックのみを修復アクションとしてサポートしている。

- IAM Identity Center 内の ID ストアを外部 IdP に設定し、SAML2.0 を設定し最小限の権限モデルで管理:

  - 属性ベースのアクセス制御: Attribute-Based Access Control を利用して、ユーザーの属性やコンテキストに応じて柔転なアクセスポリシーを設定することができます。属性は、ユーザー名や所属部署、役職などの情報を指し、コンテキストは、時間や場所、デバイスなどの状況を指します。属性やコンテキストは、タグや条件演算子を使ってポリシーに組み込むことができます。今回の場合は、外部 IdP からの属性をキーと値のペアとしてマッピングして制御する。
  - 権限セットを作成し、必要なアクセス許可を含むインラインポリシーをアタッチし、aws:PrincipalTag 条件キーを使用してアクセス許可の範囲を設定。
  - インラインポリシー: IAM アイデンティティ (ユーザー、グループ、またはロール) に埋め込まれたポリシー。インラインポリシーは、ポリシーと ID の間の厳密な 1 対 1 の関係を維持します。これらは、ID を削除すると削除されます。ID の作成時、またはそれ以降で、ポリシーを作成して ID に埋め込むことができます。ポリシーが複数のエンティティに適用される可能性がある場合は、管理ポリシーを使用することをお勧めします。
  - ![image](https://github.com/yoshikikasama/system/assets/61643054/d2d0cf1b-9658-4a38-8c23-e8d0a3408e1a)
  - 許可(アクセス権限)セット: ユーザーおよびグループが持つこの AWS アカウントアカウントに対するアクセスのレベルを定義します。権限セットは IAM Identity Center に保存され、1 つまたは複数の AWS アカウントにプロビジョニングできます。複数のアクセス権限セットを 1 人のユーザーに割り当てることができます。

- AWS で PR ごとに単体テスト、結合テストを実行したい場合:

  - CodeCommit からの pullRequestCreated を EventBridge で検知
  - CodeBuild で単体テスト・結合テスト実行

- AWS CodePipeline: 以下構成で、パイプラインが実行されると CloudFormation がエラー。以下に、問題のアーキテクチャ構成を図にして説明します。

```
+-------------------------+      +-------------------------+      +-------------------------+
|                         |      |                         |      |                         |
|    Build Account        |      | Development Account     |      | Production Account      |
|                         |      |                         |      |                         |
| +---------------------+ |      | +---------------------+ |      | +---------------------+ |
| |   AWS CodePipeline  | |      | |   AWS CodePipeline  | |      | |   AWS CodePipeline  | |
| +---------------------+ |      | +---------------------+ |      | +---------------------+ |
|           |             |      |           |             |      |           |             |
|           v             |      |           v             |      |           v             |
| +---------------------+ |      | +---------------------+ |      | +---------------------+ |
| |   AWS CodeBuild     | |      | |   AWS CloudFormation| |      | |   AWS CloudFormation| |
| |   (Build Lambda)    | |      | |   (Deploy Infra)    | |      | |   (Deploy Infra)    | |
| +---------------------+ |      | +---------------------+ |      | +---------------------+ |
|           |             |      |           |             |      |           |             |
|           v             |      |           v             |      |           v             |
| +---------------------+ |      | +---------------------+ |      | +---------------------+ |
| |   S3 Bucket         | |      | |   IAM Role          | |      | |   IAM Role          | |
| |   (Artifacts)       | |      | |   (Decrypt & Access)| |      | |   (Decrypt & Access)| |
| +---------------------+ |      | +---------------------+ |      | +---------------------+ |
|           |             |      |           |             |      |           |             |
|           v             |      |           v             |      |           v             |
| +---------------------+ |      | +---------------------+ |      | +---------------------+ |
| |   KMS Key           | |      | |   KMS Key           | |      | |   KMS Key           | |
| |   (Customer Managed)| |      | |   (Customer Managed)| |      | |   (Customer Managed)| |
| +---------------------+ |      | +---------------------+ |      | +---------------------+ |
+-------------------------+      +-------------------------+      +-------------------------+
```

- アーキテクチャの説明
  - ビルドアカウント:
    - AWS CodePipeline: パイプラインの全体的な管理を行います。
    - AWS CodeBuild: Lambda 関数をビルドおよびパッケージ化します。
    - S3 Bucket: ビルドされたアーティファクトを保存します。
    - KMS Key (Customer Managed): アーティファクトを暗号化するためのカスタマーマネージドキー。
  - 開発環境アカウント:
    - AWS CodePipeline: デプロイのためのパイプラインを管理します。
    - AWS CloudFormation: インフラストラクチャのデプロイを行います。
    - IAM Role: CloudFormation アクションを実行するための権限、および S3 バケットからアーティファクトを取得して復号化する権限を持つロール。
    - KMS Key (Customer Managed): アーティファクトを復号化するためのカスタマーマネージドキー。
  - 本番環境アカウント:
    - AWS CodePipeline: デプロイのためのパイプラインを管理します。
    - AWS CloudFormation: インフラストラクチャのデプロイを行います。
    - IAM Role: CloudFormation アクションを実行するための権限、および S3 バケットからアーティファクトを取得して復号化する権限を持つロール。
    - KMS Key (Customer Managed): アーティファクトを復号化するためのカスタマーマネージドキー。
- 解決策の説明:

  - カスタマーマネージドキーの作成:AWS KMS のマネージドキーではなく、カスタマーマネージドキーを使用することで、キーポリシーを変更し、異なる AWS アカウント間でのアクセス制御を容易にします。
  - IAM ロールの作成と設定:開発環境アカウントと本番環境アカウントにおいて、CloudFormation アクションと CodePipeline で使用する IAM ロールを作成し、S3 バケットからアーティファクトを取得および復号化する権限を持たせます。S3 バケットのポリシーを変更し、これらの IAM ロールが適切にアクセスできるように設定します。この構成により、異なる AWS アカウント間でのアーティファクトの復号化が可能となり、アクセス拒否エラーが解消されます。

- Private の ECR リポジトリに CodeBuild からアクセスする方法:

  - aws ecr get-login-password コマンドは: ログイン用のパスワードのみが標準出力されます。docker login コマンドは --password-stdin というオプションが利用可能でパスワードを標準入力から読み込ませることができます。以下のように aws ecr get-login-password の結果を渡すことで、履歴やログにパスワードを残さず済みます。
  - $ aws ecr get-login-password | docker login --username AWS --password-stdin https://<aws_account_id>.dkr.ecr.<region>.amazonaws.com
    Login Succeeded

- Blue/Green アーキテクチャ: アプリケーションの新バージョン（Green）を既存のバージョン（Blue）とは異なる環境にデプロイし、切り替えることで、アプリケーションのアップデートやデプロイメントを効果的かつ安全に行う手法です。これにより、ダウンタイムの最小化や問題が発生した場合の簡単なロールバックが可能となります。
  - [AWS のホワイトペーパーから学ぶブルーグリーンデプロイメント](https://blog.serverworks.co.jp/tech/2018/07/18/aws_blue_green_deployments/#%E3%83%96%E3%83%AB%E3%83%BC%E3%82%B0%E3%83%AA%E3%83%BC%E3%83%B3%E3%83%87%E3%83%97%E3%83%AD%E3%82%A4%E3%83%A1%E3%83%B3%E3%83%88%E3%81%A8%E3%81%AF)
  - ブルー ⇒ グリーンの切り替えの基本は DNS(Route 53)で行うものになる
  - Elastic Beanstalk や OpsWorks を利用する場合も基本的には DNS での切り替えに倣う
  - Route 53 を利用する場合、ブルー ⇒ グリーンの切り替えは向き先の ELB の変更とイコールになる
  - Route 53 では重み付けが利用できるため、それを使ってブルー/グリーンのバランスを変更しつつロールバックを行える
  - Auto Scaling を利用することで、ELB 配下の環境を入れ替えることが可能でありこの場合 Route 53 に手を加えない
  - Auto Scaling を利用する場合は、Auto Scaling Group 単位で変更するか、Auto Scaling Group が持つ Launch Configuration で変更するかの 2 パターンに分かれる
  - Auto Scaling では「スタンバイ状態」や「起動する数の設定」を利用してブルー/グリーンの Instance 数を調整することでロールバックを行える
  - Elastic Beanstalk や OpsWorks を利用する場合、それぞれのサービスがバージョン管理の機能を持っているためその恩恵に与れるが、これらはどれも環境を丸ごと複製するためにコストが高くなる

## 40.

- 目的: 開発者が AWS CloudFormation を使ってアプリケーションをデプロイできるようにする。
- サービスロール作成: 必要な権限を持つ IAM ロールを作成し、CloudFormation がリソースをプロビジョニングするために使用。
- PassRole 権限: 開発者の IAM ロールに iam:PassRole 権限を付与し、サービスロールを渡せるようにする。
  - iam:PassRole 権限は、ある IAM ロールを他の AWS サービスに渡す（使用させる）ための権限です。この権限を持つ IAM ユーザーやロールは、指定された IAM ロールを他のサービス（例えば AWS CloudFormation）に使用させることができます。必要な理由は、AWS CloudFormation などのサービスがユーザーの代わりに指定された IAM ロールの権限を使用して操作を実行するためです。
- デプロイ方法: 開発者は自分のロールを使ってデプロイ時にサービスロールを指定。
- 利点: 最小権限の原則に従い、必要な権限を安全に管理。
