# CloudLicence

## 35.

- CloudFormation で作成する Windows ベースの EC2 を既存の AWS Managed Microsoft AD ディレクトリのドメインに参加させる方法：

  - CloudFormation template を使用してタグを伝番させ、AWS::SSM::Association リソースで AWS-JoinDirectoryServiceDomain オートメーションランブックを関連づけることで、EC2 インスタンスを AWS Managed Microsoft AD ドメインに効率的に参加させることができる。
  - AWS::SSM::Association リソースは、AWS Systems Manager の一部である State Manager を用いて、インスタンスに定期的に適用する設定やポリシーを管理します。このリソースを使用すると、SSM ドキュメント（ランブックやコマンドドキュメントなど）を特定のインスタンスやリソースグループに自動的に適用できます。
  - AWS-CreateManagedWindowsInstanceWithApproval: AWS Systems Manager (SSM) オートメーション ドキュメントの一つです。このドキュメントは、承認プロセスを経た後に管理対象の Windows インスタンスを作成するために使用されます。主にガバナンスやコンプライアンス要件を満たすために、インスタンスの作成前に必要な承認を確保する場合に便利です。

- Firewall: 不正なアクセスや通信をブロックするためのネットワークセキュリティ対策に利用されるもの。
- AWS WAF:

  - web application firewall。web アプリレベルでのトラフィック制御、HTTP/HTTPS トラフィックの監視と制御に重点を置いている、
  - CloudFront, ALB, API Gateway が保護リソースとなる。

- AWS Network Firewall:

  - 概要:
    - VPC 単位でパケットの制御が可能。
    - ステートレスパケットフィルタ(5-tuple): 行きと帰りの通信を双方向で許可する必要があるフィルタリング方式。
    - ステートフルパケットフィルタ(5-tuple): 行きの通信のみを定義するだけで帰りの通信は自動的に許可されるフィルタリング方式。
    - ドメインの制御: aaa.jp のようなドメイン制御(ホワイトリスト/ブラックリスト)ができるフィルタリング方式。ドメインの制御はステートフル。
    - Suricata 互換の IPS: シグネチャ型(パターンベース)の IPS が実装可能。
    - 5-tuple: 送信元、送信元ポート番号、宛先 IP、宛先ポート番号、プロトコル番号の 5 つを指定して制御ルールを記載すること。
  - 構成要素:
    - ![Screenshot 2024-04-25 at 7 46 27](https://github.com/yoshikikasama/system/assets/61643054/4975e5aa-1415-4f9b-b253-b18e1abb6d7e)
    - ファイアウォール: AWS Network Firewall 構築時に指定したサブネットに Gateway Load Balancer のエンドポイントが作成されるため、検査対象の通信は一時的に VPC 外へ転送されることになる。
    - ファイアウォールポリシー: AWS Network Firewall で検査する動作を指定する。ファイアウォールルールグループの順序やアクションを管理する。
    - ファイアウォールルールグループ: ファイアウォールルールの順序やアクションを管理する。
      - ステートレスルール: アンマネージド
      - ステートフルルール: アンマネージド、マネージド

- Amazon GuardDuty: Amazon VPC フロー ログ、DNS ログ、 AWS CloudTrail 管理イベント、および AWS CloudTrail S3 データ イベントからのデータを分析および処理する継続的なセキュリティ監視サービスです。このデータに基づいて、GuardDuty は、AWS クラウドの脅威インテリジェンス フィード、シグネチャ、異常検出、機械学習を使用して分析と検出を提供します。

- AWS CodePipeline の承認アクションを管理し証跡を記録:

  - AWS CloudTrail の証跡を作成してログを S3 に配信する。
  - デプロイステップの前に Codepipeline の主導の承認アクションを作成する。承認者にはアクセス権を与えるポリシーを作成する。

- AWS CodePipeline: ソフトウェアのコンパイル、テスト、パッケージを自動化するためのサービス。ソース、ビルド、テスト、ビルド、承認に加えて呼び出しという合計 6 つのアクションが定義されており、それぞれのアクションごとに統合できるサービスが決まっている。

  - ビルドステージで runOrder2 を設定することで既存のビルドアクションに合わせて単体テストを実行するアクションを配置できる。1 つのステージで並行アクションを実行したければ RunOrder パラメータを変更する。
  - [AWS CodePipeline の超詳細解説](https://zenn.dev/tech4anyone/articles/c2105f60eba379#%E3%81%AF%E3%81%98%E3%82%81%E3%81%AB)
  - ![image](https://github.com/yoshikikasama/system/assets/61643054/de6a1cd4-1bf3-45a5-a1dd-d9e63626cc94)
  - ![image](https://github.com/yoshikikasama/system/assets/61643054/c63c2766-b906-42a8-9ac6-75cf85492b50)
  - ![image](https://github.com/yoshikikasama/system/assets/61643054/89cb5d86-efe2-44fe-a3c8-b78241ddb325)
  - ![image](https://github.com/yoshikikasama/system/assets/61643054/6f2e0099-eb5f-43d6-838e-25598ef94e0e)
  - ソース: 使うことが多いのは圧倒的に CodeCommit と ECR です。
  - ビルド: 基本は CodeBuild
  - テスト: 基本は CodeBuild
  - デプロイ: CodeDeploy
  - 承認: 必ず手動で行う必要がある

- AWS CodePipeline におけるアーティファクト: AWS CodePipeline ではアーティファクトを各ステージごとに作成することが可能です。作成されたアーティファクトは S3 に保存され、次のステージに受け継がれます。ただし、ビルドが不要でテストのみ実施するような場合は CodeBuild でアーティファクト不要です。必要に応じて、次のステージに渡したいものをアーティファクトとして S3 に保存してください。

  - ![image](https://github.com/yoshikikasama/system/assets/61643054/e3c07ac3-fbfd-4f8f-baa8-d499e7296053)
  - AWS CodePipeline における「アーティファクト」とは、パイプラインの各ステージを進む中で生成されるファイルやデータの集合を指します。これにはビルドの出力、設定ファイル、デプロイスクリプトなど、後続のステージで使用される情報が含まれています。
  - アーティファクトの役割と使われ方
    - 保存と転送: アーティファクトは通常、ビルドステージでコンパイルされたバイナリや実行可能ファイルなど、重要な成果物を含みます。これらは Amazon S3 に保存され、パイプラインの次のステージへと安全に転送されます。
    - ステージ間の連携: パイプラインのあるステージが完了すると、そのステージで生成されたアーティファクトは次のステージに自動的に引き継がれます。例えば、ビルドステージで生成されたバイナリファイルがテストステージに移され、テストが行われることがあります。
      バージョン管理とロールバック: 各アーティファクトは S3 に保存される際に特定のバージョンとして管理されます。これにより、何か問題が発生した場合に以前のバージョンのアーティファクトへ簡単にロールバックできるようになります。
    - 自動化と効率化: アーティファクトの自動生成と転送により、手作業でのファイル移動やエラーの可能性が減少し、開発プロセスの自動化と効率化が図られます。

- AWS CodeDeploy: EC2, ECS, Lambda がデプロイ対象
- AWS CodeBuild:

  - フルマネージドなビルドサービスでソースコードのコンパイル、テスト実行、ソフトウェアパッケージの作成を実行。python 環境 install など。
  - imutable な環境のために個々のビルドを新規 Docker コンテナで実行。
  - buildspec.yml: CodeBuild の設定ファイル。
    - version: buildspec の version 指定
    - run-as: コマンドを実行する Linux ユーザー
    - env: 環境変数
    - proxy: プロキシサーバ設定
    - batch: バッチビルド設定。ビルドのジョブを順番に制御したり、同時実行を制御したりする。
    - phases: 実行するコマンド
    - reports: テストレポート作成。pytest などの実行結果を XML などで出力する。
    - artifacts: AWS CodeBuild の出力
    - cache: キャッシュ設定
  - ![image](https://github.com/yoshikikasama/system/assets/61643054/b9b8d889-d8e4-47b6-b034-b8450b4f01bc)

- Amazon ECR でクロスリージョンレプリケーション: ソースリポジトリに 1 回プッシュするだけで、複数の AWS アカウントおよび異なるリージョン間でコンテナイメージを簡単にコピーができます。また異なるリージョンにイメージをコピーすることにより、地理的分散ができるので、ディザスタリカバリの要件を満たすこともできます。

## 36.

- Amazon Timestream:

  - 高速かつスケーラブルなサーバレス時系列データベースサービスです。
  - ![image](https://github.com/yoshikikasama/system/assets/61643054/7efd8d9a-5f75-41c6-a1ba-171f0148976f)
  - 一番大きな単位としてデータベース (Database) があり、その中に複数のテーブル (Table) を持つことができ、そのテーブルの中に複数のタイムシリーズ (Time-Series) が入っています。タイムシリーズ (Time-Series) は時系列に並んだレコード (Record) のまとまりとなっていて、その中にディメンション（Dimension）と呼ばれる測定値を識別するための属性情報とメジャー (Measure) と呼ばれる測定値でテーブル内で一意に決まるものに対して、タイムスタンプごとにレコード (Record) と呼ばれる単一のデータポイントが記録されています。
  - Timestream table に対して毎日クエリを実行する際の最速クエリパフォーマンスについて:

    - バッチ処理書き込み: 複数のログイベントを 1 回の書き込み操作で処理することができ、ネットワーク遅延や書き込み回数によるオーーバーヘッドが軽減されるため、大量のデータ生成において効率的。
    - マルチメジャーレコード: 1 つのレコードに複数のメトリクスを含めることができる。これは 10 分の 1 秒ごとに 5 つの異なるメトリクスを含むログイベントのように、多様なデータポイントを持つログを扱う場合に有効。サーバの CPU、メモリ量、スワップ、ディスクの使用状況を取得するシンプルな監視アプリケーションを作成しました。その際、4 つの測定値はシングルメジャーレコードのデータモデルを利用してそれぞれ別のレコードとして書き込んでいました。これをマルチメジャーレコードを使うと、4 つの測定値は同時に取得されるので、1 つのレコードとして格納され、まとめてクエリを実行する事が出来ます。マルチメジャーレコードを利用すると、テーブルに書き込まれるレコード数を削減する事が出来ます。以前はメジャー毎に 1 つずつ、計 4 レコードを書き込んでいましたが、今回のアップデートで同時に取得した 4 つのメジャー値を 1 行のマルチメジャーレコードとして書き込む事が出来ます。また、ストレージの使用料も減りますが、以前と同じ情報量を保持しています。処理するデータ量が減少する為、マルチメジャーレコードでクエリを実行する方が簡単で効率的です。例えば、結合を使用して同じクエリで複数のメジャーを取得する必要も無い為、全体的なコスト削減にもつながります。
      - ![image](https://github.com/yoshikikasama/system/assets/61643054/03ca76df-efd5-4b43-9d96-3c6f2b75bda1)
      - ![image](https://github.com/yoshikikasama/system/assets/61643054/3ca9c80b-f33e-463e-a1d7-03ab58be3e5a)
    - マグネティックストレージへの書き込み:データのライフサイクルを直近データのメモリストアと履歴データのマグネティックストアという 2 つのストレージ階層で管理しています。メモリストアからマグネティックストアへのデータの移動は設定したポリシーに応じて自動的に実施されます。以前はデータはメモリストアにしかロード出来ず、遅れて到着するデータを格納する為には、メモリストアの保持時間を拡張して対応する必要がありました。今回、直接マグネティックストアに書き込む事が出来るようになり、ストレージコストを削減する事が出来ます。時系列データを扱う場合には、遅れて到着するデータ (タイムスタンプが過去) についても考慮する必要があります。データが遅れて到着する理由は多数ありますが、制御出来ない事が大半です。例えば、アプリケーションやデバイスが停止したり、一時的にネットワークから切断された後、オンラインに戻った際に滞留していたデータが一度に送信するようなケースが考えられます。以前の Timestream ではメモリ保持期間外のデータを書き込むとエラーとして処理していた為、遅延したデータを取り込むには、テーブルのメモリストアの保持期限を増やす必要がありました。今回、テーブルの設定を有効化するだけで、遅れて到着したデータをマグネティックストレージに直接書き込めるようになりました。メモリストアに書き込む場合と同様に、WriteRecord API を利用すると、書き込むデータのタイムスタンプとテーブルのメモリストア保持期間に応じて、メモリ／マグネティックストレージのいずれかに自動的にルーティングされます。
    - メモリストはは頻繁にアクセスされる最新のデータのための高速アクセス層、磁気ストアは長期的なデータ保持とコスト効率の良いクエリパフォーマンスのために設計されている。

| 構成要素名                   | 構成要素説明                                               |
| ---------------------------- | ---------------------------------------------------------- |
| データベース (Database)      | テーブル (Table) を保持するコンテナ                        |
| テーブル (Table)             | タイムシリーズ (Time-Series) を保持するコンテナ            |
| タイムシリーズ (Time-Series) | ある属性値で説明できる、時系列に並んだレコードのまとまり   |
| ディメンション (Dimension)   | 測定値を識別するための属性情報セット                       |
| メジャー (Measure)           | 測定値 (名前 (measure_name) と値 (measure_value) のセット) |
| レコード (Record)            | 単一の時系列のデータポイント                               |

- CloudFormation カスタムリソース: CloudFormation から Lambda や SNS を動かし、その結果を返すことで作成完了とするリソースのことです。上の図では CloudFormation からスタックの作成が行われると、Lambda とそれに必要なロールを作成します。その後カスタムリソースと呼ばれるリソースが Lambda を実行して、その結果をカスタムリソースへ応答オブジェクトとして返却します。カスタムリソースは実体のないリソースで、テンプレート上で Lambda の実行と結果の取得を定義するためのリソースなので、AWS 上には何も作成されない点がちょっと分かりにくいポイントですね。Lambda からのレスポンスとなる応答オブジェクトは、JSON の形式で送信され Lambda の成功/失敗や失敗時の理由、CloudFormation テンプレートに返したい任意のデータなどが含まれます。

  - ![image](https://github.com/yoshikikasama/system/assets/61643054/85861c4e-fb8e-43ca-804a-1fa5b6731e5b)

- 買収した企業の　 AWS アカウント AWS Organizations に招待:

  - デフォルトでは、組織の一部としてメンバーアカウントを作成すると、AWS はメンバーアカウント内にロールを自動的に作成し、そのロールを引き受けることができる管理アカウントの IAM ユーザーに管理者権限を付与します。デフォルトでは、そのロールの名前は です OrganizationAccountAccessRole。
  - ただし、組織に参加するように招待したメンバー アカウントには、管理者ロールが自動的に作成されません。次の手順に示すように、これを手動で行う必要があります。これは基本的に、作成されたアカウントに対して自動的に設定されるロールを複製します。OrganizationAccountAccessRole 一貫性と覚えやすさを考慮して、手動で作成したロールには同じ名前 を使用することをお勧めします。

- AWS CodeBuild: ビルド仕様ファイルである buildspec.yml において、JUNITXML フォーマットを出力することで、テスト結果の詳細が含まれたレポートを生成します。このレポートを新しい CodeBuild レポートグループにアップロードすることで企業は Artifact と共にテスト結果を簡単に閲覧できます。

  - ![image](https://github.com/yoshikikasama/system/assets/61643054/28fafebf-a37c-4f9e-8d6f-044d70bc32ed)

- 会社の EC2 インスタンス、IoT デバイス、オンプレミスのインフラ全体で自動化されたパッチと構成の管理:

  - SSM Patch Manager: EC2, AWS IoT Green grass デバイス、オンプレミスサーバーのパッチを System Manager のメンテナンスウィンドウタスクとしてスケジュールする。
  - IAM:
    - EC2 インスタンスにインスタンスプロファイルをアタッチ
    - AWS IoT Green grass デバイス、オンプレミスサーバーに System Manager 用の IAM サービスロールを作成する。SSM Agent をオンプレミスサーバーにインストールし、それを AWS 環境と通信させるために必要な認証情報と権限を提供する。これを実現するために AWS はマネージドインスタンスのアクティベーションという機能を提供している。これを使用するとオンプレミスサーバーや VM を SSM Manager サービスに登録できる。登録する際には、activation code と activation id が生成され、これらを使用して SSM Agent を on-premise のサーバーにインストールする。インストールされた SSM Agent は、特定の IAM Role に関連づけられた権限を使用して、AWS System Manager と通信することができる。

- Data Streams というサービスからデータを読み込み、それを古いスタイルの REST API（ウェブサービス）に送る。
- AWS Lambda とがデータを REST API に送るけど、送られるデータの 10%ぐらいにエラーがあり、手動で直さないといけない問題が起こっている。
- エラーが起きた時に、そのエラーデータを別の場所（Amazon SQS のデッドレターキューと呼ばれる場所）に送って保管するように設定されているんだけど、テストをしてみたらエラーのないデータも間違ってこのデッドレターキューにたくさん送られてしまっていることに気付いた。
- 問題の核心は、この間違って送られてしまうデータの数を減らすためには、エンジニアがどう Lambda 関数の設定を変更すればいいかということ。
  - もともと AWS Lambda では、大量のデータを「バッチ」っていう塊で一度に処理することができる。ただ、これらデータの中にエラーがあると、Lambda はその全体のバッチ処理に失敗したと見なし、エラーがあったとして全てのデータ（エラーがあるデータもないデータも）をデッドレターキューに送ることがある。ここで、「エラー発生時にバッチを分割する」設定を使うと、Lambda はエラーを含む大きなバッチを発見したら、そのバッチをより小さいバッチに分けて、もう一度処理を試みる。このプロセスを通じて、Lambda はエラーのないデータとエラーのあるデータをより簡単に区別できるようになる。つまり、バッチが最初にエラーに遭遇したときに、全部をデッドレターキューに送るのではなく、さらに細分化してエラーのないデータとエラーのあるデータを区別する。この結果、問題となっている少数のデータだけが特定され、それだけがデッドレターキューに送られることになる。だから、「バッチに分割すること」で、正常に処理できるデータが誤ってデッドレターキューに送られるのを減らせる。エラーのないデータは正しく処理が完了し、必要ない手動介入を減らせる。

## 37.

- AWS Organizations 管理の AWS アカウントで S3 Bucket に対して転送中の暗号化を強制するためには:

  - S3 では転送中の暗号化と保管時の暗号化が可能です。転送中の暗号化とは HTTPS を指し、保管時の暗号化とはクライアント側またはサーバー側の暗号化を指します。
  - バケットポリシー内の HTTP リクエストまたは HTTPS リクエストを調べるには、"aws:SecureTransport" というキーを確認する条件を使用します。このキーが true の場合、Amazon S3 は HTTPS を介してリクエストを送信します。AWS Config を有効にし、s3-bucket-ssl-requests-only ルールに準拠させるには、リクエストが "aws:SecureTransport": "false" の条件を満たす場合にアクセスを明示的に拒否するバケットポリシーを作成します。
  - AWS Config を有効にし、s3-bucket-ssl-requests-only ルールと AWS System Mangager オートメーションランブックを組み合わせたデプロイをすることで強制できる。Runbook で暗号化がされていない通信を拒否する Bucket policy を強制的に付与します。

- CodeDeploy と Amazon EC2 Auto Scaling:
  - ›一度に一つのインスタンスをデプロイし、CPU 使用率が 85%を超えた場合に自動的にロールバックする方法。
  - CodeDeployDefault OneAtTime デプロイ戦略はアプリケーションを一度に一つのインスタンスにデプロイし、残りのフリートがトラフィックに残り続けることを保証する。
  - CPU 使用率メトリクスに基づくアラームを設定し、このしきい値に違反した場合にデプロイを自動的にロールバックする。
  - 一貫性のある更新: Auto Scaling グループに新しい EC2 インスタンスが加わるたびに、CodeDeploy が自動的に最新のアプリケーションをそのインスタンスにデプロイするから、アプリケーションのバージョンが常に最新で一貫している状態を保てる。
  - ローリングアップデート: CodeDeploy は「一度に 1 つのインスタンスにデプロイ」する戦略を取ることができるので、アプリケーションの更新中にもサービスの可用性を保ちつつ、段階的に全てのインスタンスを更新できる。
- 自動ロールバック: CPU 使用率などのメトリクスを監視して、デプロイメントが原因でパフォーマンスに問題が生じた場合には、自動的に以前の安定したバージョンにロールバックできるので、リスクを低減できる。
- AWS CodeDeploy が動作する主なタイミング:

  - アプリケーションが更新された時:
    - 開発者がアプリケーションのコードや設定に変更を加え、新しいバージョンをリリースする時。これらの変更を適用するために、AWS CodeDeploy を使用して、新しいバージョンを自動的に既存のサーバーまたはインスタンスへデプロイすることができる。
  - EC2 インスタンスが増えた時:
    - Amazon EC2 Auto Scaling が動作して、トラフィックの増加や負荷の変化に応じて自動的に EC2 インスタンスの数を調整するとき。新しいインスタンスが起動された場合、そのインスタンスに最新のアプリケーションバージョンを自動的にデプロイする必要がある。AWS CodeDeploy はこの自動デプロイメントをサポートしているため、Auto Scaling によって追加された新しい EC2 インスタンスにも、常に最新のアプリケーションが展開されるようになる。

- CodeDeploy のデプロイ設定(EC2/オンプレミス):

| デプロイ設定                  | インプレース                                                                     | Blue/Green                                                                                                                                         |
| ----------------------------- | -------------------------------------------------------------------------------- | -------------------------------------------------------------------------------------------------------------------------------------------------- |
| CodeDeployDefault.AllAtOnce   | 一度にできる限り多くのインスタンスへデプロイ。1 つでもデプロイできると成功。     | 一度にできる限り多くのインスタンスへデプロイ。すべてのインスタンスへルーティングし、一つでも正常に再ルーティングできれば成功。                     |
| CodeDeployDefault.HalfAtATime | 一度に最大で半分のインスタンスへデプロイ。少なくとも半分デプロイできると成功。   | 一度に最大で半分のインスタンスへデプロイ。一度に最大半分のインスタンスへルーティングし、少なくとも半分のインスタンスへ再ルーティングできれば成功。 |
| CodeDeployDefault.OneAtATime  | 一度に一つのインスタンスへデプロイ。すべてのインスタンスへデプロイできると成功。 | 一度に一つのインスタンスへデプロイ。一度に一つのインスタンスへトラフィックをルーティングし、すべてのインスタンスへ再ルーティングできると成功。     |

- Amazon Route 53 Application Recovery Controller:
  - Readiness Check:　レプリカ環境として条件を見たいしているか確認できる機能。

| 項目                             | 内容                                                                                                       |
| -------------------------------- | ---------------------------------------------------------------------------------------------------------- |
| ElbV2TargetGroupsCanServeTraffic | 各 NLB,ALB を検査して、少なくとも 1 つの正常な Amazon EC2 インスタンスがあることを確認します。             |
| Dynamo TableStatus               | 各 DynamoDB テーブルを検査して、ステータスが ACTIVE であることを確認します。                               |
| VpcCidrBlock                     | すべての VPC を検査して、すべての VPC の CIDR ブロックネットワークサイズの値が同じであることを確認します。 |
| VpnConnectionsRoutesCidr         | すべての VPN 接続を検査して、宛先 CIDR ブロックが同じであることを確認します。                              |

- Routing Control:
  - Routing Control: セルに出入りするトラフィックを ON/OFF できるスイッチ。
  - ARC ヘルスチェック: Route53 ヘルスチェックと統合し、各アプリケーションの DNS レコードに紐づいている。ステータスが変更されると ARC はヘルスチェックを更新してトラフィックルーティングを変更する。
- 安全ルール: リカバリー操作によって逆にアプリケーションの可用性が落ちないように設定。1 つ以上のスイッチを ON の状態に保つように設定すれば全断することがなくなる。安全ルールには、アサーションルールとゲートルールの 2 種類があり、これらを使用してフェイルオーバーをさまざまな方法で保護できます。

  - アサーションルール: アサーションルールでは、1 つまたは一連のルーティングコントロールの状態を変更すると、Route 53 ARC はルールを作成したときに設定した基準を満たす必要があります。基準が満たされていない場合、ルーティングコントロールの状態は変更できません。これが役立つ例としては、フェイルオープンシナリオを防ぐ場合です。例えば、あるセルへのトラフィックの流れを停止しても、別のセルへトラフィックの流れが開始しないというシナリオです。これを回避するために、アサーションルールでは、コントロールパネルにある一連のルーティングコントロールのうち、少なくとも 1 つのルーティングコントロールが常時 On に設定されていることを確認します。これにより、トラフィックはアプリケーションの少なくとも 1 つのリージョンまたはアベイラビリティーゾーンに流れるようになります。もし、このルールによって「特定の場所には最低 1 つはトラフィックを送り続ける」って設定をしたら、その設定が守られない場合は、新しいトラフィックの送り方をすることができない。例えば、「サーバー A がダウンした時は、サーバー B にトラフィックを送る」って設定してあったとするにゃん。もしサーバー B もダウンしていたら、このルールが「停止！サーバー B には送れないよ！」って警告してくれる。
  - ゲートルール: ゲートルールでは、一連のルーティングコントロールを全体的にオン/オフに切り替えることができるため、ルーティングコントロールの状態が変更できるかどうかは、ルールで指定する一連の基準に基づいて実行されます。最も単純な基準は、スイッチに指定する 1 つのルーティングコントロールが ON もしくは OFF に設定されているかどうかです。これを実装するには、スイッチ全体として使用するゲートルーティングコントロールと、さまざまなリージョンやアベイラビリティーゾーンへのトラフィックフローを制御するターゲットルーティングコントロールを作成します。次に、ゲートルールに設定したターゲットルーティングコントロールの状態が手動または自動で更新されないように、ゲートルーティングコントロールの状態を Off に設定します。更新を許可する場合は On に設定します。全てのサーバーにトラフィックを送る前に、このゲートルールをチェックしてくれよ！」って言ってるみたいなもの。もし、このゲートが「オフ」になっていたら、どんな新しいルールやトラフィックの流れも始められない。でも、「オン」になっていれば、トラフィックの流れを変えることができるようになる
  - 比喩でいうと:
  - アサーションルール：いつも最低 1 つは避難路が開いているように確認してる警備員さんみたいなもの。
  - ゲートルール：ビル全体のメインスイッチのようなもので、これが「オン」でないと何も始まらない。

- Zone Shift: 特定の AZ にトラフィックを流さないという機能。

- AWS Organizations で現在 AWS アカウントでアクティブなサービスのみの使用をサポートする適切な SCP の割り当て:

  - IAM Access Analyzer を使用して現在 AWS アカウントでアクティブなサービスを識別し、それに基づいて SCP を作成、新しい OU を作成して、対象の AWS アカウントをこの OU に移動させることで組織構造を再編する。その後、作成されたカスタム SCP を OU に適用し、デフォルトの FullAWSAccess SCP を削除することでえ、アカウントが承認されたサービスのみを使用するよう制限する。
  - SCP によるポリシーは、設定された組織単位（OU）またはアカウントに適用される。もし、SCP で特定のサービスへのアクセスが許可されていない場合、その OU またはアカウントに含まれるユーザーは指定されたサービスを使用できなくなる。

- AWS のサービスコントロールポリシー（SCP）は、AWS Organizations を使って複数の AWS アカウントを管理するときに、これらのアカウントで使用できる AWS サービスやアクションを制御するためのもの。
  - 特定のサービスを許可するポリシーを作成した場合: SCP で特定のサービスのみを許可した場合、そのポリシーに明示的にリストアップされているサービスのみが使用可能になる。その他のサービスは、デフォルトで使用不可能になる。
    - 例えば、SCP で Amazon S3 と Amazon EC2 のみを許可した場合、これら以外のサービス（例えば、Lambda や DynamoDB など）へのアクセスは原則として拒否される。
  - 特定のサービスを拒否するポリシーを作成した場合:SCP で特定のサービスを拒否した場合、そのポリシーにリストされたサービスのみが使用禁止になる。その他のサービスは、ポリシーにより制限されない限り使用可能となる。
    - 例えば、SCP で Amazon S3 の使用を拒否した場合、S3 は使えなくなるが、それ以外のサービス（EC2、Lambda、DynamoDB など）は引き続き使うことができるにゃん。
  - つまり、特定のサービスを許可するポリシーは、そのサービス以外のものを全て拒否する「ホワイトリスト」アプローチ。
  - 一方で、特定のサービスを拒否するポリシーは、そのサービスだけを禁止して、他は許可する「ブラックリスト」アプローチになる。
