# memo

[DevOps on AWS 大全](https://qiita.com/tech4anyone/items/b06f88035d27c6ef13b2)

## AWS における CI/CD のテクノロジースタック

- CI(Continuous Integration): ソースコードを書いたら、すぐにテストし、出力結果をもとにすぐに修正する、というサイクルを高速回転させること
- CD(Continuous Delivery): 自動で頻繁に本番環境へリリースを行うこと
- ビルド: ソースコードから実行可能なソフトウェアアプリケーションを生成するプロセスのことを指します。このプロセスには、コードのコンパイル、リンク、そしてパッケージングなどが含まれます。具体的には、プログラミング言語で書かれたテキスト形式のコードをコンピュータが理解できるバイナリ形式（実行ファイルやライブラリなど）に変換する作業です。

  - 毎回ビルドが必要な理由は、ソフトウェア開発プロセスにおいて、変更が常に行われるためです。以下に、ビルドを繰り返し行う理由をいくつか挙げて説明します。
  - 1. コードの更新: ソフトウェアは進化し続けるもので、新しい機能の追加、バグの修正、性能の改善などが頻繁に行われます。これらの変更がソースコードに反映されるたびに、それを実行可能な形式に変換する新しいビルドが必要になります。
  - 2. エラーの検出: ビルドプロセスはコンパイルエラーやその他の問題を検出する機会も提供します。開発者がコードに変更を加えるたびにビルドを行うことで、新たに導入された問題を早期に発見し、修正することができます。
  - 3. テストの自動化: ビルドプロセスの一環として、自動テストが実行されることが多いです。これにより、コードの変更が既存の機能に悪影響を与えていないかを確認できます。テストに合格するたびに新しいビルドが生成され、品質の維持が確保されます。
  - 4. 依存関係の管理: ソフトウェアプロジェクトには多くの外部ライブラリやモジュールが含まれることがあります。これらの依存関係が更新された場合、互換性を保つために新しいビルドが必要になることがあります。
  - 5. 継続的インテグレーション: 継続的インテグレーション（CI）は、チームメンバーが頻繁にコード変更を共有し、自動でビルドとテストを実行するプラクティスです。これにより、開発プロセスがスムーズに進行し、エラーが早期に検出されます。
  - 6. プラットフォームやデバイス間の一貫性: 異なるプラットフォームやデバイスでアプリケーションを実行する場合、各環境に適合するためには異なるビルドが必要になることがあります。

- Python のビルド: 他のコンパイル言語のそれとは少し異なる意味を持つことがあります。Python は基本的にインタープリタ言語であり、ソースコードは実行時にインタープリタによって直接解釈されます。しかし、Python プロジェクトをビルドするという文脈では、通常以下のようなプロセスやステップが含まれます：

  - 1. 依存関係のインストール: プロジェクトが依存する外部ライブラリやパッケージをインストールします。これは通常、pip を使用して requirements.txt や Pipfile にリストされたパッケージをインストールすることで行われます。
  - 2. 環境の設定: プロジェクト専用の仮想環境を設定することで、プロジェクトの依存関係が他のプロジェクトやシステム全体の Python 環境と衝突することを防ぎます。venv や conda といったツールが使用されます。
  - 3. コンパイル（オプショナル）: Python では、実行前に.py ファイルをバイトコード（.pyc ファイル）にコンパイルすることがあります。これは Python インタープリタが自動的に行うため、開発者が意識的にビルドプロセスに含めることは少ないですが、パフォーマンスの最適化のために事前に行うことも可能です。
  - 4. 静的コード解析: コードのスタイルチェックや潜在的なバグを検出するために、flake8 や pylint などのツールを使用して静的コード解析を行います。
  - 5. 自動テストの実行: ユニットテストや統合テストを自動で実行して、コード変更が既存の機能に悪影響を与えていないことを確認します。pytest や unittest がよく使われます。
  - 6. ビルドスクリプトの実行: 特定のビルドスクリプトや Makefile を使用して、上記のプロセスを自動化します。これにより、開発者や CI/CD システムが一連のコマンドを実行するだけでビルドプロセスを完了できるようになります。
  - 7. パッケージング: アプリケーションをデプロイや配布可能な形式（例えば、ホイールファイル.whl やソース配布）にパッケージングします。これは setuptools を用いた setup.py スクリプトや pipenv を使用して行われることが多いです。
  - これらのステップを通じて、Python プロジェクトが「ビルド」され、テスト、デプロイ、または配布のために準備されます。これにより、開発の一貫性を保ちつつ、エラーの早期発見やデプロイの自動化が可能となります。パッケージングが完了すると、その成果物（実行可能ファイル、バイナリ、ホイールファイル、Docker コンテナなど）を実際にユーザーやクライアントがアクセスできる環境にデプロイする準備を行います。

- インタープリタ: プログラムを一行ずつ読み込み、解析し、実行するプログラムまたは環境のことを指します。コンパイラとは異なり、インタープリタはプログラム全体を一度に機械語に変換するのではなく、各命令を逐次的に実行します。これにより、プログラムの開発とテストが迅速に行える利点がありますが、実行速度はコンパイルされたコードに比べて遅くなる場合があります。

  - インタープリタの特徴:
    - 逐次実行: ソースコードを一行ずつ読み込み、その都度実行します。これにより、開発中にコードの変更がすぐにテストできるという利点があります。
    - プラットフォームの独立性: インタープリタ自体が特定のプラットフォームに依存する場合を除き、ソースコードは様々なシステム上でインタープリタを通じて直接実行可能です。
    - デバッグが容易: コードのどの部分が現在実行されているかを容易に追跡できるため、デバッグがしやすいです。

- アプリケーションのデプロイ: web アプリなどのデプロイ
- リソースのプロビジョニング: AWS リソースの構築
- AWS におけるパイプラインのベストプラクティスパターン:

  - 大前提として、デプロイとプロビジョニングのパイプラインは分けることをおすすめします。
  - やろうと思えば、パイプラインを長く続けてプロビジョニングにした後にデプロイすることは可能です。
  - しかし、たいていの場合はプロビジョニングが必要な頻度とデプロイが必要な頻度は一致しません。
  - 例えば、アプリケーションを更新するたびに CloudFormation で定義した Lambda のパラメータを変更したりすることはあまり多くありません。
  - そのため、デプロイとプロビジョニングは別のパイプラインとすることが推奨です。

- AWS CodeArtifact:

  - AWS CodeArtifact はアーティファクト管理ツールです。
  - アーティファクト管理とは相互に依存するソフトウェアパッケージの依存関係を管理することです。
  - そして、代表的なパブリックのアーティファクトリポジトリには Maven や npm などが存在します。
  - AWS CodeArtifact はこれらのリポジトリと連携して独自のリポジトリを作ることができるサービスです。
  - 企業で開発を行っていると、承認されたパッケージのみ利用させたい、という場面が多々出てきます。その時に AWS CodeArtifact を利用すると、簡単にこの要件を実現できます。

- Amazon CodeGuru: ソースコードのレビューとアプリケーションパフォーマンスに関する推奨を行ってくれる機械学習ベースのサービスです。
- EC2 Image Builder:

  - 仮想マシンイメージまたはコンテナイメージを自動で作成するサービスです。
  - 名前が誤解を与えがちですが、オンプレミスの仮想マシンイメージやコンテナイメージも作成可能です。
  - EC2 Image Builder を含むパイプラインを組むことで、AMI の自動再作成だけではなく、EC2 の再作成まで一気通貫で行うことが可能になります。

- AWS Lambda のバージョンとエイリアス:

  - Lambda 関数のバージョンで 1 つの Lambda 関数に対して複数のバージョンを発行することが可能です。
  - エイリアスごとに異なる Lambda 関数のバージョンを指定できるため、開発環境と本番環境で異なるバージョンを選択することが可能です。
  - <img width="795" alt="image" src="https://github.com/yoshikikasama/system/assets/61643054/50075baa-1df9-467c-bb18-4e02ed725f62">
  - 上図では開発向けの dev エイリアスと本番向けの prod エイリアスを用意しています。そして、開発向けの dev エイリアスは$LATEST を利用して、常に最新バージョンの Lambda が起動するように設定しています。一方、本番向けは V1 と V2 でトラフィック分割をしています。これは一気に新しいバージョンに切り替えることによる思わぬトラブルを避けるためです。

- API Gateway:

  - Edge-Optimized は、クライアントに最も近い AWS Edge Location で API をホストし、低レイテンシーでアクセスできます。デフォルト設定
  - Regional は特定の AWS リージョン内に API を展開し、そのリージョン内のすべてのエンドユーザーに向けて高パフォーマンスな接続を提供します。
  - Private は VPC 内で API をホストし、パブリックインターネットを経由せずにプライベートネットワーク内でアクセス可能です。
  - API Gateway はカナリアリリースも可能です。カナリアリリースをするときには既存のステージに結び付く Canary と呼ばれる特別なステージを作成してリリースします。あるステージに対して Canary ステージを定義するとデプロイ操作がいったん、Canary のみに行われます。その後、トラフィックをシフトしてメインにもデプロイを反映する昇格か変更を切り戻す削除化を選ぶことができます。

- Amazon Kinesis Data Streams: リアルタイムで大量のデータを処理し、ストリーム処理アプリケーションを構築するためのサービスです。データはシャードと呼ばれるパーティションに分割され、各シャードで並行処理が可能です。これにより、高いスループットと低いレイテンシでデータを受け取り、処理することができます。IoT センサーデータ、ログ、トランザクションデータなど、様々なデータソースからのストリームデータを受信し、リアルタイムで分析・処理する際に効果的です。

  - ![image](https://github.com/yoshikikasama/system/assets/61643054/70aa2230-4c60-4d45-8718-11e69cabe847)
  - スケーラビリティはシャード数の増減で実現します。そして、シャード数はキャパシティモードと呼ばれる設定に基づいて管理されます。なお、Amazon Kinesis Data Streams では、オンデマンドモードとプロビジョニングモードの 2 つのキャパシティモードが提供されています。

- Amazon Kinesis Data Firehose: データストリームからのデータをシンプルかつスケーラブルに受け取り、処理・保存するサービスです。

  - ![image](https://github.com/yoshikikasama/system/assets/61643054/8fc5730d-0fc2-455e-b5b1-038905bcd1b0)
  - データを指定した Amazon S3、Amazon Redshift、Amazon OpenSearch などへ直接転送でき、データの変換や加工も柔軟に設定可能です。
  - Kinesis Data Firehose は管理が簡単で、サーバーレスのアーキテクチャを提供するため、開発者はデータの取り込みや保存に集中できます。
  - Kinesis Data Stream との大きな違いは 2 つ、1)ストリームではなくバッチで書き込む点、2)データ変換処理を実装できる点です。
  - Kinesis Data Streams と比較してマネージドであることを売りにしています。そのため、スケーリングについても考慮する点はなくデータの転送が急増した場合でも、自動的にスケールアウトします。自動スケーリングにより、運用者は手動でのスケールアップやダウンの必要性から解放され、効率的なデータ処理が実現されます。

- Amazon Kinesis Data Analytics:

  - リアルタイムデータストリーム上での SQL クエリを可能にするサービスです。
  - ![image](https://github.com/yoshikikasama/system/assets/61643054/e10b581e-84c8-4d5b-a639-0345c0be9402)
  - Kinesis Data Stream や Kinesis Data Firehose と比較してデータ分析色が強く、直接データを受ける口というよりは、ほか 2 つの Kinesis が受けたものに対して SQL クエリを発行するイメージです。
  - Kinesis Data Firehose 同様、処理するデータ量やクエリの複雑さに応じて自動的にスケーリングされます。

- Amazon Kinesis シリーズの比較:
  - Kinesis Data Streams: 高いスループットが必要で、リアルタイムデータ処理を要する場合、例えば、IoT デバイスのセンサーデータやログデータのリアルタイム分析
  - Kinesis Data Firehose: サーバレス運用、データ加工可、バッチで処理するため準リアルタイム。
  - Kinesis Data Analytics: SQL によるリアルタイムデータ分析が必要で、既存の SQL スキルを活用
- Amazon Route53:

  - 高可用、スケーラブル、そして完全マネージド型の権威 DNS サーバです。また、Route53 は権威 DNS サーバであると同時にドメインレジスターでもあります。
  - Record: ドメインに関連付けられた各リソースのエントリーで、主にドメイン名を IP アドレスに対応付けます。Record の中には Domain/subdomain Name、Record Type、Value(IP アドレス)、Routing Policy、TTL(DNS リゾルバでのキャッシュ期間) という 5 つの設定項目があります。
    - A: ドメイン名を IPv4 アドレスに解決
    - AAAA: ドメイン名を IPv6 アドレスに解決
    - CNAME:別のドメイン名にエイリアスを設定
  - Hosted Zone: 特定のドメインに関連する DNS レコードの集合体で、各 Hosted Zone には一意の名前が付与されます。Hosted Zone 内でレコードセットを設定することで、ドメインの挙動や解決ルールを定義できます。例えば、www.example.com をどの IP アドレスに解決するかなどがホステッドゾーンで設定されます。
  - Routing Policy:ルーティング先のサービスまで含めて可能な限りダウンタイムを短くする。
    - Simple Routing Policy: 単一のリソースにトラフィックを転送します。
    - Weighted Routing Policy: 複数のリソースに対して異なる重みを設定し、トラフィックを分散させる。
    - Latency-Based Routing Policy: クライアントの地理的位置に応じてトラフィックを最も低いレイテンシを持つエンドポイントに導くことができます。グローバルに展開されたアプリケーションで効果的です。
    - Failover Routing Policy: プライマリとセカンダリの 2 つのリソースを設定し、プライマリが利用できない場合にセカンダリにトラフィックを自動的にフェイルオーバーさせます。
    - トラフィックフロー: 複数の Routing Policy を組み合わせて使用する場合に発生するレコード設定の複雑な階層構造管理をできるようにしてくれます。このサービスを利用すると Weighted Routing Policy でトラフィック分割しながらリリースできる仕組みを作りつつ、バックエンドがダウンした時に備えた Failover Routing Policy で Sorry 画面に自動で向くようにする、といったことが可能になります。

- Amazon RDS:
  - 垂直スケーリング: インスタンスサイズを変更することで、CPU、メモリ、ストレージのリソースを調整できます。
  - 水平スケーリング: リードレプリカと呼ばれる複製を作成し、リードトラフィックを分散します。リードレプリカは読み取り専用で、主データベースに対してリードトラフィックを分散させることで読み取りの性能向上が期待できます。
  - マルチ-AZ デプロイメント: データベースを自動的に複製し、プライマリデータベースとセカンダリデータベースのペアを複数の可用性ゾーンにまたがって配置します。これにより、プライマリが利用できない場合に自動的にフェイルオーバーし、高い可用性を確保します。
  - Amazon RDS は自動的にデータベースをバックアップし、連続的なバックアップのスナップショットを作成します。
- Amazon Aurora:
  - 複数の可用性ゾーンにまたがる 6 つのコピーにデータを自動的にレプリケートし、障害が発生しても瞬時にフェイルオーバーできる高可用性構成を提供します。また、Aurora Replica を使用して読み取りトラフィックを分散し、スケーラビリティを向上させることができます。
  - Amazon Aurora は自動的にデータをバックアップし、連続的なバックアップのスナップショットを作成することでデータの保護を強化します。
  - 複数の Aurora Replica を作成して、読み取りトラフィックを分散できます。これにより、大量の読み取りトラフィックに対して柔軟にスケールアウトできます。Replica はプライマリデータベースと同等のパフォーマンスを提供し、自動的なフェイルオーバーもサポートしています。
  - グローバルデータベース: 複数の AWS リージョンにまたがる Aurora データベースのレプリケーションを可能にします。これにより、異なる地理的なリージョンにおいても低レイテンシで読み取り可能なデータベースの構築が可能です。
- ![image](https://github.com/yoshikikasama/system/assets/61643054/052eb97e-66b7-4df9-b8a7-b76437ebc36a)

- Amazon ElastiCache for Redis は、レプリケーションとシャーディングによりスケーラビリティを実現しています。

  - レプリケーションはクラスターモードを無効化している場合のオプションです。ElastiCache はプライマリキャッシュノードに対して複数のリードレプリカを作成できます。
  - これにより、読み取りトラフィックを分散させ、単一のプライマリによる負荷を軽減することができます。なお、リードレプリカはプライマリに対して非同期で更新され、耐障害性を向上させます。
  - ![image](https://github.com/yoshikikasama/system/assets/61643054/b2bba4ee-7bce-435b-93b0-41394f3fb7e8)
  - シャーディングはクラスターモードを有効化している場合のオプションです。キャッシュデータを複数のシャードに分割することで、水平方向のスケーリングを可能にします。
  - ![image](https://github.com/yoshikikasama/system/assets/61643054/96212586-83a9-4f5a-a4b8-c098f4f04d33)
  - 各シャードは独自のキャッシュエンジンのインスタンスを持ち、負荷が均等に分散されます。これにより、大量のデータやトラフィックにも柔軟に対応できます。
  - クラスターモードで使う場合のみオートスケーリングも利用可能です。
  - Amazon ElastiCache でディザスタリカバリを考える必要がある場合にはスナップショットの定期取得とマルチ-AZ デプロイメントがベストプラクティスです。ただし、どちらも Amazon ElastiCache for Redis でしか利用できず、Amazon ElastiCache for Memcached では使えないことは留意してください。
  - スナップショット: 定期的にスナップショットを作成し、データを Amazon S3 に保存します。これにより、データの永続性を確保し、障害やデータ損失の際にはスナップショットからデータを復元できます。
  - マルチ-AZ デプロイメント: マルチ-AZ デプロイメントがサポートされています。これにより、プライマリキャッシュノードとセカンダリキャッシュノードが異なる可用性ゾーンに配置され、プライマリに障害が発生した場合に自動的にセカンダリにフェイルオーバーします。
  - Amazon ElastiCache for Reids と Amazon ElastiCache for Memcached の比較:
  - ![image](https://github.com/yoshikikasama/system/assets/61643054/6a4a58b7-c204-4a7f-a899-c54bbf9024db)

- Amazon DynamoDB:

  - DynamoDB Streams は、データベース内の変更をリアルタイムで捕捉する機能を提供します。これにより、データの変更に対してトリガーを設定して、リアルタイムアプリケーションやイベント駆動型サービスを構築できます。
  - DynamoDB Accelerator（DAX）は、インメモリキャッシュを提供し、ミリ秒単位のレイテンシでデータへのアクセスを可能にします。
  - ![image](https://github.com/yoshikikasama/system/assets/61643054/533ecfce-9bd8-4d97-b2b5-8411d7a7a3e2)
  - DAX は DynamoDB に特化しており、DynamoDB へのアクセスを高速化する際に理想的です。一方、ElastiCache は Redis や Memcached を使用することで、汎用的なデータキャッシュソリューションとして広く利用されます。
  - DynamoDB Global Table: 複数の AWS リージョンにまたがるデータの自動的なレプリケーションをサポートします。グローバルテーブルは、書き込み可能なプライマリリージョンと、読み取り専用のセカンダリリージョンを指定でき、地理的な近接性に応じてトラフィックを分散させることが可能です。

- Auto Scaling Groups

  - スケーリングポリシー:
    - Target Tracking Scaling: 事前に設定したメトリクスの目標値を保ちながら自動的にスケーリングします。例えば、CPU 使用率やネットワークトラフィックの目標値を指定できます。
    - Simple Scaling/Step Scaling: 特定のメトリクスの閾値を超えた場合に、指定された数だけインスタンスを追加または削除します。例えば、CPU 使用率が閾値を超えたら 2 台追加、といった指定が可能です。
    - Scheduled Actions: 予め定義された時間に定義された台数だけスケーリングします。
    - Predictive Scaling: 機械学習を使用して CloudWatch からの履歴データに基づいたキャパシティー要件を予測しスケーリングポリシーを定義します。
  - ターミネートポリシー:
    - Default: 異常なく運用されているインスタンスから順に選択して終了します。
    - OldestInstance: 最も古い起動時間を持つインスタンスが優先的に終了されます。
    - NewestInstance: 最も新しい起動時間を持つインスタンスが優先的に終了されます。
  - ウォームプール: インスタンスが追加される前に、事前に起動しておくプールのことを指します。これにより、インスタンスが必要になったときに素早く対応でき、起動にかかる時間を最小限に抑えることができます。

- RPO（Recovery Point Objective）: ディザスタリカバリ計画において設定されるパラメータで、災害発生時に許容されるデータ損失の最大許容時間を示します。具体的には、最後の正常なデータバックアップからどれだけの時間のデータ損失が許容されるかを定義します。例えば、RPO が 1 時間の場合、ディザスタ発生前に 1 時間以内のデータ損失を許容するという意味です。
- RTO（Recovery Time Objective）: ディザスタ発生後にサービスやシステムを正常な運用状態に戻すための目標時間を示します。
  つまり、ディザスタが発生してからサービスが復旧するまでの合理的な時間枠を指定します。例えば、RTO が 1 時間の場合、ディザスタ発生後に 1 時間以内にサービスを完全に回復させる必要があります。
- ![image](https://github.com/yoshikikasama/system/assets/61643054/df4f6d9a-4390-42f0-a4e5-c3f3af619176)

- バックアップとリストア: 定期的なバックアップを取得して起き、ディザスタ発生時にリストアしながらセカンダリリージョンを構築する手法です。コストは最も安いですが、リストアをしながら別リージョンに環境を構築するため RTO は最も長くなります。
  - ![image](https://github.com/yoshikikasama/system/assets/61643054/0481cc1b-b3e1-4648-9860-7b12f0b7d792)
- パイロットライト: 本番環境の一部のトラフィックをセカンダリリージョンにルーティングする手法です。
  - ![image](https://github.com/yoshikikasama/system/assets/61643054/3d5124e5-a3ca-4e63-922e-5db8500620a4)
- ウォームスタンバイ: セカンダリリージョンにアプリケーションの冗長な最小限の環境を構築し、必要に応じてトラフィックを切り替える手法です。
  - ![image](https://github.com/yoshikikasama/system/assets/61643054/37205d6a-809f-4a63-a591-0839a68cb1f0)
- ホットサイト/マルチサイト:、本番環境と同等の冗長なフルサイズの環境を別の AWS リージョンに構築する手法です。

  - ![image](https://github.com/yoshikikasama/system/assets/61643054/f2740308-72b0-4424-abc0-4b628ded3082)

- Amazon CloudWatch Metrics:

  - Namespace: 論理的なグループにメトリクスを分類します。Namespace は AWS サービスやカスタムアプリケーションごとに異なり、メトリクスの一元管理を可能にします。AWS サービスのメトリクスは通常、そのサービス名が Namespace として使用されます。たとえば、Amazon EC2 のメトリクスは AWS/EC2 という Namespace に属します。
  - Dimension: メトリクスを更に特定化するためのキー/バリューペアであり、メトリクスデータをより細かく分類します。例えば、EC2 インスタンスの CPU 使用率をモニタリングする場合、インスタンス ID がディメンションとなります。ディメンションを指定することで、同じメトリクスでも異なるコンテキストでのデータを取得できます。

- Amazon SQS:

  - キューの種類を適切に選択する: FIFO キューと標準キューでは、メッセージの順序や重複性が異なります。アプリケーションの要件に応じて、最適なキューの種類を選びましょう。
  - 可視性タイムアウトを適切に設定する: 可視性タイムアウトは、メッセージの処理時間に影響します。可視性タイムアウトが短すぎると、メッセージが重複して処理される可能性があります。可視性タイムアウトが長すぎると、メッセージの処理が遅延する可能性があります。可視性タイムアウトは、メッセージの処理時間の平均値よりも少し長めに設定しましょう。
    - 可視性タイムアウト: SQS では RecieveMessage の API でキューからメッセージを取り出せます。取り出す時にはキューからメッセージは削除せず、代わりに「指定した時間内は今後 RecieveMessage では取り出せない」という状態に設定できます。SQS では、コンシューマーは処理が完了したメッセージをキューから削除する必要があります。メッセージ受け取り時に発行された ReceiptHandle を指定して DeleteMessage の API を使用することで、キューから 1 つずつメッセージを削除できます。これでプロデューサーからの 1 つの依頼が確実に完了したことを示せます。キューから取り出さないでという状態は、可視性タイムアウトで設定した時間を経過すると、再度キューから取り出せるようになります。この仕組みによって、コンシューマーが受け取ったけど処理が完了しなかったメッセージが取り出せないままキューに残り続けずに、他のコンシューマーで再試行できます。例えば、障害などで DelteMessage が送れなくなった場合など。
  - ロングポーリングを有効にする: ロングポーリングは、メッセージの到着を待つことで、空のレスポンスを減らします。ロングポーリングを有効にすると、コストやネットワークトラフィックを削減することができます。ロングポーリングは、キューまたはリクエストレベルで設定することができます。
  - バッチ処理を利用する: バッチ処理は、一度に複数のメッセージを送受信することで、レイテンシーやオーバーヘッドを減らします。バッチ処理を利用すると、スループットを向上させることができます。バッチ処理は、送信者または受信者のコードで実装することができます。
  - メッセージ属性やメッセージフィルタリングを活用する: メッセージ属性やメッセージフィルタリングは、メッセージの内容や処理方法を制御することができます。メッセージ属性やメッセージフィルタリングを活用すると、受信者が必要なメッセージだけを受け取ることができます。メッセージ属性やメッセージフィルタリングは、送信者または受信者のコードで実装することができます。
  - デッドレターキューの利用: メッセージの処理でエラーが発生した場合、デッドレターキューにリダイレクトして再処理を容易にすることができます。メッセージ処理のデバックやリドライブにも活用できます。

- AWS X-Ray:
  - AWS で動作するアプリケーションのパフォーマンスや問題を分析するためのサービスです。
  - AWS X-Ray を活用するには、まずアプリケーションに X-Ray SDK を組み込みます。X-Ray SDK を使用すると、アプリケーションが送受信するリクエストやレスポンスにトレース ID やセグメント ID などのメタデータを付与できます。これらのメタデータは、X-Ray デーモンや X-Ray インターセプターなどのエージェントによって収集され、X-Ray API に送信されます。X-Ray API では、受信したメタデータをもとにトレース情報を生成し、X-Ray コンソールや X-Ray CLI などで閲覧できるようにします。なお、監視対象が EC2 の場合には X-Ray Agent のインストールが、ECS の場合には X-Ray Agent のインストールまたは Docker コンテナが必要になります。ElasticBeanstalk や Lambda、API Gateway の場合には明示的なインストールは必要ありません。
  - サービスマップ: アプリケーションの構成要素や依存関係をグラフィカルに表示します。各ノードやエッジには、リクエスト数やエラー率、レイテンシーなどの統計情報が表示されます。
  - トレース: 個々のリクエストやレスポンスの流れを詳細に表示します。各セグメントやサブセグメントには、呼び出し元や呼び出し先、処理時間やステータスコードなどの情報が表示されます。
  - アラーム: トレース情報に基づいてアラームを設定できます。アラームは、CloudWatch と連携して、異常な状況が発生した場合に通知やアクションを実行できます。
