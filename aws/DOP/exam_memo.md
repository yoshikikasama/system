# exam_memo

## 第 1 分野: SDLC のオートメーション

- コード、イメージ、アーティファクトリポジトリの設定
- バージョン管理を使用してパイプラインをアプリケーション環境に統合
- 構築プロセスのセットアップ (AWS CodeBuild など)
- 構築とデプロイのシークレットの管理 (AWS Secrets Manager、AWS Systems Manager Parameter Store など)
- 適切なデプロイ戦略の決定 (AWS CodeDeploy など)
- プルリクエストまたはコードマージを生成するときに構築またはテストを実行 (AWS CodeCommit、CodeBuild など)
- 負荷/ストレステスト、パフォーマンスベンチマーキング、アプリケーションテストを大規模環境で実行
- アプリケーション終了コードに基づいてアプリケーションのヘルスを測定
- 単位テストとコードカバレッジの自動化
- テストのためパイプラインでの AWS サービスの呼び出し
- アーティファクトリポジトリの作成と設定 (AWS CodeArtifact、Amazon S3、Amazon Elastic Container Registry [Amazon ECR] など)
- アーティファクトを生成する構築ツールの設定 (CodeBuild、AWS Lambda など)
- Amazon EC2 インスタンスとコンテナイメージの構築プロセスの自動化 (EC2 Image Builder など)
- アーティファクトリポジトリへのアクセスを許可するセキュリティ権限の設定 (AWS Identity and Access Management [IAM]、CodeArtifact など)
- デプロイメントエージェントの設定 (CodeDeploy エージェントなど)
- デプロイに関する問題のトラブルシューティング
- さまざまなデプロイ方法の使用 (blue/green、Canary など)

### 試験メモ

- CI(Continuous Integration): ソースコードを書いたら、すぐにテストし、出力結果をもとにすぐに修正する、というサイクルを高速回転させること
- CD(Continuous Delivery): 自動で頻繁に本番環境へリリースを行うこと
- ビルド: ソースコードから実行可能なソフトウェアアプリケーションを生成するプロセスのことを指します。このプロセスには、コードのコンパイル、リンク、そしてパッケージングなどが含まれます。具体的には、プログラミング言語で書かれたテキスト形式のコードをコンピュータが理解できるバイナリ形式（実行ファイルやライブラリなど）に変換する作業です。

  - 毎回ビルドが必要な理由は、ソフトウェア開発プロセスにおいて、変更が常に行われるためです。以下に、ビルドを繰り返し行う理由をいくつか挙げて説明します。
  - 1. コードの更新: ソフトウェアは進化し続けるもので、新しい機能の追加、バグの修正、性能の改善などが頻繁に行われます。これらの変更がソースコードに反映されるたびに、それを実行可能な形式に変換する新しいビルドが必要になります。
  - 2. エラーの検出: ビルドプロセスはコンパイルエラーやその他の問題を検出する機会も提供します。開発者がコードに変更を加えるたびにビルドを行うことで、新たに導入された問題を早期に発見し、修正することができます。
  - 3. テストの自動化: ビルドプロセスの一環として、自動テストが実行されることが多いです。これにより、コードの変更が既存の機能に悪影響を与えていないかを確認できます。テストに合格するたびに新しいビルドが生成され、品質の維持が確保されます。
  - 4. 依存関係の管理: ソフトウェアプロジェクトには多くの外部ライブラリやモジュールが含まれることがあります。これらの依存関係が更新された場合、互換性を保つために新しいビルドが必要になることがあります。
  - 5. 継続的インテグレーション: 継続的インテグレーション（CI）は、チームメンバーが頻繁にコード変更を共有し、自動でビルドとテストを実行するプラクティスです。これにより、開発プロセスがスムーズに進行し、エラーが早期に検出されます。
  - 6. プラットフォームやデバイス間の一貫性: 異なるプラットフォームやデバイスでアプリケーションを実行する場合、各環境に適合するためには異なるビルドが必要になることがあります。

- Python のビルド: 他のコンパイル言語のそれとは少し異なる意味を持つことがあります。Python は基本的にインタープリタ言語であり、ソースコードは実行時にインタープリタによって直接解釈されます。しかし、Python プロジェクトをビルドするという文脈では、通常以下のようなプロセスやステップが含まれます：

  - 1. 依存関係のインストール: プロジェクトが依存する外部ライブラリやパッケージをインストールします。これは通常、pip を使用して requirements.txt や Pipfile にリストされたパッケージをインストールすることで行われます。
  - 2. 環境の設定: プロジェクト専用の仮想環境を設定することで、プロジェクトの依存関係が他のプロジェクトやシステム全体の Python 環境と衝突することを防ぎます。venv や conda といったツールが使用されます。
  - 3. コンパイル（オプショナル）: Python では、実行前に.py ファイルをバイトコード（.pyc ファイル）にコンパイルすることがあります。これは Python インタープリタが自動的に行うため、開発者が意識的にビルドプロセスに含めることは少ないですが、パフォーマンスの最適化のために事前に行うことも可能です。
  - 4. 静的コード解析: コードのスタイルチェックや潜在的なバグを検出するために、flake8 や pylint などのツールを使用して静的コード解析を行います。
  - 5. 自動テストの実行: ユニットテストや統合テストを自動で実行して、コード変更が既存の機能に悪影響を与えていないことを確認します。pytest や unittest がよく使われます。
  - 6. ビルドスクリプトの実行: 特定のビルドスクリプトや Makefile を使用して、上記のプロセスを自動化します。これにより、開発者や CI/CD システムが一連のコマンドを実行するだけでビルドプロセスを完了できるようになります。
  - 7. パッケージング: アプリケーションをデプロイや配布可能な形式（例えば、ホイールファイル.whl やソース配布）にパッケージングします。これは setuptools を用いた setup.py スクリプトや pipenv を使用して行われることが多いです。
  - これらのステップを通じて、Python プロジェクトが「ビルド」され、テスト、デプロイ、または配布のために準備されます。これにより、開発の一貫性を保ちつつ、エラーの早期発見やデプロイの自動化が可能となります。パッケージングが完了すると、その成果物（実行可能ファイル、バイナリ、ホイールファイル、Docker コンテナなど）を実際にユーザーやクライアントがアクセスできる環境にデプロイする準備を行います。

- インタープリタ: プログラムを一行ずつ読み込み、解析し、実行するプログラムまたは環境のことを指します。コンパイラとは異なり、インタープリタはプログラム全体を一度に機械語に変換するのではなく、各命令を逐次的に実行します。これにより、プログラムの開発とテストが迅速に行える利点がありますが、実行速度はコンパイルされたコードに比べて遅くなる場合があります。

  - インタープリタの特徴:
    - 逐次実行: ソースコードを一行ずつ読み込み、その都度実行します。これにより、開発中にコードの変更がすぐにテストできるという利点があります。
    - プラットフォームの独立性: インタープリタ自体が特定のプラットフォームに依存する場合を除き、ソースコードは様々なシステム上でインタープリタを通じて直接実行可能です。
    - デバッグが容易: コードのどの部分が現在実行されているかを容易に追跡できるため、デバッグがしやすいです。

- アプリケーションのデプロイ: web アプリなどのデプロイ
- リソースのプロビジョニング: AWS リソースの構築
- AWS におけるパイプラインのベストプラクティスパターン:

  - 大前提として、デプロイとプロビジョニングのパイプラインは分けることをおすすめします。
  - やろうと思えば、パイプラインを長く続けてプロビジョニングにした後にデプロイすることは可能です。
  - しかし、たいていの場合はプロビジョニングが必要な頻度とデプロイが必要な頻度は一致しません。
  - 例えば、アプリケーションを更新するたびに CloudFormation で定義した Lambda のパラメータを変更したりすることはあまり多くありません。
  - そのため、デプロイとプロビジョニングは別のパイプラインとすることが推奨です。

- AWS CodeArtifact:

  - AWS CodeArtifact はアーティファクト管理ツールです。
  - アーティファクト管理とは相互に依存するソフトウェアパッケージの依存関係を管理することです。
  - そして、代表的なパブリックのアーティファクトリポジトリには Maven や npm などが存在します。
  - AWS CodeArtifact はこれらのリポジトリと連携して独自のリポジトリを作ることができるサービスです。
  - 企業で開発を行っていると、承認されたパッケージのみ利用させたい、という場面が多々出てきます。その時に AWS CodeArtifact を利用すると、簡単にこの要件を実現できます。

- Amazon CodeGuru: ソースコードのレビューとアプリケーションパフォーマンスに関する推奨を行ってくれる機械学習ベースのサービスです。
- EC2 Image Builder:

  - 仮想マシンイメージまたはコンテナイメージを自動で作成するサービスです。
  - 名前が誤解を与えがちですが、オンプレミスの仮想マシンイメージやコンテナイメージも作成可能です。
  - EC2 Image Builder を含むパイプラインを組むことで、AMI の自動再作成だけではなく、EC2 の再作成まで一気通貫で行うことが可能になります。

- CodePipeline

  - AWS CodePipeline: ソフトウェアのコンパイル、テスト、パッケージを自動化するためのサービス。ソース、ビルド、テスト、ビルド、承認に加えて呼び出しという合計 6 つのアクションが定義されており、それぞれのアクションごとに統合できるサービスが決まっている。 -　 runOrder を同じ値にすると並列に実行する
    - 直列実行: アクションを順番に実行する場合は、runOrder を異なる値に設定します。例えば、最初のアクションの runOrder を 1、次のアクションの runOrder を 2 と設定します。この場合、1 のアクションが完了してから 2 のアクションが開始されます。
    - 並列実行: アクションを並列に実行する場合は、同じ runOrder 値を設定します。例えば、複数のアクションの runOrder を全て 1 に設定します。この場合、これらのアクションは同時に実行されます。
  - バージョンの異なる複数のコードをデプロイする場合は、その分だけ CodePipeline を作成する。
  - Jenkins で CICD を実行する場合は、マルチマスターセットアップとしてデプロイし、CodeBuild プラグインを使用することで CodeBuild でビルドを実行する。
  - 別の Codepipeline オプションを呼び出せない
  - S3 デプロイステップでアーティファクトを別リージョンのバケットにコピーできる。
  - CodeCommit への変更をトリガーにパイプラインを開始するには CloudWatch イベントと連携する。
  - CodePipeline では CloudFormation のパラメータを上書きすることが可能
    - パラメータの上書き機能を使用して、動的パラメータ値のみを指定します。
    - json を設定する。{"stage":"prod"}
  - ビルドステージで runOrder2 を設定することで既存のビルドアクションに合わせて単体テストを実行するアクションを配置できる。1 つのステージで並行アクションを実行したければ RunOrder パラメータを変更する。
  - [AWS CodePipeline の超詳細解説](https://zenn.dev/tech4anyone/articles/c2105f60eba379#%E3%81%AF%E3%81%98%E3%82%81%E3%81%AB)
  - ![image](https://github.com/yoshikikasama/system/assets/61643054/de6a1cd4-1bf3-45a5-a1dd-d9e63626cc94)
  - ![image](https://github.com/yoshikikasama/system/assets/61643054/c63c2766-b906-42a8-9ac6-75cf85492b50)
  - ![image](https://github.com/yoshikikasama/system/assets/61643054/89cb5d86-efe2-44fe-a3c8-b78241ddb325)
  - ![image](https://github.com/yoshikikasama/system/assets/61643054/6f2e0099-eb5f-43d6-838e-25598ef94e0e)
  - ソース: 使うことが多いのは圧倒的に CodeCommit と ECR です。
  - ビルド: 基本は CodeBuild
  - テスト: 基本は CodeBuild
  - デプロイ: CodeDeploy
  - 承認: 必ず手動で行う必要がある

- AWS CodeBuild:

  - フルマネージドなビルドサービスでソースコードのコンパイル、テスト実行、ソフトウェアパッケージの作成を実行。python 環境 install など。
  - imutable な環境のために個々のビルドを新規 Docker コンテナで実行。
  - buildspec.yml: CodeBuild の設定ファイル。
    - version: buildspec の version 指定
    - run-as: コマンドを実行する Linux ユーザー
    - env: 環境変数
    - proxy: プロキシサーバ設定
    - batch: バッチビルド設定。ビルドのジョブを順番に制御したり、同時実行を制御したりする。
    - phases: 実行するコマンド
    - reports: テストレポート作成。pytest などの実行結果を XML などで出力する。
    - artifacts: AWS CodeBuild の出力
    - cache: キャッシュ設定
  - ![image](https://github.com/yoshikikasama/system/assets/61643054/b9b8d889-d8e4-47b6-b034-b8450b4f01bc)

- CodeDeploy

  - CodeDeploy では CloudWatch アラームを使用した自動ロールバックが可能
    - アプリケーションにアラームを追加した場合、指定された 1 つ以上のアラームがアクティブ化されたときに、CodeDeploy は最後の正常なデプロイであることがわかっているリビジョンを再デプロイします。
    - https://docs.aws.amazon.com/ja_jp/codedeploy/latest/userguide/deployment-groups-configure-advanced-options.html
  - CodeDeploy と Amazon EC2 Auto Scaling:
    - 一度に一つのインスタンスをデプロイし、CPU 使用率が 85%を超えた場合に自動的にロールバックする方法。
    - CodeDeployDefault OneAtTime デプロイ戦略はアプリケーションを一度に一つのインスタンスにデプロイし、残りのフリートがトラフィックに残り続けることを保証する。これはローリングアップデートの一種です。
      - ローリングアップデート: CodeDeploy は「一度に 1 つのインスタンスにデプロイ」する戦略を取ることができるので、アプリケーションの更新中にもサービスの可用性を保ちつつ、段階的に全てのインスタンスを更新できる。
    - CPU 使用率メトリクスに基づくアラームを設定し、このしきい値に違反した場合にデプロイを自動的にロールバックする。
    - 一貫性のある更新: Auto Scaling グループに新しい EC2 インスタンスが加わるたびに、CodeDeploy が自動的に最新のアプリケーションをそのインスタンスにデプロイするから、アプリケーションのバージョンが常に最新で一貫している状態を保てる。
  - 自動ロールバック: CPU 使用率などのメトリクスを監視して、デプロイメントが原因でパフォーマンスに問題が生じた場合には、自動的に以前の安定したバージョンにロールバックできるので、リスクを低減できる。
  - AWS CodeDeploy が動作する主なタイミング:

    - アプリケーションが更新された時:
      - 開発者がアプリケーションのコードや設定に変更を加え、新しいバージョンをリリースする時。これらの変更を適用するために、AWS CodeDeploy を使用して、新しいバージョンを自動的に既存のサーバーまたはインスタンスへデプロイすることができる。
    - EC2 インスタンスが増えた時:
      - Amazon EC2 Auto Scaling が動作して、トラフィックの増加や負荷の変化に応じて自動的に EC2 インスタンスの数を調整するとき。新しいインスタンスが起動された場合、そのインスタンスに最新のアプリケーションバージョンを自動的にデプロイする必要がある。AWS CodeDeploy は Auto Scaling イベントに基づいて CodeDeploy デプロイメントをトリガーするために、ライフサイクルフックを設定します。この自動デプロイメントをサポートしているため、Auto Scaling によって追加された新しい EC2 インスタンスにも、常に最新のアプリケーションが展開されるようになる。

  - AWS CodeDeploy EC2 インスタンス:

    - アプリケーション: デプロイ先のタイプを指定して作成します。デプロイ先として下記 3 タイプのリソースがサポートされます。
      - EC2/オンプレミス
      - Lambda
      - ECS
    - デプロイグループ: アプリケーションの中に複数作成可能であり、これがデプロイ対象の情報を持っています。
    - ![image](https://github.com/yoshikikasama/system/assets/61643054/ac73b1e0-3eeb-4b26-91e3-1ceb675386b4)
    - デプロイタイプ
    - ![image](https://github.com/yoshikikasama/system/assets/61643054/ac18a83e-2ed4-4bae-bf3d-580b8a4d19e8)
    - EC2 インスタンスに CodeDeploy エージェントをインストールする必要がある。

  - CodeDeploy のデプロイ設定(EC2/オンプレミス):

  | デプロイ設定                  | インプレース                                                                     | Blue/Green                                                                                                                                         |
  | ----------------------------- | -------------------------------------------------------------------------------- | -------------------------------------------------------------------------------------------------------------------------------------------------- |
  | CodeDeployDefault.AllAtOnce   | 一度にできる限り多くのインスタンスへデプロイ。1 つでもデプロイできると成功。     | 一度にできる限り多くのインスタンスへデプロイ。すべてのインスタンスへルーティングし、一つでも正常に再ルーティングできれば成功。                     |
  | CodeDeployDefault.HalfAtATime | 一度に最大で半分のインスタンスへデプロイ。少なくとも半分デプロイできると成功。   | 一度に最大で半分のインスタンスへデプロイ。一度に最大半分のインスタンスへルーティングし、少なくとも半分のインスタンスへ再ルーティングできれば成功。 |
  | CodeDeployDefault.OneAtATime  | 一度に一つのインスタンスへデプロイ。すべてのインスタンスへデプロイできると成功。 | 一度に一つのインスタンスへデプロイ。一度に一つのインスタンスへトラフィックをルーティングし、すべてのインスタンスへ再ルーティングできると成功。     |

## 第 2 分野: 設定管理と IaC

- IaC テンプレートの作成とデプロイ (AWS Serverless Application Model [AWS SAM]、AWS CloudFormation、AWS Cloud Development Kit [AWS CDK] など)
- CloudFormation StackSets を複数のアカウントと複数の AWS リージョンに適用
- 最適な設定管理サービスを決定 (AWS OpsWorks、AWS Systems Manager、AWS Config、AWS AppConfig など)
- インフラストラクチャのパターン、ガバナンスコントロール、セキュリティ標準を再利用可能な IaC テンプレート (AWS Service Catalog、CloudFormation モジュール、AWS CDK など) に実装
- アカウントのプロビジョンと設定の標準化と自動化
- アカウントの作成、統合、および一元管理 (AWS Organizations、AWS Control Tower など)
- 複数アカウントや複雑な組織構造 (SCP、ロールを引き受けるなど) に IAM ソリューションを適用
- 大規模環境でのガバナンスとセキュリティコントロールの実装と開発 (AWS Config、AWS Control Tower、AWS Security Hub、Amazon Detective、Amazon GuardDuty、AWS Service Catalog、SCP)
- システムインベントリ、設定、およびパッチ管理の自動化 (Systems Manager、AWS Config など)
- 複雑なシナリオ (AWS SDK、Lambda、AWS Step Functions など) 向けに Lambda 関数オートメーションを開発
- ソフトウェアアプリケーションを希望の状態に自動設定 (OpsWorks、Systems Manager ステートマネージャーなど)
- ソフトウェアコンプライアンスの維持 (Systems Manager など)

### 試験メモ

- AWS Lambda のバージョンとエイリアス:

  - Lambda 関数のバージョンで 1 つの Lambda 関数に対して複数のバージョンを発行することが可能です。
  - エイリアスごとに異なる Lambda 関数のバージョンを指定できるため、開発環境と本番環境で異なるバージョンを選択することが可能です。
  - <img width="795" alt="image" src="https://github.com/yoshikikasama/system/assets/61643054/50075baa-1df9-467c-bb18-4e02ed725f62">
  - 上図では開発向けの dev エイリアスと本番向けの prod エイリアスを用意しています。そして、開発向けの dev エイリアスは$LATEST を利用して、常に最新バージョンの Lambda が起動するように設定しています。一方、本番向けは V1 と V2 でトラフィック分割をしています。これは一気に新しいバージョンに切り替えることによる思わぬトラブルを避けるためです。

- API Gateway:

  - Edge-Optimized は、クライアントに最も近い AWS Edge Location で API をホストし、低レイテンシーでアクセスできます。デフォルト設定
  - Regional は特定の AWS リージョン内に API を展開し、そのリージョン内のすべてのエンドユーザーに向けて高パフォーマンスな接続を提供します。
  - Private は VPC 内で API をホストし、パブリックインターネットを経由せずにプライベートネットワーク内でアクセス可能です。
  - API Gateway はカナリアリリースも可能です。カナリアリリースをするときには既存のステージに結び付く Canary と呼ばれる特別なステージを作成してリリースします。あるステージに対して Canary ステージを定義するとデプロイ操作がいったん、Canary のみに行われます。その後、トラフィックをシフトしてメインにもデプロイを反映する昇格か変更を切り戻す削除化を選ぶことができます。

- CloudFormation:

  - CodePipeline でデプロイ時に CloudFormation スタックが IAM ロールを作成する権限がない場合は InsufficientCapabilitiesException エラーが出る。そのため、　 DeployCloudFormation ステージアクションで IAM の機能を有効にする。
  - エラー内容：AWS CloudFormation でスタックを作成しようとすると、InsufficientCapabilities Exception というエラーが発生しました。
  - 原因：スタック作成に必要な権限を指定していないためです。CloudFormation は、スタックを作成する際に、テンプレートが特定の権限（IAM リソース）を含んでいるかどうかを確認する必要があります。この確認を行うために --capabilities オプションを使います。このオプションを指定しないと、セキュリティ上の理由でスタック作成が拒否され、エラーが発生します。
    - CAPABILITY_NAMED_IAM: テンプレート内で特定の名前を持つ IAM ロールを定義している場合
    - CAPABILITY_IAM: テンプレート内で IAM ロールを定義していますが、名前を指定していない場合
  - cfn-hup :
    - AWS CF のメタデーターを 1 回実行する。
    - 通常は(EC2 の)ユーザーデーターの一部として実装される
  - cfn-init:
    - AWS CF のメタデーターをモニタリングし、変更を検出した場合に適用される。
  - AWS CloudFormation のエラー「指定された期間内に X 個のリソースシグナルを受信できませんでした」を解決するには
    - Amazon Elastic Compute Cloud (Amazon EC2) インスタンス、Auto Scaling グループ、または WaitCondition が CreationPolicy 属性で指定された期間内に 1 つ以上のインスタンスから成功シグナルを受信しない場合にこのエラーが発生します。
      - シナリオ 1: cfn-signal スクリプトが AWS CloudFormation スタックの 1 つ以上のインスタンスにインストールされていません。
      - シナリオ 2: AWS CloudFormation テンプレートに構文エラーまたは正しくない値があります。
      - シナリオ 3: CreationPolicy 属性の Timeout プロパティの値が小さすぎます。
      - シナリオ 4: Amazon EC2 インスタンスから cfn-signal が送信されていません。
  - cfn-signal ヘルパー スクリプト: Amazon EC2 インスタンスが正常に作成または更新されたかどうかを CloudFormation に通知します。インスタンスにソフトウェア アプリケーションをインストールして構成すると、それらのソフトウェア アプリケーションの準備ができたときに CloudFormation に通知できます。cfn-signal スクリプトは、CreationPolicy 属性または WaitOnResourceSignals 更新ポリシー を持つ Auto Scaling グループと組み合わせて使用します。 CloudFormation は、これらのポリシーを使用してリソースを作成または更新すると、リソースが必要な数のシグナルを受信するか、タイムアウト期間を超えるまで、スタック上の作業を一時停止します。 CloudFormation が受信する有効なシグナルごとに、CloudFormation はシグナルをスタック イベントに発行して、各シグナルを追跡できるようにします。
  - CloudFormation での AutoScalingGroup 配下のインスタンス入れ替え方法:
    - UpdatePolicy 属性の AutoScalingRollingUpdate ポリシー: 既存の AutoScalingGroup 配下のインスタンスを数台ずつ入れ替えていく方法。スケーリングアクティビティが古いインスタンスを新しいインスタンスに徐々に置き換えるのを待つ代わりに、Auto Scaling グループ内のインスタンスのローリング更新を実行するには、AutoScalingRollingUpdate ポリシーを使用します。このポリシーは、CloudFormation が Auto Scaling グループ内のインスタンスをバッチ単位で置き換えるか、リソース全体を置き換えずにすべてのインスタンスを一度に置き換えるかを指定する柔軟性を提供します。
    - UpdatePolicy 属性の AutoScalingReplacingUpdate: 新しい AutoScalingGroup を作成して、新旧のグループを入れ替える方法。
  - Auto Scaling ライフサイクルフック: インスタンスが Auto Scaling Group に参加したり、グループから離脱する前に特定のアクションを実行するために使用される。これはインスタンスの準備やクリーンアップなどのタスクに適しており、デプロイ処理では使用しない。

- CloudFormation のスタックポリシー（Stack Policy）
  - 目的: スタックポリシーは、CloudFormation スタックの更新中に特定のリソースが誤って変更されることを防ぐために使用されます。
  - 使用方法: スタックポリシーは JSON 形式で定義され、スタックの作成または更新時に適用されます。リソースの更新を制御し、保護するために、特定のリソースに対する更新操作を許可または禁止するルールを設定します。
  - 例: 特定の S3 バケットやデータベースインスタンスが誤って更新されないように保護します。
- CloudFormation の Update Policy（更新ポリシー）

  - 目的: 更新ポリシーは、Auto Scaling グループや Amazon ECS サービスなどのリソースがどのように更新されるかを指定するために使用されます。特にローリング更新（Rolling Update）などのデプロイメント戦略を制御します。
  - 使用方法: Update Policy は CloudFormation テンプレート内でリソースに対して設定され、更新中のリソースの動作を指定します。例えば、Auto Scaling グループのインスタンスをバッチで更新する方法や、一度に更新するインスタンスの数を設定します。
  - 例: Auto Scaling グループ内の EC2 インスタンスをローリングアップデートする場合。

- AWS CloudFormation StackSets の「自動デプロイ設定」を有効にします。
  ```bash
  aws cloudformation create-automatic-deployment-rule \
    --stack-set-name EnableConfigStackSet \
    --automatic-deployment-enabled true \
    --retained-stacks OrgId=<OrganizationsId>
  ```
  - これで、新しい AWS アカウントが作成されたときに、自動的に AWS Config を有効にする CloudFormation StackSet の設定が完了しました。これにより、全ての新しいアカウントに対して一貫した設定を自動的に適用することができます。

## 第 3 分野: 耐障害性の高いクラウドソリューション

- ビジネス要件を技術的耐障害性のニーズに変換
- 既存のワークロードで単一障害点を特定して修正
- 利用可能な場合はクロスリージョンソリューションを有効化 (Amazon DynamoDB、Amazon RDS、Amazon Route 53、Amazon S3、Amazon CloudFront など)
- クロス AZ サービスをサポートするためにロードバランシングを設定
- ダウンタイムを最小限に抑えながら、複数のアベイラビリティーゾーンとリージョンをサポートするようにアプリケーションと関連サービスを設定
- スケーリングに関する問題を特定して修正
- 適切なオートスケーリング、ロードバランシング、およびキャッシュソリューションを特定して実装
- コンテナベースのアプリケーション (Amazon ECS、Amazon EKS など) のデプロイ
- 複数のリージョンにワークロードをデプロイしてグローバルなスケーラビリティを実現
- サーバーレスアプリケーションの設定 (Amazon API Gateway、Lambda、AWS Fargate など)
- マルチ AZ とマルチリージョンのワークロード (Amazon RDS、Amazon Aurora、Route 53、CloudFront など) のフェイルオーバーのテスト
- 適切なリージョン間バックアップとリカバリ戦略 (AWS Backup、Amazon S3、Systems Manager など) の特定と実装
- バックエンドの障害から復旧するためのロードバランサーの設定

### 試験メモ

- Amazon Route53:

  - 高可用、スケーラブル、そして完全マネージド型の権威 DNS サーバです。また、Route53 は権威 DNS サーバであると同時にドメインレジスターでもあります。
  - Record: ドメインに関連付けられた各リソースのエントリーで、主にドメイン名を IP アドレスに対応付けます。Record の中には Domain/subdomain Name、Record Type、Value(IP アドレス)、Routing Policy、TTL(DNS リゾルバでのキャッシュ期間) という 5 つの設定項目があります。
    - A: ドメイン名を IPv4 アドレスに解決
    - AAAA: ドメイン名を IPv6 アドレスに解決
    - CNAME:別のドメイン名にエイリアスを設定
  - Hosted Zone: 特定のドメインに関連する DNS レコードの集合体で、各 Hosted Zone には一意の名前が付与されます。Hosted Zone 内でレコードセットを設定することで、ドメインの挙動や解決ルールを定義できます。例えば、www.example.com をどの IP アドレスに解決するかなどがホステッドゾーンで設定されます。
  - Routing Policy:ルーティング先のサービスまで含めて可能な限りダウンタイムを短くする。
    - Simple Routing Policy: 単一のリソースにトラフィックを転送します。
    - Weighted Routing Policy: 複数のリソースに対して異なる重みを設定し、トラフィックを分散させる。
    - Latency-Based Routing Policy: クライアントの地理的位置に応じてトラフィックを最も低いレイテンシを持つエンドポイントに導くことができます。グローバルに展開されたアプリケーションで効果的です。
    - Failover Routing Policy: プライマリとセカンダリの 2 つのリソースを設定し、プライマリが利用できない場合にセカンダリにトラフィックを自動的にフェイルオーバーさせます。
    - トラフィックフロー: 複数の Routing Policy を組み合わせて使用する場合に発生するレコード設定の複雑な階層構造管理をできるようにしてくれます。このサービスを利用すると Weighted Routing Policy でトラフィック分割しながらリリースできる仕組みを作りつつ、バックエンドがダウンした時に備えた Failover Routing Policy で Sorry 画面に自動で向くようにする、といったことが可能になります。

- Amazon RDS:
  - 垂直スケーリング: インスタンスサイズを変更することで、CPU、メモリ、ストレージのリソースを調整できます。
  - 水平スケーリング: リードレプリカと呼ばれる複製を作成し、リードトラフィックを分散します。リードレプリカは読み取り専用で、主データベースに対してリードトラフィックを分散させることで読み取りの性能向上が期待できます。
  - マルチ-AZ デプロイメント: データベースを自動的に複製し、プライマリデータベースとセカンダリデータベースのペアを複数の可用性ゾーンにまたがって配置します。これにより、プライマリが利用できない場合に自動的にフェイルオーバーし、高い可用性を確保します。
  - Amazon RDS は自動的にデータベースをバックアップし、連続的なバックアップのスナップショットを作成します。
- Amazon Aurora:
  - 複数の可用性ゾーンにまたがる 6 つのコピーにデータを自動的にレプリケートし、障害が発生しても瞬時にフェイルオーバーできる高可用性構成を提供します。また、Aurora Replica を使用して読み取りトラフィックを分散し、スケーラビリティを向上させることができます。
  - Amazon Aurora は自動的にデータをバックアップし、連続的なバックアップのスナップショットを作成することでデータの保護を強化します。
  - 複数の Aurora Replica を作成して、読み取りトラフィックを分散できます。これにより、大量の読み取りトラフィックに対して柔軟にスケールアウトできます。Replica はプライマリデータベースと同等のパフォーマンスを提供し、自動的なフェイルオーバーもサポートしています。
  - グローバルデータベース: 複数の AWS リージョンにまたがる Aurora データベースのレプリケーションを可能にします。これにより、異なる地理的なリージョンにおいても低レイテンシで読み取り可能なデータベースの構築が可能です。
- ![image](https://github.com/yoshikikasama/system/assets/61643054/052eb97e-66b7-4df9-b8a7-b76437ebc36a)
- DevOps エンジニアは、クロスリージョンフェイルオーバー要件を持つアプリケーションを管理します。アプリケーションは、プライマリリージョンにある Amazon RDS データベース上の Amazon Aurora にデータを保存し、セカンダリリージョンにはリードレプリカを配置します。アプリケーションは Amazon Route 53 を使用して、顧客のトラフィックをアクティブなリージョンに転送します。プライマリデータベースに障害が発生した場合、ダウンタイムを最小限に抑えるには、どの手順を実行する必要がありますか？

  - Amazon RDS イベント通知を設定することで、Amazon SNS 通知と AWS Lambda 関数をトリガーにしてリードレプリカを昇格させ、Amazon Route 53 でトラフィックをセカンダリリージョンに転送誘導することができます。Amazon RDS では、Amazon RDS のイベントが発生したときに、Amazon Simple Notification Service (Amazon SNS) を使用して通知を送信します。これらの通知には、AWS リージョンの Amazon SNS でサポートされているすべての通知形式を使用できます (E メール、テキストメッセージ、HTTP エンドポイントへの呼び出しなど)。

- ![image](https://github.com/yoshikikasama/system/assets/61643054/c4d38a52-2024-4761-b7a5-9fec157a78ae)

  - Route 53 エイリアスレコードとヘルスチェック
    - Route 53 ヘルスチェック: Route 53 を使用してプライマリリージョンの ALB のヘルスチェックを行います。ヘルスチェックが失敗した場合、トラフィックを災害復旧リージョンにリダイレクトします
    - ALB は EC2 インスタンスのヘルスチェックを行い、不健全なインスタンスがあればそのインスタンスへのトラフィックを停止します。
    - Route 53 は ALB のヘルスチェックを行い、ALB 全体が不健全と判断された場合、トラフィックを災害復旧リージョンにリダイレクトします。
  - ALB と Auto Scaling グループ
    - Primary Region (us-east-1): プライマリリージョンには、Application Load Balancer (ALB) と Auto Scaling グループが設定されており、複数のアベイラビリティーゾーンにまたがってアプリケーションを実行します。
    - Disaster Recovery Region (例: us-west-2): 災害復旧リージョンにも同様に ALB と Auto Scaling グループを設定します。この構成はプライマリリージョンの障害時に迅速に切り替えられます。
  - RDS インスタンスとリードレプリカ
    - プライマリリージョンの RDS (Multi-AZ): データベースはプライマリリージョンにマルチ AZ 配置で設定されています。
    - 災害復旧リージョンの RDS リードレプリカ: 災害復旧リージョンにはリードレプリカを設定します。プライマリリージョンで障害が発生した場合、AWS Lambda と CloudWatch Events を使用してリードレプリカをマスターに昇格させます。

- Amazon ElastiCache for Redis は、レプリケーションとシャーディングによりスケーラビリティを実現しています。

  - レプリケーションはクラスターモードを無効化している場合のオプションです。ElastiCache はプライマリキャッシュノードに対して複数のリードレプリカを作成できます。
  - これにより、読み取りトラフィックを分散させ、単一のプライマリによる負荷を軽減することができます。なお、リードレプリカはプライマリに対して非同期で更新され、耐障害性を向上させます。
  - ![image](https://github.com/yoshikikasama/system/assets/61643054/b2bba4ee-7bce-435b-93b0-41394f3fb7e8)
  - シャーディングはクラスターモードを有効化している場合のオプションです。キャッシュデータを複数のシャードに分割することで、水平方向のスケーリングを可能にします。
  - ![image](https://github.com/yoshikikasama/system/assets/61643054/96212586-83a9-4f5a-a4b8-c098f4f04d33)
  - 各シャードは独自のキャッシュエンジンのインスタンスを持ち、負荷が均等に分散されます。これにより、大量のデータやトラフィックにも柔軟に対応できます。
  - クラスターモードで使う場合のみオートスケーリングも利用可能です。
  - Amazon ElastiCache でディザスタリカバリを考える必要がある場合にはスナップショットの定期取得とマルチ-AZ デプロイメントがベストプラクティスです。ただし、どちらも Amazon ElastiCache for Redis でしか利用できず、Amazon ElastiCache for Memcached では使えないことは留意してください。
  - スナップショット: 定期的にスナップショットを作成し、データを Amazon S3 に保存します。これにより、データの永続性を確保し、障害やデータ損失の際にはスナップショットからデータを復元できます。
  - マルチ-AZ デプロイメント: マルチ-AZ デプロイメントがサポートされています。これにより、プライマリキャッシュノードとセカンダリキャッシュノードが異なる可用性ゾーンに配置され、プライマリに障害が発生した場合に自動的にセカンダリにフェイルオーバーします。
  - Amazon ElastiCache for Reids と Amazon ElastiCache for Memcached の比較:
  - ![image](https://github.com/yoshikikasama/system/assets/61643054/6a4a58b7-c204-4a7f-a899-c54bbf9024db)

- Amazon DynamoDB:

  - DynamoDB Streams は、データベース内の変更をリアルタイムで捕捉する機能を提供します。これにより、データの変更に対してトリガーを設定して、リアルタイムアプリケーションやイベント駆動型サービスを構築できます。
  - DynamoDB Accelerator（DAX）は、インメモリキャッシュを提供し、ミリ秒単位のレイテンシでデータへのアクセスを可能にします。
  - ![image](https://github.com/yoshikikasama/system/assets/61643054/533ecfce-9bd8-4d97-b2b5-8411d7a7a3e2)
  - DAX は DynamoDB に特化しており、DynamoDB へのアクセスを高速化する際に理想的です。一方、ElastiCache は Redis や Memcached を使用することで、汎用的なデータキャッシュソリューションとして広く利用されます。
  - DynamoDB Global Table: 複数の AWS リージョンにまたがるデータの自動的なレプリケーションをサポートします。グローバルテーブルは、書き込み可能なプライマリリージョンと、読み取り専用のセカンダリリージョンを指定でき、地理的な近接性に応じてトラフィックを分散させることが可能です。

- Auto Scaling Groups

  - スケーリングポリシー:
    - Target Tracking Scaling: 事前に設定したメトリクスの目標値を保ちながら自動的にスケーリングします。例えば、CPU 使用率やネットワークトラフィックの目標値を指定できます。
    - Simple Scaling/Step Scaling: 特定のメトリクスの閾値を超えた場合に、指定された数だけインスタンスを追加または削除します。例えば、CPU 使用率が閾値を超えたら 2 台追加、といった指定が可能です。
    - Scheduled Actions: 予め定義された時間に定義された台数だけスケーリングします。
    - Predictive Scaling: 機械学習を使用して CloudWatch からの履歴データに基づいたキャパシティー要件を予測しスケーリングポリシーを定義します。
  - ターミネートポリシー:
    - Default: 異常なく運用されているインスタンスから順に選択して終了します。
    - OldestInstance: 最も古い起動時間を持つインスタンスが優先的に終了されます。
    - NewestInstance: 最も新しい起動時間を持つインスタンスが優先的に終了されます。
  - ウォームプール: インスタンスが追加される前に、事前に起動しておくプールのことを指します。これにより、インスタンスが必要になったときに素早く対応でき、起動にかかる時間を最小限に抑えることができます。

- AWS のディザスタリカバリ (DR) アーキテクチャ、パート II: 迅速なリカバリによるバックアップと復元:
- ![image](https://github.com/yoshikikasama/system/assets/61643054/d758cd18-d6ef-4b55-959a-592168a70abf)
- DR 戦略のアーキテクチャ:

  - バックアップと復元:
    - ![image](https://github.com/yoshikikasama/system/assets/61643054/ce3b2ab2-ec92-4915-acff-d902f4de470e)
    - さまざまな AWS データ リソースのバックアップを示しています。バックアップはソースと同じリージョンに作成され、別のリージョンにもコピーされます。これにより、あらゆる影響範囲の災 ​​ 害から最も効果的に保護されます。バックアップとリカバリの戦略は、RTO の面で最も効率が悪いと考えられています。ただし、Amazon EventBridge などの AWS リソースを使用してサーバーレス自動化を構築することで、検出とリカバリを改善し、RTO を短縮できます。
  - Pilot Light:
    - ![image](https://github.com/yoshikikasama/system/assets/61643054/f2b1d938-dc2b-4b49-afe3-1b51332431b7)
    - 重要なデータはライブですが、サービスはアイドル状態です。ライブ データとは、データ ストアとデータベースがアクティブ リージョンで最新 (またはほぼ最新) であり、読み取り操作に対応できる状態であることを意味します。Elastic Load Balancing や Amazon EC2 Auto Scaling などの基本的なインフラストラクチャ要素が配置されています。ただし、機能要素 (コンピューティングなど) は「シャット オフ」になっています。クラウドでは、Amazon EC2 インスタンスをシャット オフする最善の方法は、それをデプロイしないことです。図 6 では、デプロイされたインスタンスが 0 個であることを示しています。これらのインスタンスを「オン」にするには、以前に構築され、すべてのリージョンにコピーされた Amazon マシン イメージ (AMI) を使用します。この AMI は、必要なオペレーティング システムとパッケージを備えた Amazon EC2 インスタンスを作成します。点火されるまで家を暖めることができない炉のパイロット ライトのように、パイロット ライト戦略は、残りのインフラストラクチャをデプロイするためにトリガーされるまで、リクエストを処理できません。
  - ウォームスタンバイ:
    - ![image](https://github.com/yoshikikasama/system/assets/61643054/6c8bcaf8-fc81-47ab-ae73-83072a7422a4)
    - パイロット ライト戦略と同様に、ウォーム スタンバイ戦略では、定期的なバックアップに加えてライブ データを維持します。この 2 つの違いは、インフラストラクチャと、その上で実行されるコードです。ウォーム スタンバイでは、リクエストを処理できる最小限のデプロイメントが維持されますが、容量は削減され、実稼働レベルのトラフィックを処理できません。これは、図 7 に示されており、層ごとに 1 つの Amazon EC2 インスタンスがデプロイされています。これにより、パッシブ エンドポイントで合成テスト トランザクションを送信する前に処理するための追加作業が不要になるため、ウォーム スタンバイのテストが容易になります。フェイルオーバーの前に、インフラストラクチャをスケールアップして実稼働のニーズを満たす必要があります。
  - マルチサイト アクティブ/アクティブ:
    - ![image](https://github.com/yoshikikasama/system/assets/61643054/e1f2176c-100a-40aa-8b2b-90913c589da5)
    - マルチサイト アクティブ/アクティブでは、2 つ以上のリージョンがリクエストをアクティブに受け入れます。フェイルオーバーは、リクエストを処理できないリージョンからリクエストを再ルーティングすることで構成されます。ここでは、データはリージョン間で複製され、それらのリージョンで読み取りリクエストを処理するためにアクティブに使用されます。書き込みリクエストの場合、ローカル リージョンへの書き込みや特定のリージョンへの書き込みの再ルーティングを含むいくつかのパターンを使用できます。

- [Amazon RDS を使った災害復旧戦略の実装](https://aws.amazon.com/jp/blogs/news/implementing-a-disaster-recovery-strategy-with-amazon-rds/)

  - リカバリータイムオブジェクティブ (RTO) と、リカバリーポイントオブジェクティブ (RPO) の 2 つは、考慮すべき主要なメトリクスとなります。RTO は、災害が発生した後、業務再開にどの位の時間を要するかを表します。RPO も同じ様に時間で表現されますが、こちらは、災害が発生した際にどの規模のデータが失われるかを表します。例えば、RPO が 1 時間であるということは、災害の発生により 1 時間分に相当するデータが失われる可能性があるという意味です。

- Aurora

  - 地域が完全に停止した場合でも 1 分以内に回復可能。
  - フェイルオーバーの手順。
    - RDS Event Notification を使用して、Amazon SNS トピックにステータスアップデートを公開。
    - トピックにサブスクライブされた AWS Lambda 関数を使用して、データベースの健全性を監視。
    - 障害が発生した場合、Lambda 関数は読み取りレプリカを促進し、Route 53 を更新して、プライマリ領域からセカンダリ領域へトラフィックをリダイレクトする。

- RDS のマルチ AZ 構成をリージョン間で構成するという意味不明な選択肢
  - マルチ AZ だって書いてあるのに、なぜリージョンが出てくるんですか。
  - RDS や Aurora でマルチリージョンにする場合、大体はリードレプリカが正解です。
- CodeDeploy のロールバックは CloudWatch アラームを関連付ける

  - CloudWatch Events や CloudWatch Logs を関連付けるは間違いです。
  - CloudWatch アラームを関連付けることで自動ロールバックできます。オペレーションで CodeDeploy 使用しているインスタンスまたは Amazon EC2 Auto Scaling グループの CloudWatch アラームを作成できます。アラームは、指定期間にわたって単一のメトリクスを監視し、その値と複数期間に対するしきい値との比較結果に基づいて 1 つ以上のアクションを実行します。 CloudWatch アラームは、状態が変化したときにアクションを呼び出します (例: から OK）ALARM。

- AutoScaling グループのインスタンスの CPU 使用率が一定を超えた場合に展開をロールバックするにはどうすればいい？

  - Blue/Green デプロイを実行するように System manager を設定する。CPU 使用率を cloudwatch で確認し、超えた場合にアラームを出して自動ロールバックするようにしておく。

- Amazon Timestream:

  - 高速かつスケーラブルなサーバレス時系列データベースサービスです。
  - ![image](https://github.com/yoshikikasama/system/assets/61643054/7efd8d9a-5f75-41c6-a1ba-171f0148976f)
  - 一番大きな単位としてデータベース (Database) があり、その中に複数のテーブル (Table) を持つことができ、そのテーブルの中に複数のタイムシリーズ (Time-Series) が入っています。タイムシリーズ (Time-Series) は時系列に並んだレコード (Record) のまとまりとなっていて、その中にディメンション（Dimension）と呼ばれる測定値を識別するための属性情報とメジャー (Measure) と呼ばれる測定値でテーブル内で一意に決まるものに対して、タイムスタンプごとにレコード (Record) と呼ばれる単一のデータポイントが記録されています。
  - Timestream table に対して毎日クエリを実行する際の最速クエリパフォーマンスについて:
    - バッチ処理書き込み: 複数のログイベントを 1 回の書き込み操作で処理することができ、ネットワーク遅延や書き込み回数によるオーーバーヘッドが軽減されるため、大量のデータ生成において効率的。
    - マルチメジャーレコード: 1 つのレコードに複数のメトリクスを含めることができる。これは 1/10 秒ごとに 5 つの異なるメトリクスを含むログイベントのように、多様なデータポイントを持つログを扱う場合に有効。サーバの CPU、メモリ量、スワップ、ディスクの使用状況を取得するシンプルな監視アプリケーションを作成しました。その際、4 つの測定値はシングルメジャーレコードのデータモデルを利用してそれぞれ別のレコードとして書き込んでいました。これをマルチメジャーレコードを使うと、4 つの測定値は同時に取得されるので、1 つのレコードとして格納され、まとめてクエリを実行する事が出来ます。マルチメジャーレコードを利用すると、テーブルに書き込まれるレコード数を削減する事が出来ます。以前はメジャー毎に 1 つずつ、計 4 レコードを書き込んでいましたが、今回のアップデートで同時に取得した 4 つのメジャー値を 1 行のマルチメジャーレコードとして書き込む事が出来ます。また、ストレージの使用料も減りますが、以前と同じ情報量を保持しています。処理するデータ量が減少する為、マルチメジャーレコードでクエリを実行する方が簡単で効率的です。例えば、結合を使用して同じクエリで複数のメジャーを取得する必要も無い為、全体的なコスト削減にもつながります。
      - ![image](https://github.com/yoshikikasama/system/assets/61643054/03ca76df-efd5-4b43-9d96-3c6f2b75bda1)
      - ![image](https://github.com/yoshikikasama/system/assets/61643054/3ca9c80b-f33e-463e-a1d7-03ab58be3e5a)
    - マグネティックストレージへの書き込み:データのライフサイクルを直近データのメモリストアと履歴データのマグネティックストアという 2 つのストレージ階層で管理しています。メモリストアからマグネティックストアへのデータの移動は設定したポリシーに応じて自動的に実施されます。以前はデータはメモリストアにしかロード出来ず、遅れて到着するデータを格納する為には、メモリストアの保持時間を拡張して対応する必要がありました。今回、直接マグネティックストアに書き込む事が出来るようになり、ストレージコストを削減する事が出来ます。時系列データを扱う場合には、遅れて到着するデータ (タイムスタンプが過去) についても考慮する必要があります。データが遅れて到着する理由は多数ありますが、制御出来ない事が大半です。例えば、アプリケーションやデバイスが停止したり、一時的にネットワークから切断された後、オンラインに戻った際に滞留していたデータが一度に送信するようなケースが考えられます。以前の Timestream ではメモリ保持期間外のデータを書き込むとエラーとして処理していた為、遅延したデータを取り込むには、テーブルのメモリストアの保持期限を増やす必要がありました。今回、テーブルの設定を有効化するだけで、遅れて到着したデータをマグネティックストレージに直接書き込めるようになりました。メモリストアに書き込む場合と同様に、WriteRecord API を利用すると、書き込むデータのタイムスタンプとテーブルのメモリストア保持期間に応じて、メモリ／マグネティックストレージのいずれかに自動的にルーティングされます。
    - メモリストアは頻繁にアクセスされる最新のデータのための高速アクセス層、磁気ストアは長期的なデータ保持とコスト効率の良いクエリパフォーマンスのために設計されている。

| 構成要素名                   | 構成要素説明                                               |
| ---------------------------- | ---------------------------------------------------------- |
| データベース (Database)      | テーブル (Table) を保持するコンテナ                        |
| テーブル (Table)             | タイムシリーズ (Time-Series) を保持するコンテナ            |
| タイムシリーズ (Time-Series) | ある属性値で説明できる、時系列に並んだレコードのまとまり   |
| ディメンション (Dimension)   | 測定値を識別するための属性情報セット                       |
| メジャー (Measure)           | 測定値 (名前 (measure_name) と値 (measure_value) のセット) |
| レコード (Record)            | 単一の時系列のデータポイント                               |

## 第 4 分野: モニタリングとロギング

- ログをセキュアに保存して管理
- メトリクスフィルターを使用してログイベントから CloudWatch メトリクスを作成
- CloudWatch メトリクスストリームの作成 (Amazon S3 または Amazon Kinesis Data Firehose オプションなど)
- カスタムメトリクスの収集 (CloudWatch エージェントの使用など)
- ログストレージライフサイクルの管理 (S3 ライフサイクル、CloudWatch Log グループの保持など)
- CloudWatch Log サブスクリプションを使用してログデータを処理 (Kinesis、Lambda、Amazon OpenSearch Service など)
- フィルターとパターン構文または CloudWatch Logs Insights を使用してログデータを検索
- ログデータの暗号化の設定 (AWS KMS など)
- 異常検出アラーム (CloudWatch 異常検知など)
- 一般的な CloudWatch メトリクスとログ (Amazon EC2 の CPU 使用率、
- Amazon RDS でのキュー長、Application Load Balancer (ALB) の 5xx エラーなど)
- Amazon Inspector と一般的な評価テンプレート
- AWS Config ルール
- AWS CloudTrail ログイベント
- CloudWatch ダッシュボードと Amazon QuickSight ビジュアライゼーションの構築
- CloudWatch アラームと CloudWatch メトリクス (標準およびカスタム) との関連付け
- さまざまなサービス (コンテナ、API Gateway、Lambda など) 用に AWS XRay を設定
- リアルタイムログストリームの分析 (Kinesis Data Streams の使用など)
- AWS のサービスでのログの分析 (Amazon Athena、CloudWatch Logs Insights など)
- オートスケーリングのソリューションの設定 (DynamoDB、EC2 Auto Scaling グループ、RDS ストレージのオートスケーリング、ECS キャパシティープロ
  バイダーなど)
- CloudWatch カスタムメトリクスとメトリクスフィルター、アラーム、通知(Amazon SNS、Lambda など) の作成
- ログファイルを処理し (例えば Lambda を使用)、ログファイルを(OpenSearch Service、CloudWatch Logs などの) 別の送信先に配信するよう
  に S3 イベントを設定
- 特定のイベントパターンに基づいて通知を送信するように EventBridge を設定
- EC2 インスタンスにエージェントをインストールして設定 (AWS Systems Manager Agent [SSM Agent]、CloudWatch エージェントなど)
- 問題を修復するために AWS Config ルールを設定
- ヘルスチェックを設定 (Route 53、ALB など)

### 試験メモ

- Amazon CloudWatch Metrics:

  - Namespace: 論理的なグループにメトリクスを分類します。Namespace は AWS サービスやカスタムアプリケーションごとに異なり、メトリクスの一元管理を可能にします。AWS サービスのメトリクスは通常、そのサービス名が Namespace として使用されます。たとえば、Amazon EC2 のメトリクスは AWS/EC2 という Namespace に属します。
  - Dimension: メトリクスを更に特定化するためのキー/バリューペアであり、メトリクスデータをより細かく分類します。例えば、EC2 インスタンスの CPU 使用率をモニタリングする場合、インスタンス ID がディメンションとなります。ディメンションを指定することで、同じメトリクスでも異なるコンテキストでのデータを取得できます。

- Amazon GuardDuty
  - AWS 環境における脅威検出サービス
  - 異常な活動の検出、セキュリティインシデントのアラート
  - 既存の AWS アカウントと今後作成する AWS アカウントで、侵害された可能性のある EC2 インスタンス、疑わしいネットワークアクティビティ、異常な API アクティビティを検出したい。これらのイベントを検出した場合、既存の Amazon SNS トピックを使用して、調査と修復のために運用サポートチームに通知を送信したい。
  - AWS Organizations を使用した GuardDuty アカウントの管理:
    - 一元化され「委任」された Amazon GuardDuty の管理者アカウントを作成して、すべての GuardDuty チェックを処理できる。具体的には、管理者アカウントによって、すべての GuardDuty イベントに対する監視と制御が集中化できます。これは、セキュリティイベントの管理と対応における効率性と一貫性を高めることができます。また、Amazon EventBridge のルールを作成することで、GuardDuty イベントを Amazon SNS トビックに転送できます。これにより、セキュリティイベントが発生した場合、即時に運用サポートチームに通知することができます。
    - ※補足：一つの管理者アカウントが他のアカウントのセキュリティ監視機能を集中管理するという方法を採用しています。ここでの「委任」とは、セキュリティ監視の責任をこの管理者アカウントに集中させることを意味します。具体的には、管理者アカウントは組織内の全 AWS アカウントに対する Amazon GuardDuty のアラートとチェックを一手に引き受け、必要に応じて対応を行います。これにより、セキュリティの管理が一元化され、効率的かつ一貫した対応が可能になります。また、Amazon EventBridge を用いて、発生したセキュリティイベントを Amazon Simple Notification Service （SNS） トピックに自動的に転送し、運用サポートチームへの通知を行う仕組みが含まれています。
  - 潜在的なセキュリティリスクがないか、 AWS お客様の環境を継続的に監視する脅威検出サービスです。 GuardDuty AWS CloudTrail 管理イベント、 AWS CloudTrail イベントログ基礎データソース、VPC フローログ (Amazon EC2 インスタンスから)、DNS ログなどの分析と処理を行います。 GuardDuty また、 AWS 他のサービスからのモニタリングログやイベントも提供します。これらのソースには、Kubernetes 監査ログ、RDS ログインアクティビティ、S3 ログ、EBS ボリューム、ランタイムモニタリング、Lambda ネットワークアクティビティログが含まれます。 GuardDuty これらのログとイベントのソースを「機能」という用語で統合したものです。
  - また、 EventBridge GuardDuty 結果が生成されたときに通知を受け取るように設定できる。
  - GuardDuty を Organizations で使用する場合、 AWS その組織の管理アカウントは、 GuardDuty 組織内の任意のアカウントを委任管理者アカウントとして指定できます。この管理者アカウントでは、 GuardDuty 指定されたユーザーでのみ自動的に有効になります。 AWS リージョンこのアカウントには、 GuardDuty その地域内の組織内のすべてのアカウントを有効化および管理する権限もあります。管理者アカウントは、 AWS この組織のメンバーを表示したり、メンバーを追加したりできます。
- Cloud Trail
  - AWS アカウントの API コールを記録、監査するサービス
  - API コールの監査、変更追跡
- Security HUB
  - セキュリティのベストプラクティスに基づいて AWS 環境のセキュリティを監視します。
  - 適用外の理由: IAM ユーザーが最後にアクセスした日を提供するだけで、90 日間アカウントにアクセスしていないユーザーの認証情報を取り消す要件を満たしていません。
- Config:
  - CloudFormation 変更検出
  - 暗号化されていない EBS ボリュームを検出
  - 送信は、SNS TOPIC or SSM Run Command
  - 詳細な監視: AWS Config は、AWS リソースの設定変更を詳細に追跡し、リソースがコンプライアンスに準拠しているかを確認できます。
  - 自動修復: 管理対象のルールに基づいてリソースの状態を評価し、自動で修復することができます。
  - 一元管理: すべてのリソースを一元的に監視し、統一されたポリシーで管理できます。
- Amazon Macie
  - AWS のデータセキュリティサービス。データの可視化と保護
  - データ検出、機密データの保護
- Trusted Advisor
  - アカウントのベストプラクティスをチェックし、コスト削減やセキュリティ向上を支援します。
  - Trusted Advisor は IAM アクセスキーのローテーションをチェックしますが、IAM ユーザーの非アクティブな認証情報を取り消す要件を満たしていません。
- AWS Identity and Access Management (IAM) Access Analyzer
  - Access Analyzer の目的: アクセス権の監査とリスク評価を行います。
  - 適用外の理由: 非アクティブな IAM ユーザーの認証情報を取り消すのではなく、ポリシーをデタッチするだけなので要件を満たしていません。
- Cloud Trail
- Security HUB
  - セキュリティのベストプラクティスに基づいて AWS 環境のセキュリティを監視します。
  - 適用外の理由: IAM ユーザーが最後にアクセスした日を提供するだけで、90 日間アカウントにアクセスしていないユーザーの認証情報を取り消す要件を満たしていません。
- Config:
  - CloudFormation 変更検出
  - 暗号化されていない EBS ボリュームを検出
  - 送信は、SNS TOPIC or SSM Run Command
  - 詳細な監視: AWS Config は、AWS リソースの設定変更を詳細に追跡し、リソースがコンプライアンスに準拠しているかを確認できます。
  - 自動修復: 管理対象のルールに基づいてリソースの状態を評価し、自動で修復することができます。
  - 一元管理: すべてのリソースを一元的に監視し、統一されたポリシーで管理できます。
- Amazon Macie
- Trusted Advisor
  - アカウントのベストプラクティスをチェックし、コスト削減やセキュリティ向上を支援します。
  - Trusted Advisor は IAM アクセスキーのローテーションをチェックしますが、IAM ユーザーの非アクティブな認証情報を取り消す要件を満たしていません。
- AWS Identity and Access Management (IAM) Access Analyzer
  - Access Analyzer の目的: アクセス権の監査とリスク評価を行います。
  - 適用外の理由: 非アクティブな IAM ユーザーの認証情報を取り消すのではなく、ポリシーをデタッチするだけなので要件を満たしていません。
- Amazon GuardDuty で悪意のある攻撃を検知し、その管理アカウントで CloudWatch ルールを作成しその結果を kinesis data 　 firehose から S3 に送信する。

- AWS Organizations で組織全体に対してセキュリティ標準を実施し、コンプライアンスにつながる AWS サービスの設定ミスをほぼリアルタイムで特定したい場合:

  - AWS Confg の設定レコーダー: AWS リソースの設定変更を検出し、これらの変更を設定項目として取り込みます。
  - AWS Security HUb: セキュリティに関する情報を一元的に管理できる。

- AWS Config:

  - Configuration Recorder による記録(Record):設定レコーダーはリージョンごとに 1 つのみ作成できます。設定レコーダーでは以下のようなパラメータを指定します。
    - 記録するリソースタイプ (「すべて」 もしくは 「特定のリソースタイプ」)
    - 記録頻度 (「継続的な記録」もしくは「日時記録」)
    - Config データの保持期間
  - Config Rules による評価(Evaluate):「記録している構成情報が 理想的な状態かどうかを評価してくれる機能 」です。 評価の例としては「セキュリティグループで SSH 全開放になっていないか」や 「S3 バケットがパブリック公開されていないか」などがあります。
    - AWS Config マネージドルール: AWS が事前に定義してくれている Config ルールです。 お手軽に展開できます。Config ルールに 修復アクション を関連付けできます これにより非準拠になったリソースに対して、修復を簡単に実行できます。
    - AWS Config はデフォルトで AWS Security Hub と統合 されています。 Security Hub 上で Config ルールの結果を確認できます。
    - 修復アクション: AWS Config ルールに紐づける形で設定します。ルールによる評価の結果「非準拠」になったリソースに対して修復アクション（リソースの設定変更）を行い、「準拠」状態へ遷移させることができます。修復の実行を「自動」で行うか「手動」で行うかを選択可能です。修復アクションは AWS Systems Manager の Automation ドキュメントによって行われます。
    - ![image](https://github.com/yoshikikasama/system/assets/61643054/afb5b4a7-67ae-4629-ba6b-470bccfaf350)
    - ![image](https://github.com/yoshikikasama/system/assets/61643054/ce435d24-270b-4e6f-9bab-f157f5e02d48)
    - AWS Config 適合パック(コンフォーマンスパック): 適合パックは一つのエンティティであり、複数作成することができます。適合パックの中心となるのはテンプレートです。 CloudFormation と同じような記法で一つ以上の AWS Config ルール（および必要に応じて修復アクション）を定義し、一括でデプロイすることができます。デプロイされた Config ルールは個別に作成された場合と同様に管理することもできますし、適合パックというグループの中で管理することもできます。
    - ![image](https://github.com/yoshikikasama/system/assets/61643054/693339fc-79a2-4ed9-abe2-0e41db6f67dd)
    - 適合パックは Organizations とも連携可能なため、以下のような形でマスターアカウント配下の AWS アカウントにデプロイすることができます。このような一元管理にも対応しています。
    - ![image](https://github.com/yoshikikasama/system/assets/61643054/14ba8cea-8ce1-4cf9-a98c-e8c69e6f453d)
      - 組織内のメンバーアカウントによって設定変更できないので、組織全体でコンプライアンスを管理するのに役だつ。AWS System Manager オートメーションランブックのみを修復アクションとしてサポートしている。
    - CloudTrail や Config をマルチアカウントで有効化する場合は大体 CloudFormation Stace Sets

- AWS Config がリソースの設定を評価した結果、非準拠と判定された場合に起動できるアクション:

  - AWS Lambda:
    - 軽量な修正や即時対応が必要な場合：設定変更の監視と即時対応が必要な場合に適しています。例えば、特定の設定を変更する、通知を送る、シンプルな修復作業を行うなど。
    - カスタム評価ロジックの実装：独自のルールや複雑な評価ロジックを実装する場合に便利です。
    - トリガー例:
      - 非準拠のリソースを検出した際に通知を送信する。
      - 特定の設定変更を自動で適用する。
  - AWS Systems Manager (SSM) Automation:
    - 利用シナリオ:
      - 複雑な修復手順やオーケストレーションが必要な場合：複数ステップにわたる複雑な修復手順が必要な場合に適しています。インスタンスの停止、設定変更、再起動などの一連の作業を自動化できます。
    - 手順の標準化：修復手順を標準化し、再利用可能にする場合に便利です。
    - トリガー例:
      - 非準拠リソースを検出した際に、リソースの設定を自動的に修復する。
      - インスタンスの再配置や設定変更を一連の手順で実行する。
  - Amazon SNS (Simple Notification Service)
    - 利用シナリオ:
      - 通知が必要な場合：非準拠のリソースを検出した際に、管理者や他のシステムに通知を送る場合に適しています。
    - トリガー例:
      - 非準拠リソースが検出された際に、メールや SMS で通知を送る。

- これらのサービスの違い

  - 目的と機能の違い:
    - AWS Health: 主に AWS サービスの稼働状況やパフォーマンスに関する情報を提供し、サービス障害やメンテナンスに関するリアルタイムの通知を行います。
    - GuardDuty: 悪意のある活動の検出に特化。
    - Config: リソースの設定変更とコンプライアンスの監視に特化。
    - Security Hub: セキュリティ情報の統合管理とベストプラクティスの評価。
    - Trusted Advisor: 全般的な最適化アドバイス（コスト、セキュリティ、パフォーマンス）。
  - 監視対象の違い:
    - AWS Health: AWS サービス自体の稼働状況とユーザーリソースへの影響。
    - GuardDuty: ネットワークアクティビティやログに基づいた脅威検出。
    - Config: リソースの設定とその変更。
    - Security Hub: GuardDuty や Config など複数のソースからのフィンドイングを統合。
    - Trusted Advisor: リソース使用状況と最適化提案。
  - 通知と対応の違い:
    - AWS Health: AWS サービスのステータスに関するリアルタイムの通知。
    - GuardDuty: 異常な活動のリアルタイム通知と対応。
    - Config: 設定変更やコンプライアンス違反の通知と自動修復。
    - Security Hub: フィンドイングの統合と優先順位付けによる通知。
    - Trusted Advisor: ベストプラクティスに基づく提案と通知。

- 個別のアカウントごとにスタックをセットアップではなく、マスターアカウントや委任アカウントから Stack Sets での一括セットアップが可能です。

- AWS X-Ray:
  - AWS で動作するアプリケーションのパフォーマンスや問題を分析するためのサービスです。
  - AWS X-Ray を活用するには、まずアプリケーションに X-Ray SDK を組み込みます。X-Ray SDK を使用すると、アプリケーションが送受信するリクエストやレスポンスにトレース ID やセグメント ID などのメタデータを付与できます。これらのメタデータは、X-Ray デーモンや X-Ray インターセプターなどのエージェントによって収集され、X-Ray API に送信されます。X-Ray API では、受信したメタデータをもとにトレース情報を生成し、X-Ray コンソールや X-Ray CLI などで閲覧できるようにします。なお、監視対象が EC2 の場合には X-Ray Agent のインストールが、ECS の場合には X-Ray Agent のインストールまたは Docker コンテナが必要になります。ElasticBeanstalk や Lambda、API Gateway の場合には明示的なインストールは必要ありません。
  - サービスマップ: アプリケーションの構成要素や依存関係をグラフィカルに表示します。各ノードやエッジには、リクエスト数やエラー率、レイテンシーなどの統計情報が表示されます。
  - トレース: 個々のリクエストやレスポンスの流れを詳細に表示します。各セグメントやサブセグメントには、呼び出し元や呼び出し先、処理時間やステータスコードなどの情報が表示されます。
  - アラーム: トレース情報に基づいてアラームを設定できます。アラームは、CloudWatch と連携して、異常な状況が発生した場合に通知やアクションを実行できます。

## 第 5 分野: インシデントとイベントへの対応

- AWS イベントソースの統合 (AWS Health、EventBridge、CloudTrail など)
- イベント処理ワークフローの構築 (Amazon Simple Queue Service [Amazon SQS]、Kinesis, Amazon SNS, Lambda, Step Functions など)
- 失敗したデプロイの分析 (AWS CodePipeline、CodeBuild、CodeDeploy、
- CloudFormation、CloudWatch 模擬モニタリングなど)
- 失敗したプロセスに関するインシデントの分析 (オートスケーリング、Amazon ECS、Amazon EKS など)

### 試験メモ

- Kinesis

  - 各サーバーで Amazon Kinesis Agent を使い、ログをアップロードし、Amazon Kinesis Data 　 Firehose で AWS Lambda 関数を使用して、Amazon S3 に書き込む前にログを正規化することが可能。
    Firehose では出力先の S3 を集約することでマルチアカウントのログの一元管理が可能。

- Amazon Kinesis Data Streams: リアルタイムで大量のデータを処理し、ストリーム処理アプリケーションを構築するためのサービスです。データはシャードと呼ばれるパーティションに分割され、各シャードで並行処理が可能です。これにより、高いスループットと低いレイテンシでデータを受け取り、処理することができます。IoT センサーデータ、ログ、トランザクションデータなど、様々なデータソースからのストリームデータを受信し、リアルタイムで分析・処理する際に効果的です。

  - ![image](https://github.com/yoshikikasama/system/assets/61643054/70aa2230-4c60-4d45-8718-11e69cabe847)
  - スケーラビリティはシャード数の増減で実現します。そして、シャード数はキャパシティモードと呼ばれる設定に基づいて管理されます。なお、Amazon Kinesis Data Streams では、オンデマンドモードとプロビジョニングモードの 2 つのキャパシティモードが提供されています。

- Amazon Kinesis Data Firehose: データストリームからのデータをシンプルかつスケーラブルに受け取り、処理・保存するサービスです。

  - ![image](https://github.com/yoshikikasama/system/assets/61643054/8fc5730d-0fc2-455e-b5b1-038905bcd1b0)
  - データを指定した Amazon S3、Amazon Redshift、Amazon OpenSearch などへ直接転送でき、データの変換や加工も柔軟に設定可能です。
  - Kinesis Data Firehose は管理が簡単で、サーバーレスのアーキテクチャを提供するため、開発者はデータの取り込みや保存に集中できます。
  - Kinesis Data Stream との大きな違いは 2 つ、1)ストリームではなくバッチで書き込む点、2)データ変換処理を実装できる点です。
  - Kinesis Data Streams と比較してマネージドであることを売りにしています。そのため、スケーリングについても考慮する点はなくデータの転送が急増した場合でも、自動的にスケールアウトします。自動スケーリングにより、運用者は手動でのスケールアップやダウンの必要性から解放され、効率的なデータ処理が実現されます。

- Amazon Kinesis Data Analytics:

  - リアルタイムデータストリーム上での SQL クエリを可能にするサービスです。
  - ![image](https://github.com/yoshikikasama/system/assets/61643054/e10b581e-84c8-4d5b-a639-0345c0be9402)
  - Kinesis Data Stream や Kinesis Data Firehose と比較してデータ分析色が強く、直接データを受ける口というよりは、ほか 2 つの Kinesis が受けたものに対して SQL クエリを発行するイメージです。
  - Kinesis Data Firehose 同様、処理するデータ量やクエリの複雑さに応じて自動的にスケーリングされます。

- Amazon Kinesis シリーズの比較:

  - Kinesis Data Streams: 高いスループットが必要で、リアルタイムデータ処理を要する場合、例えば、IoT デバイスのセンサーデータやログデータのリアルタイム分析
  - Kinesis Data Firehose: サーバレス運用、データ加工可、バッチで処理するため準リアルタイム。
  - Kinesis Data Analytics: SQL によるリアルタイムデータ分析が必要で、既存の SQL スキルを活用

- Amazon SQS:

  - キューの種類を適切に選択する: FIFO キューと標準キューでは、メッセージの順序や重複性が異なります。アプリケーションの要件に応じて、最適なキューの種類を選びましょう。
  - 可視性タイムアウトを適切に設定する: 可視性タイムアウトは、メッセージの処理時間に影響します。可視性タイムアウトが短すぎると、メッセージが重複して処理される可能性があります。可視性タイムアウトが長すぎると、メッセージの処理が遅延する可能性があります。可視性タイムアウトは、メッセージの処理時間の平均値よりも少し長めに設定しましょう。
    - 可視性タイムアウト: SQS では RecieveMessage の API でキューからメッセージを取り出せます。取り出す時にはキューからメッセージは削除せず、代わりに「指定した時間内は今後 RecieveMessage では取り出せない」という状態に設定できます。SQS では、コンシューマーは処理が完了したメッセージをキューから削除する必要があります。メッセージ受け取り時に発行された ReceiptHandle を指定して DeleteMessage の API を使用することで、キューから 1 つずつメッセージを削除できます。これでプロデューサーからの 1 つの依頼が確実に完了したことを示せます。キューから取り出さないでという状態は、可視性タイムアウトで設定した時間を経過すると、再度キューから取り出せるようになります。この仕組みによって、コンシューマーが受け取ったけど処理が完了しなかったメッセージが取り出せないままキューに残り続けずに、他のコンシューマーで再試行できます。例えば、障害などで DelteMessage が送れなくなった場合など。
  - ロングポーリングを有効にする: ロングポーリングは、メッセージの到着を待つことで、空のレスポンスを減らします。ロングポーリングを有効にすると、コストやネットワークトラフィックを削減することができます。ロングポーリングは、キューまたはリクエストレベルで設定することができます。
  - バッチ処理を利用する: バッチ処理は、一度に複数のメッセージを送受信することで、レイテンシーやオーバーヘッドを減らします。バッチ処理を利用すると、スループットを向上させることができます。バッチ処理は、送信者または受信者のコードで実装することができます。
  - メッセージ属性やメッセージフィルタリングを活用する: メッセージ属性やメッセージフィルタリングは、メッセージの内容や処理方法を制御することができます。メッセージ属性やメッセージフィルタリングを活用すると、受信者が必要なメッセージだけを受け取ることができます。メッセージ属性やメッセージフィルタリングは、送信者または受信者のコードで実装することができます。
  - デッドレターキューの利用: メッセージの処理でエラーが発生した場合、デッドレターキューにリダイレクトして再処理を容易にすることができます。メッセージ処理のデバックやリドライブにも活用できます。
  - Amazon SQS デッドレターキューのリドライブポリシー: デッドレターキューにアクセスできるソースキューを指定します。このポリシーは、潜在的なデッドレターキューに適用されます。すべての送信元キューを許可するか、特定のソースキューを許可するか、すべての送信元キューを拒否するかを選択できます。デフォルトでは、すべてのソースキューがデッドレターキューを使用することを許可しています。特定のキューを許可することを選択した場合(byQueue オプション)の場合、ソースキューの Amazon リソースネーム (ARN)を使用して最大 10 個のソースキューを指定できます。denyAll を指定した場合、キューをデッドレターキューとして使用することはできません。ソースキューとデッドレターキューを指定し、さらにソースキューのコンシューマが一定回数でメッセージ処理に失敗した場合、Amazon SQS がメッセージをソースキューからデッドレターキューへ移動する条件を指定します。

- ライフサイクルフック
- インスタンスを起動または終了したときにカスタムアクションを実行できるように、ライフサイクルフックを Auto Scaling グループに追加できます。
  - Amazon EC2 Auto Scaling はスケールアウトイベントに応答すると、1 つ以上のインスタンスを起動します。これらのインスタンスは Pending 状態で起動します。Auto Scaling グループに autoscaling:EC2_INSTANCE_LAUNCHING ライフサイクルフックを追加すると、インスタンスは Pending 状態から Pending:Wait 状態に移行します。ライフサイクルアクションを完了したら、インスタンスは Pending:Proceed 状態に移行します。インスタンスが完全に設定されると、Auto Scaling グループにアタッチされて InService 状態へ移行します。
  - Amazon EC2 Auto Scaling はスケールインイベントに応答すると、1 つ以上のインスタンスを終了します。これらのインスタンスは Auto Scaling グループからデタッチされ Terminating 状態へ移行します。Auto Scaling グループに autoscaling:EC2_INSTANCE_TERMINATING ライフサイクルフックを追加すると、インスタンスは Terminating 状態から Terminating:Wait 状態に移行します。ライフサイクルアクションを完了したら、インスタンスは Terminating:Proceed 状態に移行します。インスタンスが完全に終了すると、Terminated 状態へ移行します。
- Amazon EC2 Auto Scaling のライフサイクルフック:
  - Auto Scaling グループ内の EC2 インスタンスがライフサイクルの特定のポイントに到達したときにカスタムアクションを実行するための機能です。これにより、インスタンスが起動または終了する際に、追加の設定や処理を行うための時間を確保できます。
    - ライフサイクルフックは、以下のライフサイクルイベントに対応しています：
      - Pending: インスタンスが Auto Scaling グループに追加されるときに発生します。インスタンスが起動してから、稼働状態になる前に待機します。この間にカスタムスクリプトを実行したり、必要なセットアップを行ったりできます。
      - Terminating: インスタンスが Auto Scaling グループから削除されるときに発生します。インスタンスが終了する前に待機します。この間にデータのバックアップやログの収集などを行うことができます。

## 第 6 分野: セキュリティとコンプライアンス

- 人間とマシンのアクセスに対するさまざまな IAM エンティティ (ユーザー、グループ、ロール、ID プロバイダー、ID ベースのポリシー、リソースベースのポリシー、セッションポリシーなど) の適切な使用
- ID フェデレーション手法 (IAM ID プロバイダーと AWS IAM アイデンティティセンター [AWS Single Sign-On] の使用など)
- IAM アクセス許可の境界を使用したアクセス許可管理の委任
- 組織 SCP
- ネットワークセキュリティコンポーネント (セキュリティグループ、ネットワーク ACL、ルーティング、AWS Network Firewall、AWS WAF、AWS Shield など)
- 証明書とパブリックキーインフラストラクチャ (PKI)
- データ管理 (データ分類、暗号化、キー管理、アクセスコントロールなど)
- マルチアカウント環境とマルチリージョン環境におけるセキュリティコントロール適用の自動化 (Security Hub、Organizations、AWS Control Tower、SystemsManager など)
- セキュリティコントロールを組み合わせた多層防御の適用 (AWS CertificateManager [ ACM ]、AWS WAF、AWS Config、AWS Config ルール、Security Hub、GuardDuty、セキュリティグループ、ネットワーク ACL、AmazonDetective、Network Firewall など)
- 大規模環境における機密データの検出の自動化 (Amazon Macie など)
- 転送中のデータと保存中のデータの暗号化 (AWS KMS、AWS CloudHSM、ACM など)
- セキュリティモニタリングサービスと機能 (CloudTrail、AWS Config、VPC フローログ、CloudFormation ドリフト検出など)
- セキュリティの脆弱性とイベントを特定するための AWS のサービス(GuardDuty、Amazon Inspector、IAM Access Analyzer、AWS Config など)
- 一般的なクラウドセキュリティの脅威 (セキュアでないウェブトラフィック、公開された AWS アクセスキー、パブリックアクセスが有効か、または暗号化が無効な S3 バケットなど）

### 試験メモ

- サービスコントロールポリシー（SCP）は、AWS の組織（Organization）内で使用されるポリシーで、主に AWS リソースの利用を制限するために使用されます。以下に SCP の主要なポイントを説明します：
  - 拒否型ポリシー：
    - SCP は「許可型」ではなく「拒否型」のポリシーです。つまり、特定のアクションを明示的に拒否することで、制限を設定します。
    - 例えば、特定のリージョンでのリソース作成を禁止したり、特定のサービスへのアクセスを拒否したりすることができます。
  - 階層構造の継承：
    - SCP は階層構造に基づいて継承されます。AWS 組織では、組織単位（OU）やアカウントに SCP を適用できます。
    - 上位の OU やルートに適用された SCP は、下位の OU やアカウントにも自動的に適用されます。
  - ポリシーの上書き：
    - SCP は拒否型ポリシーのため、下位の OU やアカウントで設定された SCP が上位の SCP を上書きすることができます。ただし、これは「より制限的な」形でのみ行われます。
    - 例えば、上位の OU で「すべてのリージョンでの S3 バケット作成を禁止」と設定されている場合、下位の OU で「特定のリージョンでのみ S3 バケット作成を許可」することはできません。ただし、下位の OU で「さらに特定のリージョンで S3 バケット作成を禁止」と設定することは可能です。
- AWS Organizations で現在 AWS アカウントでアクティブなサービスのみの使用をサポートする適切な SCP の割り当て:
  - IAM Access Analyzer を使用して現在 AWS アカウントでアクティブなサービスを識別し、それに基づいて SCP を作成、新しい OU を作成して、対象の AWS アカウントをこの OU に移動させることで組織構造を再編する。その後、作成されたカスタム SCP を OU に適用し、デフォルトの FullAWSAccess SCP を削除することでえ、アカウントが承認されたサービスのみを使用するよう制限する。
  - SCP によるポリシーは、設定された組織単位（OU）またはアカウントに適用される。もし、SCP で特定のサービスへのアクセスが許可されていない場合、その OU またはアカウントに含まれるユーザーは指定されたサービスを使用できなくなる。
- AWS のサービスコントロールポリシー（SCP）は、AWS Organizations を使って複数の AWS アカウントを管理するときに、これらのアカウントで使用できる AWS サービスやアクションを制御するためのもの。

  - 特定のサービスを許可するポリシーを作成した場合: SCP で特定のサービスのみを許可した場合、そのポリシーに明示的にリストアップされているサービスのみが使用可能になる。その他のサービスは、デフォルトで使用不可能になる。
    - 例えば、SCP で Amazon S3 と Amazon EC2 のみを許可した場合、これら以外のサービス（例えば、Lambda や DynamoDB など）へのアクセスは原則として拒否される。
  - 特定のサービスを拒否するポリシーを作成した場合:SCP で特定のサービスを拒否した場合、そのポリシーにリストされたサービスのみが使用禁止になる。その他のサービスは、ポリシーにより制限されない限り使用可能となる。
    - 例えば、SCP で Amazon S3 の使用を拒否した場合、S3 は使えなくなるが、それ以外のサービス（EC2、Lambda、DynamoDB など）は引き続き使うことができる。
  - つまり、特定のサービスを許可するポリシーは、そのサービス以外のものを全て拒否する「ホワイトリスト」アプローチ。
  - 一方で、特定のサービスを拒否するポリシーは、そのサービスだけを禁止して、他は許可する「ブラックリスト」アプローチになる。

- AWS Organizations(アカウント管理): 複数の AWS アカウントを統合・管理するための中核となるサービスです。AWS Organizations を使用することで、複数の AWS アカウントを作成し、それらを階層的なグループに組織化することができます。AWS Organizations を使用すると、中央の AWS アカウントから、すべての子アカウントのセキュリティ設定、コスト管理、リソース共有などを統合的に管理することができます。また、アカウント間でリソースを共有したり、AWS のサービスを利用する際に必要な権限をより細かく制御できます。
  - ![image](https://github.com/yoshikikasama/system/assets/61643054/beb544d7-d620-44e2-8d9d-1bf7829f7006)
- AWS IAM Identity Center(旧称 AWS SSO)(アカウントのアクセス権限管理): AWS Identity and Access Management（IAM）の一部で、AWS の認証およびアクセス制御の中央管理システムです。IAM Identity Center を使用することで、各アカウントで個別作成する必要がなく、中央管理下アカウントにてユーザーやグループ、およびそれらのアクセス許可ポリシーを管理できます。これにより、煩雑なユーザー管理業務から解放されます。また、AWS Directory Service や Azure AD、オンプレミスの Active Drectory、サードパーティの IDaaS サービスなど、さまざまな IdP と統合でき、既存の ID 基盤に組み込めます。
  - ![image](https://github.com/yoshikikasama/system/assets/61643054/a855cac8-56d0-4899-8dfc-e51617e40d4d)
- AWS Control Tower(アカウント管理): AWS Organizations をベースとしランディングゾーンを実現するサービスです。AWS が提唱するランディングゾーン（Landing Zone）とは、新しく AWS アカウントを作成する際にセキュリティ、コンプライアンス、オペレーションの観点から最適な状態を維持・管理するための代表的なフレームワーク/設計思想です。ランディングゾーンはマルチアカウント管理における様々なベストプラクティスの集合体であり、それをマネージドサービスとして提供しているのが AWS Control Tower です。AWS Control Tower は、AWS Organizations で階層的に管理されたアカウントに対して、自動的にベストプラクティスにもとづくセキュリティ設定や AWS サービスの利用状況を監視する機能を提供します。また、AWS Control Tower は AWS アカウントを複数のプリセットのルールに従って設定することができる「ガードレール」を提供し、AWS アカウントの標準化やセットアップの効率化が可能です。

  - ![image](https://github.com/yoshikikasama/system/assets/61643054/81f5de13-6fdc-456b-94e2-0ef6912decfa)
  - ![image](https://github.com/yoshikikasama/system/assets/61643054/54197e7f-0119-4765-b939-a4d845c11bcc)
  - Account Factory で新しい AWS アカウントの作成と初期設定を行う
  - ドリフト: 管理を逸脱した状態。
  - ランディングゾーン:マルチアカウントを適切に管理、利用するために整えた環境のことです。ランディングゾーンは、おもに２種類あります。Langind Zone は AWS Control Tower が作成するマルチアカウント環境の基盤です。Landing Zone には、管理アカウントとログアカウントが含まれます。管理アカウントは、AWS Control Tower の設定や操作を行うためのアカウントで、ログアカウントは、Landing Zone 内のすべてのアクティビティを監査するためのアカウントです。また、Landing Zone 内のアカウントをグループ化するための単位に OU が存在します。OU には、ルート OU とサービス OU があります。ルート OU は、Landing Zone 内のすべてのアカウントを含む最上位の OU で、サービス OU は、ルート OU の下に作成される任意の OU です。サービス OU は、特定の目的や役割に応じてアカウントを分類することができます。AWS Organization を利用するとき同様、適切な組織設計にすることで効率よく各アカウントを管理することが可能になります。
    - サービスベースドランディングゾーン: サービスとして提供されるランディングゾーンで、Control Tower が作るランディングゾーンはこれに該当します。AWS のセキュリティサービスを組織全体で管理する Audit アカウントやログを一元保管する LogArchive アカウントを用意します。ほかにもアカウントログインに使用する IAM Identity Center の有効化なども含まれます。
    - ![image](https://github.com/yoshikikasama/system/assets/61643054/ff2eed85-56b6-46ad-bea1-21c2499c2da0)
    - 例えるなら空港。新たに空港を作りたいときに、自ら設計・構築するのもひとつの選択肢ですが、ベストプラクティスに応じた設計で構築してくれる。そのようなサービスベースドランディングゾーンを作る機能を Control Tower は持っています。
  - カスタムランディングゾーン: 自身で構築するランディングゾーンです。
  - Account Factory は、AWS Control Tower が提供するアカウント作成サービスです。Account Factory を利用することで、Landing Zone 内に新しいアカウントを簡単に作成し、自動的に OU や Guardrails を適用することができます。また、Account Factory は、AWS SSO や AWS Service Catalog を利用して操作することができます。

- 大企業が買収した小企業の AWS アカウントを、自社の AWS Organizations と AWS Control Tower 環境に統合する方法:

  - ステップ 1: AWS Config コンフォーマンスパックの作成と適用
    - コンフォーマンスパックの作成: 大企業のポリシーに基づいた AWS Config ルールを集めたコンフォーマンスパックを作成します。これには、セキュリティ、コンプライアンス、ベストプラクティスに関連するルールが含まれます。
      - AWS Config 適合パック(コンフォーマンスパック): 適合パックは一つのエンティティであり、複数作成することができます。適合パックの中心となるのはテンプレートです。 CloudFormation と同じような記法で一つ以上の AWS Config ルール（および必要に応じて修復アクション）を定義し、一括でデプロイすることができます。デプロイされた Config ルールは個別に作成された場合と同様に管理することもできますし、適合パックというグループの中で管理することもできます。
    - コンフォーマンスパックの適用: 小企業のアカウントに対してこのコンフォーマンスパックを適用します。これにより、小企業のアカウントがどの程度大企業のポリシーに適合しているかを評価できます。
  - ステップ 2: 設定レコーダーと配信チャンネルの削除
    - 影響評価の結果確認: コンフォーマンスパックの評価結果を確認し、設定の不整合や問題点を特定します。
    - 設定レコーダーと配信チャンネルの削除: 小企業のアカウントで設定レコーダーと配信チャンネルを手動で削除します。これは AWS CLI やマネジメントコンソールを使用して実行します。小企業のアカウントが独自に設定している AWS Config 設定レコーダーや配信チャンネルが、大企業の AWS Control Tower によって提供される設定と競合する可能性があります。これにより、重複したデータ収集やコンプライアンスチェックが発生し、リソースの無駄遣いやパフォーマンスの低下を引き起こすことがあります。AWS Control Tower は、自動的に設定レコーダーと配信チャンネルを再作成し、組織全体の一貫したガバナンスを適用します。これにより、統一されたポリシーとコンプライアンス基準が維持されます。
      - AWS Config の配信チャンネル（Delivery Channel）: AWS Config が収集した設定変更データやコンプライアンスデータを Amazon S3 バケットや Amazon SNS トピックに配信するための設定です。配信チャンネルは、AWS Config が監視および記録したリソースの設定履歴、設定変更、コンプライアンス評価結果を保存および通知するために使用されます。
  - ステップ 3: AWSControlTowerExecution ロールの作成
    - 小企業のアカウントに AWSControlTowerExecution ロールを作成します。このロールは、AWS Control Tower の機能やサービスとの連携を可能にします。
  - ステップ 3: AWS Control Tower Account Factory に登録
    - 小企業のアカウントのメールアドレス、所有者情報、および宛先 OU を提供し、AWS Control Tower Account Factory に登録リクエストを行います。これにより、スムーズに統合が進行します。
  - AWS Organizations で信頼されたアクセスを有効にする
    - まず、AWS Organizations で信頼されたアクセスを有効にする必要があります。これは AWS Control Tower が AWS Organizations と連携して、他のアカウントに対する操作を実行できるようにする設定です。
    - {"trustedAccessEnabled": true,"servicePrincipal": "controltower.amazonaws.com"}
  - AWSControlTowerExecution ロールの作成:
    - 次に、AWSControlTowerExecution ロールを作成します。このロールには、AWS Control Tower が他のアカウントに対して必要な操作を実行するための権限が含まれます。

- AWS Control Tower でのデプロイ:

  - デプロイパターン 1: 手動によるリソースデプロイ
    - 1. AWS Control Tower のセットアップ
      - AWS Control Tower の有効化: AWS マネジメントコンソールにログインし、AWS Control Tower サービスにアクセスします。初期セットアップウィザードに従って、AWS Control Tower を有効化します。必要な AWS アカウント（管理アカウント、ログアーカイブアカウント、監査アカウント）が自動的に作成されます。
      - ガードレールの設定: AWS Control Tower で提供されるガードレールを選択し、有効にします。ガードレールは、セキュリティやコンプライアンスのルールを適用し、各アカウントがこれらのルールに従うようにします。
    - 2. IAM ロールの作成
      - IAM ロールの定義: AWS マネジメントコンソールで IAM サービスにアクセスします。新しいロールを作成し、「AWSControlTowerBlueprintAccess」と命名します。このロールには、管理アカウントの「AWSControlTowerAdmin」ロールが引き受けることを許可するポリシーを設定します。
      - ポリシーのアタッチ: 作成したロールに「AWSServiceCatalogAdminFullAccess」ポリシーをアタッチします。
    - 3. AWS Service Catalog の設定
      - ポートフォリオの作成: AWS Service Catalog にアクセスし、新しいポートフォリオを作成します。ポートフォリオには、企業の標準リソースやテンプレートを含む製品を追加します。
      - 製品の作成: 新しい製品を作成し、CloudFormation テンプレートを使用して製品を定義します。各製品は、開発者が必要なリソースを迅速にデプロイできるようにテンプレート化されています。
    - 4. CloudFormation テンプレートの利用
      - テンプレートの作成: 必要なリソースを含む CloudFormation テンプレートを作成します。例えば、VPC、EC2 インスタンス、S3 バケットなどを定義します。
      - テンプレートのアップロード: 作成したテンプレートを AWS Service Catalog にアップロードし、製品の一部として登録します。
    - 5. Account Factory の利用
      - Account Factory のセットアップ:AWS Control Tower のダッシュボードから Account Factory にアクセスし、新しいアカウント作成プロセスを設定します。各アカウントに対して、必要な設定（SSO 設定、ガードレール適用など）が自動的に適用されます。
      - 新しいアカウントの作成: 開発者は AWS Control Tower を使用して、新しいアカウントを簡単に作成できます。自動化されたプロセスにより、一貫した設定が適用されます。
    - 6. リソースのデプロイ
      - Service Catalog を使ったデプロイ: 開発者は AWS Service Catalog から必要な製品を選択し、デプロイします。CloudFormation テンプレートに基づいて、定義されたリソースが自動的に作成されます。
      - モニタリングと管理: AWS Config や CloudTrail を使用して、デプロイされたリソースやアカウントの設定を監視し、評価します。

- デプロイパターン 2: 完全自動化されたリソースデプロイ:

  - AWS Control Tower で新しいアカウントに対する カスタマイズ された CloudFormation template と SCP を適用してアカウントにアタッチされている全てのリソースを自動的にデプロイする方法。
    - AWS Control Tower のカスタマイズ(CfCT)をデプロイする。
    - Code Commit リポジトリをソースとして使用。
    - リポジトリで Cfn template と SCP JSON ドキュメントを含むカスタムパッケージを作成。
    - AWS Control Tower のカスタマイズ (CfCT ): AWS Control Tower ランディングゾーンをカスタマイズし、 AWS ベストプラクティスに整合させるのに役立ちます。カスタマイズは、 AWS CloudFormation テンプレートと SCP。この CfCT 機能は AWS Control Tower のライフサイクルイベントと統合されているため、リソースのデプロイはランディングゾーンと同期したままになります。例えば、Account Factory を使用して新しいアカウントを作成すると、アカウントにアタッチされたすべてのリソースが自動的にデプロイされます。カスタムのテンプレートとポリシーを組織内の個々のアカウントと組織単位 (OU) にデプロイできます。
    - ![image](https://github.com/yoshikikasama/system/assets/61643054/2f2b994b-bab3-42fb-8158-1ab656083bcd)
      - CfCT をデプロイすると、Amazon S3 によってカスタムリソースがパッケージ化され、コードパイプラインソースにアップロードされます。アップロードプロセスでは、SCP ステートマシンと AWS CloudFormation StackSets ステートマシンが自動的に呼び出され、OU レベルで SCPs をデプロイするか、OU またはアカウントレベルでスタックインスタンスをデプロイします。CfCT は次の 2 つのワークフローをデプロイします。Control Tower のアカウントファクトリーからアカウントが発行された時には、ライフサイクルイベント createManagedAccountStatus というイベントが発生します。発生したイベントを EventBridge で取得して SQS、Lambda と実行することで CodePipeline を新規アカウントに対し実行します。
      - AWS CodePipeline ワークフロー: AWS CodePipeline、組織内の および SCPs の管理をオーケストレート AWS Step Functions する 、AWS CodeBuild プロジェクト AWS CloudFormation StackSets 、および を設定します。設定パッケージをアップロードすると、CfCT はコードパイプラインを呼び出して 3 つのステージを実行します。
        - ビルドステージ: AWS を使用して設定パッケージの内容を検証します CodeBuild。
        - SCP ステージ: サービスコントロールポリシーステートマシンを呼び出します。これにより、 AWS Organizations API を呼び出して SCPs を作成します。
        - AWS CloudFormation Stage: スタックセットステートマシンを呼び出して、マニフェストファイル で指定したアカウントまたは OUs のリストで指定されたリソースをデプロイします。 マニフェストファイル。各段階で、コードパイプラインはスタックセットおよび SCP ステップ関数を呼び出します。これにより、カスタムスタックセットと SCP がターゲットとなる個々のアカウントまたは組織単位全体にデプロイされます。
      - AWS Control Tower ライフサイクルイベントワークフロー: AWS Control Tower で新しいアカウントが作成されると、ライフサイクルイベントで AWS CodePipeline ワークフローを呼び出すことができます。このワークフローを使用して設定パッケージをカスタマイズできます。設定パッケージは、Amazon EventBridge イベントルール、Amazon Simple Queue Service (Amazon SQS) 先入れ先出し (FIFO) キュー、および AWS Lambda 関数で構成されます。Amazon EventBridge イベントルールは、一致するライフサイクルイベントを検出すると、イベントを Amazon SQS FIFO キューに渡して AWS Lambda 関数を呼び出し、コードパイプラインを呼び出してスタックセットと SCPs のダウンストリームデプロイを実行します。

- IAM Identity Center: 複数の AWS アカウントおよびアプリケーションへのアクセスを提供するサービスです。

  - アクセス管理:

    - 複数の AWS アカウントへのアクセス
    - アプリケーションへのアクセス
    - AWS Organizations と統合されており、AWS Organizations 配下のアカウントに対して、アクセス許可セット（権限）をユーザーに割り当てできます。
    - [AWS 入門ブログリレー 2024 〜AWS IAM Identity Center 編〜](https://dev.classmethod.jp/articles/introduction-2024-aws-iam-identity-center/)
    - ![image](https://github.com/yoshikikasama/system/assets/61643054/bbd1583f-69d9-4b7e-b220-4a6f123bb49c)
    - AWS IAM では、インラインポリシーはあまり使わないことが多いと思いますが、AWS IAM Identity Center ではインラインポリシーを使うことも比較的多いです。理由としては、カスタマー管理ポリシーを利用する場合は、アクセス先のアカウントにおいて事前にカスタマー管理ポリシー（IAM ポリシー）を作成しておく必要があるためです。インラインポリシーの場合は AWS IAM Identity Center のアカウントの操作だけで設定が完結します。
    - <img width="925" alt="image" src="https://github.com/yoshikikasama/system/assets/61643054/7ee819f5-3bda-46fa-bbe6-d4d7278c0acb">
    - IAM Identity Center のユーザ・グループは、各アカウントで作成する IAM ユーザ・グループとは異なるため、IAM Identity Center でユーザ・グループを作成しても、各アカウント側には IAM ユーザ・グループは作成されません。接続構成としては IAM Identity Center から各アカウントに内部的にスイッチロールで接続することで、各アカウント側にはユーザ・グループの作成は行われず、IAM Identity Center で集中管理できるようになっているようです。
    - 許可セット: IAM ユーザやグループに割り当てる IAM ポリシーと同等の役割を持つ機能となりますが、違いとしては、1 つの許可セットで複数のアカウントを結びつけることができるため、各アカウント側でいちいち AdministratorAccess ポリシーや ReadOnlyAccess ポリシー等を作成する必要がありません。また、ユーザやグループに許可セットを割り当てる際、複数の許可セットを割り当てることもできるため、例えば設定作業用のフルアクセスポリシーと設定確認用のリードオンリーアクセスポリシー両方を付与して、作業時以外はリードオンリーアクセス権限を持つ許可セットでアクセスし、作業時のみフルアクセスを持つ許可セットでアクセスするといったことも簡単に実装可能です。今までは各アカウントごとに IAM ポリシーを作成していたのが、IAM Identity Center で集約管理することができるので、権限設定の見通しもよく、あるアカウントだけ権限設定を忘れたといった事態も軽減できるかと思います。
    - ![image](https://github.com/yoshikikasama/system/assets/61643054/afcfa95b-3bdb-4399-82b4-174b6483c261)
    - ![image](https://github.com/yoshikikasama/system/assets/61643054/5f9bcd41-fedd-4585-a0ae-d4cd9b0522ff)

- ID 管理（ユーザーの管理）:
  - 独自の ID ストアでユーザー管理
  - Active Directory や 外部 ID プロバイダーとの連携
- 用途: 外部の ID プロバイダと連携して AWS へアクセスする際などに使用する。One login など。
- AWS Control Tower との関係性: AWS Control Tower を利用するときには Control Tower が管理する AWS IAM Identity Center のユーザーやアクセス許可セットが作成されていましたが、2023 年 6 月のアップデートにより、これらの連携の有効化・無効化をユーザーが選択できるようになりました。

- IAM Control Tower:

  - 簡単に言うと複数の AWS アカウント（マルチアカウント）をベストプラクティスに基づいて設定および管理してくれるサービスです。
  - AWS の Organizations、Service Catalog、IAM Identity Center など複数サービスを使ってランディングゾーンを構築する
  - ダッシュボードからランディングゾーンの状態を監視する
  - 組織から OU やアカウントの Control Tower への登録状況を確認でき、OU やアカウントの作成/登録ができる
  - コントロール: 管理・統制からの逸脱（ドリフト）をさせないために OU にコントロールを適用する
    - 組織全体のガバナンス保護や逸脱を検知する機能としてコントロール（統制）が存在します。コントロールは動作の種類と必須度合いを表すガイダンスが決められています。
      - 予防
      - 検出
      - プロアクティブ
      - コントロールのガイダンス
  - Account Factory で新しい AWS アカウントの作成と初期設定を行う
  - ドリフト: 管理を逸脱した状態。
  - ランディングゾーン:マルチアカウントを適切に管理、利用するために整えた環境のことです。ランディングゾーンは、おもに２種類あります。
    - サービスベースドランディングゾーン: サービスとして提供されるランディングゾーンで、Control Tower が作るランディングゾーンはこれに該当します。AWS のセキュリティサービスを組織全体で管理する Audit アカウントやログを一元保管する LogArchive アカウントを用意します。ほかにもアカウントログインに使用する IAM Identity Center の有効化なども含まれます。
    - ![image](https://github.com/yoshikikasama/system/assets/61643054/ff2eed85-56b6-46ad-bea1-21c2499c2da0)
    - 例えるなら空港。新たに空港を作りたいときに、自ら設計・構築するのもひとつの選択肢ですが、ベストプラクティスに応じた設計で構築してくれる。そのようなサービスベースドランディングゾーンを作る機能を Control Tower は持っています。
  - カスタムランディングゾーン: 自身で構築するランディングゾーンです。

- ある企業が、AWS Control Tower を使って複数の AWS アカウントを管理しています。この企業の DevOps チームは、アカウントの管理やリソースの提供を効率化するために特定の設定を行いたいと考えています。

  - AWS Control Tower: これは複数の AWS アカウントを安全かつ効率的に管理するためのサービスです。AWS Control Tower を使うと、複数のアカウントを統一的に管理できます。
  - IAM ロール: AWSControlTowerBlueprintAccess という名前の IAM ロールを作成します。このロールには、管理アカウントの AWSControlTowerAdmin ロールが引き受けることを許可するポリシーが設定されています。また、このロールには AWSServiceCatalogAdminFullAccess というポリシーがアタッチされています。これにより、Service Catalog へのフルアクセス権が与えられます。
  - AWS Service Catalog: これは、AWS リソースのカタログを作成し、管理するためのサービスです。企業が標準的なリソースを簡単にプロビジョンできるようになります。
  - CloudFormation: テンプレートを基に Service Catalog 製品を作成することで、開発者が必要なリソースを簡単にデプロイできるようになります。
  - CloudFormation テンプレートを使用: 各カスタマイズに必要なリソースを含む CloudFormation テンプレートを作成します。これにより、AWS Control Tower を使ってカスタマイズされた環境を一貫して管理できます。

- AWS Organizations : 多数の AWS アカウントの管理
- AWS IAM Identity Center (SSO) : 多数の AWS アカウントへのシングルサインオン（ログイン）
- Account Factory (AWS Service Catalog) : 新規アカウント払い出しのセルフサービス化
- AWS Config : AWS アカウントの設定の評価、監視
- AWS CloudTrail : AWS アカウント内の操作の証跡
- AWS Control Tower を有効化した AWS アカウントは全体の「管理アカウント」となりますが、AWS Control Tower はそれ以外に「ログアーカイブアカウント」と「監査アカウント」を作成し、専用の OU （デフォルトでは “Security”という名称）の配下に入れます。これらの AWS アカウントは管理用であるため、このアカウント内に皆様のサービス/プロダクトで利用する AWS リソースを作らないように注意してください。
- AWS Control Tower を有効化すると、Account Factory が利用出来るようになります。Account Factory から AWS アカウントを作ることで、AWS Organizations や AWS IAM Identity Center (SSO) の設定、ガードレールの適用を自動化することが出来ます。また、開発者にアカウント作成の権限を移譲することも可能です。

  - ![image](https://github.com/yoshikikasama/system/assets/61643054/26450295-1ec6-44d4-82cb-25017df4eb45)
  - [AWS-Black-Belt_2023_AWS-ControlTower-Basics_0831_v1.pdf](https://pages.awscloud.com/rs/112-TZM-766/images/AWS-Black-Belt_2023_AWS-ControlTower-Basics_0831_v1.pdf#page=13)
  - ![image](https://github.com/yoshikikasama/system/assets/61643054/01fc4646-308f-4345-ba67-229c62af37cd)
  - ![image](https://github.com/yoshikikasama/system/assets/61643054/cac720f5-d372-4b65-a810-42eabcea7f6b)
  - ![image](https://github.com/yoshikikasama/system/assets/61643054/634e8b0a-1e61-456d-9f42-933bba763c8b)
  - ![image](https://github.com/yoshikikasama/system/assets/61643054/11c4bf0f-823c-49b4-8102-160de3643b46)

- 要件:
  - 企業の Active Directory システムを使用している。
  - SAML 2.0 ID プロバイダー（IdP）として Active Directory を使用。
  - AWS IAM Identity Center（AWS Single Sign-On）の初期設定は完了している。
  - 従業員が既存の企業認証情報を使用して AWS にアクセスできるようにする。
  - Active Directory のグループを使用して AWS のアクセス許可を管理する。
- 手順:

  - SAML 2.0 IdP との統合: Active Directory の設定で、AWS IAM Identity Center を SAML 2.0 IdP として設定します。これにより、Active Directory の認証情報を使用して AWS にログインできるようになります。
  - SCIM プロトコルを使用した自動プロビジョニング
    - SCIM エンドポイントの設定: AWS IAM Identity Center の SCIM エンドポイントと bearer token を取得します。これらは、AWS IAM Identity Center の管理コンソールから取得できます。
    - Active Directory との同期設定：Active Directory の設定で、SCIM プロトコルを使用してユーザーとグループの情報を AWS IAM Identity Center に自動的に同期する設定を行います。これにより、Active Directory のグループ情報が AWS IAM Identity Center に自動的に反映されます。
  - グループベースのアクセス管理: Active Directory のグループを使用して、AWS IAM ポリシーを設定します。これにより、特定のグループに所属するユーザーに対して、適切な AWS リソースへのアクセス権限が付与されます。

- SAML（Security Assertion Markup Language）：
  - 認証および認可データを交換するための標準プロトコル。
  - 主にシングルサインオン（SSO）を実現するために使用。
  - ユーザーが一度ログインすると、他の連携サービスにもアクセスできるようにする。
  - 認証情報の交換を行い、ユーザーがサービスにアクセスする際の認証を簡素化する。
  - ![image](https://github.com/yoshikikasama/system/assets/61643054/9ebcc91d-b453-4526-b7cd-85abb14fddf2)
- SCIM（System for Cross-domain Identity Management）：

  - 異なるシステム間でユーザーやグループの情報を自動的に同期するためのプロトコル。
  - ユーザーとグループのプロビジョニングおよびデプロビジョニングを自動化。
  - ユーザー属性（名前、メールアドレスなど）やグループ情報を管理し、複数のシステム間で一貫性を保つ。
  - ![image](https://github.com/yoshikikasama/system/assets/61643054/f1e14e9d-1cb8-43d2-9650-891e042e7a6e)

- AWS Directory Service の構成要素

  - AWS Managed Microsoft AD：フルマネージドの Microsoft Active Directory サービス。AWS が Active Directory の管理と運用を担当。Windows ベースのワークロードとの統合に適している。
  - Simple AD： 軽量なディレクトリサービスで、Active Directory と互換性があるが、完全な Active Directory の機能セットは提供しない。
    中小規模のディレクトリサービスが必要な場合に適している。
  - AD Connector：オンプレミスの Active Directory を AWS サービスと統合するためのプロキシ。ディレクトリ情報の同期やレプリケーションは行わず、オンプレミスの Active Directory に対する認証を AWS サービスが利用できるようにする。オンプレミスの Active Directory に対する認証を AWS サービスに提供する。ディレクトリ情報の同期やレプリケーションは行わず、ユーザー認証のみを取り扱う。AD Connector は認証のみを提供し、ユーザーやグループのプロビジョニングや同期を行いません。AD Connector は SAML 2.0 ID プロバイダーとの直接的な統合をサポートせず、認証に特化しています。

- 企業の要件を満たすためには、AWS IAM Identity Center（AWS Single Sign-On, SSO）を使用することが適しています。AWS SSO は以下の機能を提供します：
  - SAML 2.0 ID プロバイダーとの統合： AWS SSO は SAML 2.0 ID プロバイダーと統合可能であり、既存の Active Directory システムを SAML 2.0 ID プロバイダーとして設定することができます。
  - ユーザーとグループの自動プロビジョニング： AWS SSO は SCIM プロトコルを使用して、Active Directory から AWS へのユーザーとグループの自動プロビジョニングをサポートします。
  - IAM ロールとアクセス許可の管理： AWS SSO を使用することで、Active Directory のグループを AWS IAM ロールにマッピングし、アクセス許可を管理することができます。

以下の表は、AD Connector と AWS IAM Identity Center (AWS SSO)の違いを示したものです。

| 機能/要件                                                    | AD Connector                                                        | AWS IAM Identity Center (AWS SSO)                          |
| ------------------------------------------------------------ | ------------------------------------------------------------------- | ---------------------------------------------------------- |
| 基本機能                                                     | オンプレミスの Active Directory と AWS サービスの認証統合           | SAML 2.0 ID プロバイダーとの統合とシングルサインオン (SSO) |
| ユーザー認証                                                 | はい                                                                | はい                                                       |
| ユーザーとグループの自動プロビジョニング                     | いいえ                                                              | はい (SCIM プロトコル使用)                                 |
| SAML 2.0 ID プロバイダーとの統合                             | いいえ                                                              | はい                                                       |
| Active Directory のグループを使用した IAM アクセス許可の管理 | 部分的（認証のみ）                                                  | はい                                                       |
| AWS サービスへの統合                                         | Amazon EC2, Amazon RDS, Amazon WorkSpaces など                      | IAM ロールへのシームレスな統合                             |
| 利用シナリオ                                                 | 既存のオンプレミスの Active Directory を AWS で認証に利用したい場合 | AWS での SSO と自動プロビジョニングを実現したい場合        |
| 適用シナリオ                                                 | 既存の AD 認証情報を AWS サービスに統合するだけの用途               | 既存の AD と AWS IAM の包括的な統合と自動プロビジョニング  |

- AWS WAF:
  - Web アプリケーションに対する悪意のある攻撃を検知し、防御する仕組みのことで、AWS WAF では、Web アプリケーションに送られる HTTP リクエストをルールに基づいて検査し、許可するか拒否するかを判断します。AWS WAF は、AWS のロードバランサーや API Gateway などのサービスと連携して、Web アプリケーションのセキュリティを向上させます。Web ACL は、Web アプリケーションに適用するセキュリティポリシーとして機能し、ロードバランサーや API Gateway などのサービスに関連付けることで、そのサービスに対する HTTP リクエストをフィルタリングできます。
- AWS Firewall Manager:
  - AWS のセキュリティグループや WAF などのファイアウォールルールを一元的に管理するサービスです。
    AWS Firewall Manager を使うと、複数のアカウントやリージョンにわたって、一貫したセキュリティポリシーを適用することができます。
    また、AWS Firewall Manager は、AWS Organizations と連携して、組織内のすべてのアカウントやリソースに対して、自動的にファイアウォールルールを適用することもできます。
  - セキュリティポリシー
    - セキュリティポリシーは、ファイアウォールルールの集合です。
    - ファイアウォールルールは、セキュリティグループや WAF などのサービスで定義されます。
    - セキュリティポリシーを作成する際には、対象となるリソースタイプやタグ、除外条件などを指定できます。
    - 例えば、EC2 インスタンスや ELB などの特定のリソースタイプに対してセキュリティグループのポリシーを適用したり、特定のタグが付いているリソースに対して AWS WAF のポリシーを適用したりできます。また、特定のアカウントやリソースをポリシーの対象から除外することもできます。
  - AWS Firewall Manager は、メンバーアカウントのリソースに対して、自動的にファイアウォールルールを作成や更新します。これにより、セキュリティポリシーの遵守を強制することができます。
- Amazon GuardDuty とは、AWS のセキュリティサービスの一つで、AWS アカウントや AWS リソースに対する潜在的な脅威や不正なアクティビティを検出するためのサービスです。AWS のネットワークや VPC フローログ、CloudTrail イベントなどのデータソースを分析し、機械学習や脅威インテリジェンスを活用して、異常なパターンや既知の攻撃シグネチャを検出します。加えて、検出した脅威や不正なアクティビティに対して、詳細な情報や推奨される対応策を提供します。また、AWS Lambda や Amazon SNS などの他の AWS サービスと連携して、自動化された対応アクションを実行することもできます。
- Amazon Inspector とは、AWS のセキュリティ監査サービスです。Amazon Inspector は、AWS 環境におけるセキュリティの脆弱性やベストプラクティスの遵守状況を自動的に評価し、改善策を提供します。AWS 環境における EC2 インスタンスやネットワーク設定などの情報を収集するために、エージェントと呼ばれるソフトウェアをインストールする必要があります。インストールしたエージェントは、収集した情報をもとに、セキュリティアセスメントと呼ばれる監査プロセスを実行します。なお、Lambda やコンテナサービスの場合にはエージェントインストールは不要です。セキュリティアセスメントでは、AWS が提供するルールパッケージと呼ばれるセキュリティチェックリストを適用します。ルールパッケージには、以下のようなものがあります。
- Amazon Inspector を使用した Amazon EC2 インスタンスのスキャン:

  - Amazon EC2 インスタンスに対して脂弱性スキャンを実行するために、AWS Systems Manager エージェント（SSM Agent）のインストールと動作、ポート 443 でのアウトバウンド通の許可、そして AWS Systems Manager との通信に対するアクセス許可が必要となる。ターゲット EC2 インスタンスに、AWS Systems Manager サービスのエンドポイントへのポート 443 でのアウトバウンドを許可するセキュリティグループを関連付けます。これにより、インスタンスは SSL/TLS を通じて AWS Systems Manager と通信できます。AWS Systems Manager (SSM) エージェントは、AWS Systems Manager のエンドポイントと通信するためにポート 443 を使用します。これにより、エージェントがインスタンスの状態やインベントリデータを AWS Systems Manager に報告し、指示を受け取ることができます。
    - AWS Systems Manager は、以下の方法で通信を確立できます：
      - インターネット経由: インスタンスがインターネットに接続されている場合、SSM エージェントはデフォルトでポート 443 を使用して、AWS Systems Manager のパブリックエンドポイントと通信します。
      - VPC エンドポイント経由: インターネットアクセスが制限されている環境では、Amazon VPC エンドポイントを使用することで、インターネットを経由せずに AWS Systems Manager と通信できます。これにより、セキュリティグループでポート 443 を開ける必要はなくなります。
  - Amazon Inspector は、AWS Systems Manager （SSM）と SSM エージェントを使用して、EC2 インスタンスのソフトウェアアプリケーションインベントリに関する情報を収集します。このデータは、Amazon Inspector によってソフトウェアの胎弱性がないかスキャンされます。Amazon Inspector は、Systems Manager でサポートされているオペレーティングシステムのソフトウエアの弱性のみをスキャンできます。

- AWS Network Firewall:

  - 概要:
    - VPC 単位でパケットの制御が可能。
    - ステートレスパケットフィルタ(5-tuple): 行きと帰りの通信を双方向で許可する必要があるフィルタリング方式。
    - ステートフルパケットフィルタ(5-tuple): 行きの通信のみを定義するだけで帰りの通信は自動的に許可されるフィルタリング方式。
    - ドメインの制御: aaa.jp のようなドメイン制御(ホワイトリスト/ブラックリスト)ができるフィルタリング方式。ドメインの制御はステートフル。
    - Suricata 互換の IPS: シグネチャ型(パターンベース)の IPS が実装可能。
    - 5-tuple: 送信元、送信元ポート番号、宛先 IP、宛先ポート番号、プロトコル番号の 5 つを指定して制御ルールを記載すること。
  - 構成要素:
    - ![Screenshot 2024-04-25 at 7 46 27](https://github.com/yoshikikasama/system/assets/61643054/4975e5aa-1415-4f9b-b253-b18e1abb6d7e)
    - ファイアウォール: AWS Network Firewall 構築時に指定したサブネットに Gateway Load Balancer のエンドポイントが作成されるため、検査対象の通信は一時的に VPC 外へ転送されることになる。
    - ファイアウォールポリシー: AWS Network Firewall で検査する動作を指定する。ファイアウォールルールグループの順序やアクションを管理する。
    - ファイアウォールルールグループ: ファイアウォールルールの順序やアクションを管理する。
      - ステートレスルール: アンマネージド
      - ステートフルルール: アンマネージド、マネージド

- 買収した企業の　 AWS アカウント AWS Organizations に招待:
  - デフォルトでは、組織の一部として新規メンバーアカウントを作成すると、AWS はメンバーアカウント内にロールを自動的に作成し、そのロールを引き受けることができる管理アカウントの IAM ユーザーに管理者権限を付与します。デフォルトでは、そのロールの名前は OrganizationAccountAccessRole。
  - ただし、組織に参加するように招待した既存メンバー アカウントには、管理者ロールが自動的に作成されません。次の手順に示すように、これを手動で行う必要があります。これは基本的に、作成されたアカウントに対して自動的に設定されるロールを複製します。OrganizationAccountAccessRole 一貫性と覚えやすさを考慮して、手動で作成したロールには同じ名前 を使用することをお勧めします。

## 参考資料

[DevOps on AWS 大全](https://qiita.com/tech4anyone/items/b06f88035d27c6ef13b2)

## Other

- RPO（Recovery Point Objective）: ディザスタリカバリ計画において設定されるパラメータで、災害発生時に許容されるデータ損失の最大許容時間を示します。具体的には、最後の正常なデータバックアップからどれだけの時間のデータ損失が許容されるかを定義します。例えば、RPO が 1 時間の場合、ディザスタ発生前に 1 時間以内のデータ損失を許容するという意味です。
- RTO（Recovery Time Objective）: ディザスタ発生後にサービスやシステムを正常な運用状態に戻すための目標時間を示します。
  つまり、ディザスタが発生してからサービスが復旧するまでの合理的な時間枠を指定します。例えば、RTO が 1 時間の場合、ディザスタ発生後に 1 時間以内にサービスを完全に回復させる必要があります。
- ![image](https://github.com/yoshikikasama/system/assets/61643054/df4f6d9a-4390-42f0-a4e5-c3f3af619176)

- バックアップとリストア: 定期的なバックアップを取得して起き、ディザスタ発生時にリストアしながらセカンダリリージョンを構築する手法です。コストは最も安いですが、リストアをしながら別リージョンに環境を構築するため RTO は最も長くなります。
  - ![image](https://github.com/yoshikikasama/system/assets/61643054/0481cc1b-b3e1-4648-9860-7b12f0b7d792)
- パイロットライト: 本番環境の一部のトラフィックをセカンダリリージョンにルーティングする手法です。
  - ![image](https://github.com/yoshikikasama/system/assets/61643054/3d5124e5-a3ca-4e63-922e-5db8500620a4)
- ウォームスタンバイ: セカンダリリージョンにアプリケーションの冗長な最小限の環境を構築し、必要に応じてトラフィックを切り替える手法です。
  - ![image](https://github.com/yoshikikasama/system/assets/61643054/37205d6a-809f-4a63-a591-0839a68cb1f0)
- ホットサイト/マルチサイト:、本番環境と同等の冗長なフルサイズの環境を別の AWS リージョンに構築する手法です。

  - ![image](https://github.com/yoshikikasama/system/assets/61643054/f2740308-72b0-4424-abc0-4b628ded3082)

| デプロイパターン | 特徴                                                                             |
| ---------------- | -------------------------------------------------------------------------------- |
| In-Place         | 稼働中の環境を新しいアプリケーションで更新する。                                 |
| Linear (線形)    | 毎分 10%ずつ新環境の割合を増やすなど、時系列グラフとした場合、直線的に推移する。 |
| Canary           | 最初は 10%のみで、数分後に全てなど、割合によって段階的にリリースする。           |
| Blue/Green       | 現バージョン環境とは別に新バージョン環境を構築し、リクエスト送信先を切り替える。 |
| Rolling          | サーバーをいくつかのグループに分けて、グループごとに In-Place 更新を行う。       |
| Immutable        | 現バージョンサーバーとは別に新バージョンサーバーにを構築する。                   |
| All at once      | すべてのサーバーで同時に In-Place 更新を行う。                                   |

デプロイメント戦略の比較表

| デプロイパターン              | キャパシティ増加 | ダウンタイム | 新旧アプリケーションの混在 | コスト増加 | 特徴                                                                                                                 |
| ----------------------------- | ---------------- | ------------ | -------------------------- | ---------- | -------------------------------------------------------------------------------------------------------------------- |
| Immutable                     | 一時的に増加     | なし         | なし                       | あり       | 新しいインスタンスを作成し、すべてのインスタンスを同時に新バージョンに置き換える。旧インスタンスは削除。             |
| Rolling with Additional Batch | 一時的に増加     | なし         | あり                       | あり       | 新しいインスタンスをバッチ単位で追加し、既存インスタンスを順次置き換える。デプロイ完了後に余分なインスタンスを削除。 |
| Blue/Green                    | 一時的に増加     | なし         | なし                       | 高い       | 別の新しい環境にデプロイし、テスト後にトラフィックを新環境に切り替える。旧環境は切り替え後に削除。                   |

この表により、Immutable と Rolling with Additional Batch の違いがより明確にわかるようになりました。Immutable は一度にすべてのインスタンスを新バージョンに置き換えますが、Rolling with Additional Batch は段階的にインスタンスを置き換えます。

- Blue/Green アーキテクチャ: アプリケーションの新バージョン（Green）を既存のバージョン（Blue）とは異なる環境にデプロイし、切り替えることで、アプリケーションのアップデートやデプロイメントを効果的かつ安全に行う手法です。これにより、ダウンタイムの最小化や問題が発生した場合の簡単なロールバックが可能となります。

  - [AWS のホワイトペーパーから学ぶブルーグリーンデプロイメント](https://blog.serverworks.co.jp/tech/2018/07/18/aws_blue_green_deployments/#%E3%83%96%E3%83%AB%E3%83%BC%E3%82%B0%E3%83%AA%E3%83%BC%E3%83%B3%E3%83%87%E3%83%97%E3%83%AD%E3%82%A4%E3%83%A1%E3%83%B3%E3%83%88%E3%81%A8%E3%81%AF)
  - ブルー ⇒ グリーンの切り替えの基本は DNS(Route 53)で行うものになる
  - Elastic Beanstalk や OpsWorks を利用する場合も基本的には DNS での切り替えに倣う
  - Route 53 を利用する場合、ブルー ⇒ グリーンの切り替えは向き先の ELB の変更とイコールになる
  - Route 53 では重み付けが利用できるため、それを使ってブルー/グリーンのバランスを変更しつつロールバックを行える
  - Auto Scaling を利用することで、ELB 配下の環境を入れ替えることが可能でありこの場合 Route 53 に手を加えない
  - Auto Scaling を利用する場合は、Auto Scaling Group 単位で変更するか、Auto Scaling Group が持つ Launch Configuration で変更するかの 2 パターンに分かれる
  - Auto Scaling では「スタンバイ状態」や「起動する数の設定」を利用してブルー/グリーンの Instance 数を調整することでロールバックを行える
  - Elastic Beanstalk や OpsWorks を利用する場合、それぞれのサービスがバージョン管理の機能を持っているためその恩恵に与れるが、これらはどれも環境を丸ごと複製するためにコストが高くなる

- ブルー/グリーンデプロイメントは、新しいアプリケーションバージョンをリリースする際に、システムの稼働時間を最大化しながらリスクを最小化するための方法です。この方法では、現行のバージョン（ブルー環境）と新しいバージョン（グリーン環境）を別々の環境で実行し、トラフィックを徐々に新しいバージョンに切り替えます。

  - 1. 2 番目の Auto Scaling グループと ALB を作成する
    - 新しい Auto Scaling グループを作成し、ここに新しいバージョンのアプリケーションをデプロイします。
    - 新しい ALB（Application Load Balancer）を作成し、この新しい Auto Scaling グループをターゲットに設定します。
    - ![image](https://github.com/yoshikikasama/system/assets/61643054/9b08baf2-7e2f-4772-bfdf-f00603f8e0de)
  - 2. Route 53 で新しい環境を指す 2 番目のエイリアスレコードを作成し、加重ルーティングポリシーを使用する
    - Amazon Route 53 で、ブルーとグリーンそれぞれの ALB を指す 2 つのエイリアスレコードを作成します。
    - 加重ルーティングポリシーを設定し、ブルー環境からグリーン環境に徐々にトラフィックをシフトさせます。
    - ![image](https://github.com/yoshikikasama/system/assets/61643054/5c1db4c2-118a-4151-9e07-14e925b81e87)
  - 3. プライマリ RDS DB インスタンスを使用するように新しい EC2 インスタンスを設定する
    - 新しい Auto Scaling グループの EC2 インスタンスが、既存のプライマリ RDS DB インスタンスを使用するように設定します。
    - これにより、ブルーとグリーンの両方の環境が同じデータベースを使用することになり、データの一貫性が保たれます。
    - ![image](https://github.com/yoshikikasama/system/assets/61643054/d9272b46-6a57-45a7-b069-38ceccf5f734)

- API Gateway の Canary リリースデプロイの設定:

  - Canary リリースは、新しいバージョンの API (および他のソフトウェア) をテスト目的でデプロイするソフトウェア開発戦略であり、ベースバージョンは同じステージで通常のオペレーション用の本稼働リリースとしてデプロイされたままになります。
  - Canary リリースのデプロイでは、すべての API トラフィックはランダムに区切られて事前に設定された比率で本稼働リリースと Canary リリースに送られます。通常、Canary リリースは低い割合の API トラフィックを受け取り、残りは本稼働リリースが受け取ります。更新された API 機能は、Canary を介した API トラフィックのみに認識されます。Canary トラフィックの割合を調整してテストカバレッジやパフォーマンスを最適化できます。
  - Canary トラフィックを低く保ち、選択をランダムにすることにより、どのような時でもほとんどのユーザーは新しいバージョンの潜在的なバグに悪影響を受けず、また、常に悪影響を受け続けるユーザーもいません。テストメトリクスが要件を満たしたら、Canary リリースを本稼働リリースに昇格させ、Canary をデプロイから無効にします。これにより、本稼働ステージで新機能が使用可能になります。
  - ![image](https://github.com/yoshikikasama/system/assets/61643054/7881c8e1-d925-4ab7-af4c-31ec307f2b94)
  - API Gateway の Canary リリースデプロイを使用すると、新しいアプリケーションバージョンを少数のユーザーに徐々に公開し、問題があれば迅速にロールバックできます。
  - ユーザーへの中断を最小限に抑え、システムの安定性を確保しつつ、新しいバージョンを安全にリリースできます。
  - 新しいバージョン(ステージ)を作成するイメージ。

- Elastic Beanstalk

  - Blue/Green デプロイメントのためには、アプリケーションの Zip ファイルを S3 に保存して、その場所を指定して新しいバージョンをデプロイする。
  - Blue/Green デプロイメントでは CNAME スワップのために Lambda 関数を呼び出す必要がある。
  - サポートされていない言語を含む複数のアプリケーションをデプロイするためには、Multi-Docker コンテナ構成を利用し、各アプリケーションをコンテナとして ECR に保存する。
  - ワーカー環境とアプリケーション環境を分離して SQS で連携することで CPU 使用率を軽減させることが可能。
  - Web サーバー環境では Web 層だけを使用可能。Web 層とアプリケーション層の両方は不可。
  - X-RAY を有効にするためには、管理ページで X-RAy デーモンを有効にし、ebExtention で Xray を true にする。

- ECS:

  | デプロイ設定                                       | 説明                                                                                   |
  | -------------------------------------------------- | -------------------------------------------------------------------------------------- |
  | CodeDeployDefault.ECSCanary10Percent5Minutes       | 最初の増分でトラフィックの 10%をシフトします。残りの 90%は 5 分後にデプロイされます。  |
  | CodeDeployDefault.ECSCanary10Percent15Minutes      | 最初の増分でトラフィックの 10%をシフトします。残りの 90%は 15 分後にデプロイされます。 |
  | CodeDeployDefault.ECSLinear10PercentEvery1Minutes  | すべてのトラフィックがシフトされるまで、トラフィックの 10%を毎分シフトします。         |
  | CodeDeployDefault.EcSLinear 10PercentEvery3Minutes | すべてのトラフィックがシフトされるまで、トラフイックの 10%を 3 分ごとにシフトします。  |

  - CloudFormation で AutoScaling グループを設定: UserData で「AWS::AutoScaling::LaunchConfiguration」を記載し ECS クラスターで参照する
  - ライフサイクルイベント:
    - ![image](https://github.com/yoshikikasama/system/assets/61643054/dd818984-c0a7-4756-b9ce-651674e81f3d)
    - タスク定義に awslogs ドライバーを含めることでネイティブに CloudWatch にログの書き込みが可能。EC2 インスタンスには IAM インスタンスロールを設定する。

- DynamoDB

  - SNS を使用することで DynamoDB ストリームをトリガーに複数の Lambda を起動することが可能。
  - DynamoDB ストリームはアイテムレベルのイベントをキャプチャする。

- AWS Trusted Advisor

  - AWS のベストプラクティスをフォローするためのレコメンデーションを提供
  - 直接 Lambda 関数は呼び出せないため、EventBridge を経由する。
  - Amazon EventBridge を使用した AWS Trusted Advisor チェック結果のモニタリング
    - EventBridge を使用して、Trusted Advisor のチェックがステータスを変更するときに検出できます。その後、ルールに指定した値のステータスが変更されたときに、EventBridge は、1 つ以上のターゲットアクションを呼び出します。
    - https://docs.aws.amazon.com/ja_jp/awssupport/latest/user/cloudwatch-events-ta.html

- ELB

  - ALB に AZ を追加するには、[Edit subnets（サブネットを編集する）]ページの[Availability Zone（アベイラビリティーゾーン）」で、追加するアベイラビリティーゾーンのチェックボックスを選択する
  - アクセスログの作成は、Elastic Load Balancing のオプション機能であり、デフォルトでは無効化。有効化すると S3 に保存される。

- S3
  - クロスリージョンレプリケーションの SLA は 15 分、RPO は 5 秒
  - クロスリージョンレプリケーションの手順
    - ソースバケットに IAM ロールを作成
    - ターゲットバケットでソースの IAM を許可
    - ターゲットバケットでレプリケーションルールを定義
- AWS Storage Gateway: オンプレミス環境と AWS クラウド間のストレージを統合するためのハイブリッドクラウドストレージサービスです。これにより、オンプレミスのアプリケーションがクラウドストレージを使用することができます。
  - ![image](https://github.com/yoshikikasama/system/assets/61643054/230fecbc-38f4-4e59-83c8-23b195f11d27)
  - RefreshCache 操作は、ファイルゲートウェイが S3 バケットの内容を最新の状態に保つためにキャッシュを更新する操作です。これにより、S3 バケット内の新しいオブジェクトや変更されたオブジェクトがファイルゲートウェイ経由でユーザーに見えるようになります。
  - ファイルゲートウェイは、AWS Storage Gateway の一つの動作モードです。このモードでは、オンプレミスのアプリケーションがクラウドに保存されたファイルを簡単に利用できるようにします。
  - ローカルキャッシュ：よくアクセスされるデータをオンプレミスにキャッシュすることで、データアクセスの速度を向上させます。
- ファイルの格納：
  - オンプレミスのアプリケーションはファイルを Storage Gateway に送信します（NFS または SMB プロトコルを使用）。
  - Storage Gateway はファイルを Amazon S3 に保存します。
- ファイルの参照：
  - ユーザーがファイルにアクセスしようとすると、まず Storage Gateway にリクエストを送信します。
  - Storage Gateway は Amazon S3 からファイルを取得し、必要に応じてローカルキャッシュからも提供します。
- ボリュームゲートウェイ

  - 用途：ブロックストレージ
    - プロトコル：iSCSI (Internet Small Computer Systems Interface)
    - データ保存：Amazon S3（バックアップ）または完全にオンプレミスに保存
  - 主なユースケース：
    - データベースや仮想マシンのバックアップと復元
    - ディザスタリカバリ
    - オンプレミスとクラウドのブロックストレージ統合
  - 特徴：
    - キャッシュボリューム：オンプレミスに頻繁にアクセスされるデータをキャッシュし、Amazon S3 にバックアップ
    - ストアボリューム：オンプレミスにデータを保存し、Amazon S3 に定期的にスナップショットを取る

- リクエスト数が多い場合はスロットリングに注意

  - このアプリはリクエスト数が多くなどの記載がある場合、スロットリングに注意が必要です。
  - Lambda 単体の場合や、Lambda と DynamoDB の連携などが出てくるイメージです。
  - Lambda 単体なら同時実行の設定や上限緩和、他のリソースとの連携なら Lambda と他のリソースの間に SQS や SNS を挟むというのが正解の場合が多いです。

- cfn-signal: EC2 リソースが正常に作成/更新されたかどうかを示すシグナルを CloudFormation に送信するスクリプトです。 シグナルは CloudFormation の CreationPolicy,UpdatePolicy 属性などで使われています。
- CreationPolicy 属性: リソースに関連付けて、AWS CloudFormation が指定数の成功シグナルを受信するかまたはタイムアウト期間が超過するまでは、ステータスが作成完了にならないようにします。

- 問題のポイント:
  - インスタンス起動時に最新の構成ファイルを適用したい：新しく作成された EC2 インスタンスが常に最新の設定で動作すること。
  - CloudFormation テンプレートが更新されたときに自動で構成を反映させたい：テンプレートが変更されたら、すべてのインスタンスがその変更を即座に反映すること。
- cfn-init: CloudFormation テンプレート内に指定されたメタデータ（設定ファイルなど）を読み取り、EC2 インスタンスに適用します。これにより、インスタンス起動時に最新の構成が適用されます。
- cfn-hup: CloudFormation テンプレートの更新を監視し、変更があった場合に自動でインスタンスの構成を更新するスクリプトです。
- 例)

  - ```
        UserData:
           Fn::Base64: !Sub |
             #!/bin/bash -xe
             yum update -y
             yum install -y aws-cfn-bootstrap
             /opt/aws/bin/cfn-init -v --stack ${AWS::StackName} --resource MyLaunchConfig --region ${AWS::Region}
             /opt/aws/bin/cfn-hup
    ```
    CloudFormation スタックが UPDATE_ROLLBACK_FAILED 状態のままになっている場合:
  - そのスタックで実行できるアクションは ContinueUpdateRollback または DeleteStack のオペレーションのみになります。これは、CloudFormation がユーザーからの追加入力を必要とし、ロールバックしようとしているテンプレートとスタックが同期していないことを確認するためです。ロールバックを再試行してエラーを解決するには、ContinueUpdateRollback を使用します。
  - 解決するには、手動で修正してロールバックする。

- ECS ウェブ層、ECS アプリ層、データベースの 3 層アプリケーションで、これらの前にあるロードバランサでアプリ層とデータベース層が正常に通信できている場合のみ通信を可能にするには？
  - アプリ層とデータベース層への接続テストをする web アプリでヘルスチェックエンドポイントを作成。そこにターゲットの URL を指定（エンドポイント）し、ヘルスチェックを行う(正常なら 200)
- 組織は EKS、ECS とオンプレクラスタ全体でコンテナされたアプリケーションを使っている。機能停止の原因となった問題によってコンテナの状態やエラーを検出する機能が必要。監視と分析のために時系列メトリックを収集集約できるようにするには？
  - Amazon Managed Service for Prometheus を使ってメトリクスを収集し、視覚化と分析には Amazon Managed Grafana を使う
  - ※Amazon Managed Service for Prometheus: コンテナ化されたアプリケーションとインフラストラクチャを大規模に監視してアラートを提供するサービス
  - ※Amazon Managed Grafana: 複数のデータソースにわたって単一のコンソールでインタラクティブなデータの可視化をして運用データの監視ができる
- セキュリティ強化のために AWS System Manager Session Manager を使用して EC2 を管理しプライベートネットワークで接続したいです。これを実装するのに必要な構成は？
  - SystemManager に必要なアクセス許可を提供する EC2 に IAM インスタンスプロファイルをアタッチし、インスタンスが実行されているリージョンで Systems Manager の VPC エンドポイントを作成する
- 複数の AWAS アカウントで潜在的なセキュリティ違反に対処するために監査を行った。そのすべてのログと調査結果を集中管理されたアカウントに収集したい。

- 問題のシナリオ:

  - ウェブアプリケーションの構成:
    - Application Load Balancer（ALB）: ALB は、インターネットからのトラフィックを EC2 インスタンスに振り分ける役割を持ちます。
    - EC2 インスタンスと Auto Scaling グループ: ウェブアプリケーションは、Auto Scaling グループにある複数の EC2 インスタンスで実行されます。Auto Scaling グループは、負荷に応じてインスタンスの数を動的に調整します。
    - セキュリティグループ: ALB には、インターネットからのトラフィックを許可するセキュリティグループが関連付けられています。
  - セキュリティインシデントと対策
    - インシデント: ウェブアプリケーションが過負荷に陥り、お客様に障害が発生しました。
    - 対策: Amazon CloudFront をウェブアプリケーションの前に追加し、すべてのお客様が CloudFront 経由でアクセスするようにしました。
  - DevOps エンジニアの課題
    - リクエストのルーティング: すべてのリクエストを CloudFront 経由でルーティングする必要があります。
    - リクエストのブロック: ヘッダーやボディの情報に基づいてリクエストをブロックする機能が必要です。
  - 解決策:
    - AWS WAF と CloudFront の連携
      - AWS WAF（Web Application Firewall）: ウェブアプリケーションに対する攻撃を検出してブロックするために使用します。
      - ウェブ ACL（Access Control List）: AWS WAF を使用して作成し、CloudFront ディストリビューションに関連付けます。
      - ルールの作成: ブロックしたいトラフィックの種類ごとにルールを作成します（例：特定のヘッダーやボディの内容に基づいてリクエストをブロック）。
    - ALB のリスナールールの設定
      - ホストヘッダーのチェック: 新しい ALB リスナールールを作成し、リクエストのホストヘッダーが CloudFront の完全修飾ドメイン名（FQDN）と一致するかどうかを確認します。これにより、CloudFront 経由でないリクエストを拒否します。
    - ![image](https://github.com/yoshikikasama/system/assets/61643054/75915be9-0883-44a7-bd6a-abca0cdc54d6)
    - CloudFront: すべてのリクエストはまず Amazon CloudFront に送信されます。CloudFront はキャッシュ機能を提供し、ウェブアプリケーションのパフォーマンスを向上させます。
    - AWS WAF: CloudFront はリクエストを AWS WAF に送信します。AWS WAF は、リクエストの内容（ヘッダーやボディ）に基づいてリクエストをブロックするルールを持っています。
    - Application Load Balancer (ALB): WAF を通過したリクエストは、Application Load Balancer（ALB）に送信されます。ALB は、リクエストをバックエンドの EC2 インスタンスに振り分けます。
    - EC2 Instances (Auto Scaling Group): ALB からのリクエストは、Auto Scaling グループに属する複数の EC2 インスタンスで処理されます。Auto Scaling グループは、負荷に応じてインスタンスの数を動的に調整します。
  - CloudFront ディストリビューション: CloudFront で作成する一つのコンフィギュレーションです。ディストリビューションは、コンテンツの配信方法を定義します。例えば、どのオリジン（元のサーバー）からコンテンツを取得するか、キャッシュの設定などを指定します。
  - ALB
    - リスナー設定: ALB がリクエストを受け取るために使うプロトコルとポートを定義します。例えば、HTTP や HTTPS などです。
    - リスナールール: ALB が受け取ったリクエストをどのように処理するかを決定するための条件とアクションのセットです。
    - ホストヘッダーは、HTTP リクエストの一部で、どのサーバーにリクエストを送信するかを指定します。
    - ホストヘッダー条件: リクエストのホストヘッダーが特定の完全修飾ドメイン名（FQDN）と一致するかどうかをチェックする条件です。
      - FQDN（完全修飾ドメイン名）: 完全なドメイン名で、例えば「example.cloudfront.net」のようにドメイン名全体を指します。この条件をリスナールールに追加することで、ALB は CloudFront を経由したリクエストのみを受け入れるようになります。具体的には、リクエストのホストヘッダーが CloudFront のドメイン名（例: d1234567890.cloudfront.net）と一致する場合のみ、そのリクエストを処理します。

- 段階的な AWS Lambda デプロイを提供するために CodeDeploy が組み込まれています。

  - Canary: トラフィックは 2 回の増分で移行されます。事前定義された Canary オプションから選択できます。このオプションは、最初の増分で更新された Lambda 関数バージョンに移行されるトラフィックの割合と、2 番目の増分で残りのトラフィックが移行されるまでの間隔を分単位で指定します。
  - Linear: トラフィックは、毎回同じ間隔（分）の等しい増分で移行します。増分ごとに移行されるトラフィックの割合と、増分間の間隔 (分) を指定する事前定義された Linear オプションから選択できます。
  - AllAtOnce: すべてのトラフィックは元の Lambda 関数から最新バージョンの Lambda 関数に一度に移行されます。

- ![image](https://github.com/yoshikikasama/system/assets/61643054/e6043f63-c984-40c1-91e8-41986d0df0b0)

  - 新しいターゲットグループを作成: 各 API エンドポイント（例えば、/api/endpoint1）に対して、Lambda 関数ターゲットグループを作成します。
  - 既存のターゲットグループと新しいターゲットグループの設定: 既存の EC2 インスタンスベースのターゲットグループ（例えば、EC2-Endpoint1）を維持し、新しい Lambda 関数ターゲットグループ（例えば、Lambda-Endpoint1）と併用します。
  - Application Load Balancer (ALB)のリスナールールを設定: ALB のリスナーに、新しいパス条件と重み付けルールを設定します。例えば、/api/endpoint1 に対して以下のような設定を行います：
    - EC2-Endpoint1 ターゲットグループに 80%のトラフィックを割り当てる
    - Lambda-Endpoint1 ターゲットグループに 20%のトラフィックを割り当てる。
  - これにより、新しい Lambda 関数バージョンのテストが限られた数のお客様で行われ、既存の ALB アクセスログに影響を与えず、ログ処理サービスとの互換性も維持されます。

- マイクロサービス間の通信をパブリックインターネットを経由せず、プライベートネットワーク接続で行う

  - AWS PrivateLink を使用して、マイクロサービス同士をプライベートに接続する方法を説明します。
  - AWS PrivateLink: VPC 内のサービスを他の VPC やオンプレミスネットワークにプライベートに公開できる機能です。これにより、インターネットを経由せずにサービスを安全に接続できます。
  - ![image](https://github.com/yoshikikasama/system/assets/61643054/0c5648fd-6278-45a0-a2dd-521551099a3a)
  - VPC: 各サービスチームは独自の VPC を持ち、その VPC 内でサービスをホストしています。
    - VPC A: 192.168.0.0/22 CIDR
    - VPC B: 192.168.4.0/22 CIDR
    - VPC C: 192.168.8.0/22 CIDR
  - ALB (Application Load Balancer): 各 VPC 内に配置され、トラフィックを EC2 インスタンスに分散します。
  - EC2 インスタンス (Microservice): 各マイクロサービスをホストしている EC2 インスタンス。
  - NLB (Network Load Balancer): 各 VPC に配置され、AWS PrivateLink のためのエントリーポイントとして機能します。
  - VPC エンドポイントサービス: NLB を指す VPC エンドポイントサービスが各 VPC 内に設定されます。
  - VPC Endpoint Service (A): VPC A からのサービス
  - VPC Endpoint Service (B): VPC B からのサービス
  - VPC Endpoint Service (C): VPC C からのサービス
  - AWS PrivateLink: 各 VPC は、AWS PrivateLink を介して他の VPC とプライベートに接続されます。他の VPC は、エンドポイントサービスに接続するためのインターフェース VPC エンドポイントを作成します。各コンシューマ VPC は、エンドポイントサービスを利用して他のマイクロサービスと通信します。
  - プライベートリンクの通信フロー
    - サービス提供側 (VPC A, B, C): 各 VPC にあるマイクロサービスは NLB を介してエンドポイントサービスとして公開されます。
    - サービス消費側 (Consumer A, B, C): 各 VPC は他の VPC のエンドポイントサービスに接続するためにインターフェース VPC エンドポイントを作成し、プライベートに通信します。
  - なぜ NLB を使用するのか？
    - AWS PrivateLink の要求: AWS PrivateLink は、VPC エンドポイントサービスを作成する際に NLB を必要とします。NLB は、プライベートリンクを介してトラフィックを受け入れるためのエントリーポイントとして機能します。
    - 高性能な TCP トラフィック処理: NLB は、TCP トラフィックの処理に特化しており、高スループットと低レイテンシを提供します。これにより、マイクロサービス間の通信が迅速かつ効率的に行われます。
    - スケーラビリティと可用性: NLB は自動的にスケーリングし、高い可用性を提供します。これにより、トラフィックの増加に対しても対応可能で、サービスの信頼性が向上します。
    - 固定 IP アドレスのサポート: NLB は固定 IP アドレスをサポートしているため、エンドポイントのアドレスが固定され、管理が容易になります。

- 会社の要件
  - ユーザーに最良の応答時間を提供
  - ユーザーが最も近いリージョン（us-east-1 または eu-west-1）からウェブサービスを利用できるようにする。
  - リージョン障害時のフェイルオーバー
  - 一方のリージョンで障害が発生した場合、もう一方のリージョンにトラフィックを誘導する。
- 解決策

  - サブドメインの設定: us.example.com と eu.example.com のサブドメインを作成し、それぞれのリージョンに対応する ALB を設定。
  - レイテンシーベースルーティングポリシー: example.com の DNS レコードにレイテンシーベースルーティングポリシーを使用して、us.example.com と eu.example.com にトラフィックを振り分ける。
  - フェイルオーバールーティングポリシー: us.example.com と eu.example.com にフェイルオーバールーティングポリシーを設定し、プライマリとセカンダリの ALB を設定。
  - 通常のトラフィックフロー: ユーザーは最も近いリージョンに接続。
    - example.com -> レイテンシーベースルーティング -> us.example.com または eu.example.com
  - フェイルオーバーのトラフィックフロー: リージョン障害時には、もう一方のリージョンにトラフィックが誘導される。
  - <img width="632" alt="image" src="https://github.com/yoshikikasama/system/assets/61643054/14c5e22e-59af-4320-a3f6-2c15c0fab54f">

- スロットリング: 抑制。制限
- アイドリング: 暇
