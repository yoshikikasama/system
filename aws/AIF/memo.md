# AIF 学習

- AI、機械学習、深層学習、⽣成 AI の関係
  - AI > 機械学習 > 深層学習 > ⽣成 AI
  - AI :⼈間の知的作業を代替する技術
  - 機械学習: 多数の⼊⼒からパターンを学習する
    - 教師あり学習
    - 教師なし学習
    - 強化学習
  - 深層学習: 多層の学習で複雑なパターンを学習する
  - ⽣成 AI: 新たなコンテンツを⽣成する

| 種類         | 教師あり学習                                   | 教師なし学習                               | 強化学習                                 |
| :----------- | :--------------------------------------------- | :----------------------------------------- | :--------------------------------------- |
| 目的         | 未知データの推定                               | データの分類                               | 最善の行動の学習                         |
| データの種類 | 推定したいデータと推定のもとになるデータセット | 分類したいデータ（推定したいデータは不要） | 行動をシミュレートしてデータを集める     |
| 要は...      | 問題と解答をセットで与えて勉強してもらう手法   | 多数のデータから特徴を見出してもらう手法   | 色々試して、結果がよかった行動を学ぶ手法 |

- ニューラルネットワーク:

  - 機械学習を実装するための有名な⼿法の⼀つ
  - ⼈間の脳の働きを模した構造で学習をする⼿法
  - 複数の頂点とそれに接続する辺から成る層状構造をとる
  - 例えば、数字を判別する場合
  - 数字の要素を分解し、当てはまる確率が⾼い数字を出⼒する
    - 9 は、上半分に丸があるな、下半分は右上から左下に向けての直線だな
    - 9 の特徴に当てはまるな。9 の確率 90%。8 の確率 20%
  - ⼊⼒層 → 中間層 → 出⼒層とデータが流れる

- 深層学習:

  - ニューラルネットを深くしたもの
  - 中間層が 2 層以上のものを特にディープラーニングと呼ぶ
  - 層を増やすことで精度が向上した

- 機械学習のパイプライン
  - データ収集: 質の良い学習のためには質の良いデータが必要。偏りのない、信頼できる⼤量のデータを⽤いて学習を⾏う
  - データの前処理: データの不備や重複を修正してデータの品質を向上させること
  - 特徴量エンジニアリング
    - 特徴量とは予測の⼿掛かりとなる変数のこと
    - 機械学習モデルが予測を⾏うためにトレーニングおよび推論中に使⽤する⼊⼒値
    - 天気を予測する場合
      - 時間情報: ⽇付
      - 地理情報: 緯度、経度、標⾼
      - 気象データ: 気温、湿度、気圧
    - 予測モデルを作成する際に特徴量の選択と変換を⾏うプロセス
    - モデルが効率的に学習できるように特徴量を⼯夫することが重要

| ⼯程                    | 内容                                               |
| :---------------------- | :------------------------------------------------- |
| 特徴量作成              | 既存のデータから新しい特徴量を作り出す             |
| 特徴量変換 , ⽋損値処理 | ⽋損値や無効な値を置き換える                       |
| 特徴量選択              | モデルのターゲット予測に強く関連する変数を選択する |
| 特徴量抽出              | 次元削減などにより処理するデータ量を削減           |

- 教師あり学習:
  - 回帰: 連続値のデータから未来の値を予測すること
    - 例: 過去の株価を元に未来を予測
  - 分類: データが属するクラスを予測して分類すること
    - 学習データに正解となるラベルを与えた状態で学習する⼿法
    - 学習したデータに基づいて、新しく与えられた未知データを分類する
- 教師なし学習の⽤途:

  - 次元削減: ⾼次元のデータをなるべく情報量を減らさずに圧縮
    - 計算量の削減、⼈間に理解できる次元数にする、といった効果がある
    - 例
      - ⾞が持つ特徴: 値段,加速性能,最⾼速度,乗り⼼地,燃費,安全性能,乗⾞定員,エコスコア
      - 着⽬指標を設定: 燃費
      - ⾞の良し悪しを少ない条件で判断できる
  - クラスタリング: 与えられたデータを⼀定の基準に従ってカテゴライズ
    - ⽝や⿃という概念は認識していないため、結果を⾒て⼈間が判断する

- 強化学習:
  - 環境が複雑で動的に変化する状況下での意思決定は⼤変
  - 明確な正解がない（計算できない）→ 結果を評価して⾏動を修正する
  - 例) ゲーム攻略
    - 試⾏錯誤しながらデータを収集し学習する
    - ⼈間の試⾏錯誤に似ている（やってみてデータを集める）
    - データの代わりに試⾏錯誤ができる環境・シミュレーションが必要

|              | 教師あり学習                                                                                                     | 教師なし学習                                                                                                               | 強化学習                                                                 |
| ------------ | ---------------------------------------------------------------------------------------------------------------- | -------------------------------------------------------------------------------------------------------------------------- | ------------------------------------------------------------------------ |
| ⽬的         | 未知データの推定                                                                                                 | データの分類                                                                                                               | 最善の⾏動の学習                                                         |
| データの種類 | 推定したいデータと、推定のもとになるデータセット                                                                 | 分類したいデータ（推定したいデータは不要）                                                                                 | ⾏動をシミュレートしてデータを集める                                     |
| ⼿法の例     | - 回帰: 蓄積された過去のデータを学習して株価や天気を予測<br>- 分類: 動物の画像データから⽝、猫、⿃などを分類する | - クラスタリング: データ間の類似度に基づいてデータをグルーピングする⼿法<br>- 次元削減: データセット内の特徴数を減らす⽅法 | - ゲーム攻略: 良し悪しの基準を与えて試⾏錯誤を⾏い、最適な攻略⼿順を学習 |

- モデルの評価

  - 分類モデル
    - 分類の正確性を評価する指標
    - 混同⾏列: 機械学習を⽤いた分類の性能評価に利⽤する⾏列。機械学習による予測結果と実際の分類を表にしたもの
    - F1 スコア
    - ROC 曲線
  - ⽂章⽣成モデル
    - 出⼒⽂の品質を評価する指標
    - ROUGE: 要約の指標。⽣成された要約⽂と参照要約（⼈⼒で要約した正解データ）を⽤意する。類似度を計算する。
    - BLEU: 翻訳の指標。⽣成された翻訳⽂と参照翻訳（⼈⼒で翻訳した正解データ）を⽤意する。類似度を計算する。
    - BERTScore: 翻訳・画像⾒出しの指標。⾔語モデルを⽤いた評価。⽣成⽂と参照⽂を BERT モデルにインプットする。ベクトル埋め込みを⽤いて類似度を計算。

- 機械学習アプリケーションの例: ランキング
  - ある基準に従って対象を順位付けし、順位が⾼いものを優先的に表⽰
  - クリック率などのユーザーの⾏動、⼈気度を元にアルゴリズムを最適化
- 機械学習アプリケーションの例: レコメンド
  - ユーザーの嗜好や類似ユーザーの⾏動などを基に、興味を持ちそうな対象を表⽰
  - コンテンツや商品の発⾒を容易にし、ユーザー体験を向上
- 機械学習アプリケーションの例: 分類
  - 分類対象がどのクラスに属するかを理解して判別する
  - 分類の⽬的は、与えられたデータを正しいクラスに割り当てること
  - スパムメールフィルター、画像診断
- 機械学習アプリケーションの例: 回帰
  - 現時点までの連続的な値のデータを基に、未来の結果を予測
  - 株価や気温といった数値的な出⼒を予測
- 機械学習アプリケーションの例: クラスタリング。教師なし

  - 類似したデータをグループ化して、⾃然に形成されたクラスター（集団）を発⾒する
  - データは事前にラベル付けされておらず、データの特徴に基づいてグルーピングを⾏う
  - 顧客セグメンテーション、ドキュメント分類。

- ⾃然⾔語処理（NLP）:
  - 機械学習を⽤いて⼈間の⾔語を解釈・操作・理解する技術
  - ⼤量の⾳声・テキストデータから NLP ソフトウェアを使って意図・感情を分析し、リアルタイムに応答できる

| ユースケース   | 使⽤例                                                                     |
| -------------- | -------------------------------------------------------------------------- |
| 機械翻訳       | 外国語がわからない旅⾏者に対し多⾔語対応の案内やサポートを提供             |
| 感情分析       | 顧客からのレビューやフィードバックを⾃動分析してクレーム時の対応に役⽴てる |
| テキスト要約   | 時間のない読者に対し⻑い記事を要約して重要な要素のみ抽出                   |
| ⾳声認識       | 医師の診察中の会話を記録して⾃動的に電⼦カルテに変換                       |
| チャットボット | 24 時間対応可能な⾃動応答システムを提供                                    |

- 固有表現抽出（Named Entity Recognition: NER）
  - ⾮構造化テキストから固有名詞や重要語句を抽出し、あらかじめ定義したカテゴリ(⼈名、組織名、地名など)に分類する
  - 深層学習による⼿法が主流で、テキスト⾃動要約、質問応答システムなど様々な⾃然⾔語処理に関わる課題の基盤として活⽤されている
  - 例) ⼊⼒テキスト︓東京オリンピックで堀⽶悠⽃が⾦メダルを獲得した。
    - 抽出・分類
      - Location・東京
      - Event・オリンピック
      - Person・堀⽶悠⽃
      - Product・⾦メダル
- インテリジェントドキュメント処理（IDP）
  - 紙ベースのドキュメントやその画像から⼿動でデータを⼊⼒する
  - プロセスを⾃動化して、他のデジタル・ビジネス・プロセスと統合する処理
- オーバーフィッティング（過学習）
  - 学習データに過剰に適合し、実際のデータを利⽤した予測が不正確になること
  - 対策としては学習回数を減らす（過剰な適合を抑える）
- ハイパーパラメータ
  - 機械学習モデルのトレーニングを管理するために使⽤する外部設定変数
  - パラメータのチューニングは⼀般的に⼈間が⼿動で調節する
  - モデル構造や機能、パフォーマンスを直接的に制御可能

| ハイパーパラメータ項⽬ | 概要                                                                                               |
| ---------------------- | -------------------------------------------------------------------------------------------------- |
| 学習率                 | アルゴリズムが推定値を更新する率のこと                                                             |
| 学習減衰率             | 学習を⾼速化するために、時間の経過と共に学習率を徐々に低下させていく率のこと                       |
| エポック数             | トレーニングデータセット全体をトレーニング中にモデルに学習させた回数                               |
| ミニバッチサイズ       | トレーニングデータのバッチサイズ、トレーニングセットをいくつかのグループに分割する際のサイズのこと |

- RNN（Recurrent Neural Network）: 時系列データや⾃然⾔語処理に利⽤。過去の株価を元に未来を予測など。
- CNN（Convolutional Neural Network）: 主に画像認識の分野で利⽤。特徴量マップを使用。

- 近年の⽣成 AI:
  - 基盤モデルと呼ばれる
  - 事前トレーニングされた巨⼤なニューラルネットワークを利⽤
  - LLM : Large Language Model, ⼤規模⾔語モデル
    - ⼤規模⾔語モデルのできること。⽂章の続きの単語の予測

-　埋め込み: 各トークンを意味を反映する数値列（ベクトル）で表したもの

- LLM の推論に利⽤されるパラメータ

  - Top K: 単語の確率値が⾼い順に K 個までの単語を候補とする
  - Top P: 単語の確率値が⾼い順に、確率の合計値が P% までの単語を候補とする
  - 温度: モデルが出⼒する回答の多様性を調整するパラメータ。温度をあげると多様性が上昇。

- Fine-tuning: 課題に適したモデルにするためにラベル付きデータで再訓練する
  - Instruction Fine-tuning
    - 特定の指⽰に従う能⼒を向上させる⼿法
    - 指⽰と対応する出⼒のペアを含むラベル付きデータセットで Fine-tuning する
  - Domain adaptation Fine-tuning:
    - 特定分野の回答性能を向上させる⼿法
    - 特定のドメインに特化したデータセットを⽤いてモデルを Fine-tuning する
- 継続事前学習 (Continual Pre-training)
  - 基盤モデルに不⾜している⾔語やドメイン知識を習得させるために、⼤量のラベルなしデータを⽤いて追加の事前学習を⾏う
  - メリット: 幅広い精度向上が望める
  - デメリット: ⼤きなコストがかかる
- プロンプトインジェクション: 意図的に作成されたプロンプトを使⽤してモデルを操作して、モデルに設定されている制約を無視させたり、意図しないアクションを実⾏させる

- 責任ある AI の実現に向けてガードレール

  - コンテンツフィルター: 有害な内容にフィルタリングをかけることで安全な出⼒を担保
  - ワードフィルター: ユーザー⼊⼒と基盤モデルからの応答に対してブロックするカスタムの単語のセットを定義
  - 機密情報フィルター: ユーザーのプライバシーを保護するため、基盤モデルの回答に含まれる個⼈情報 (PII) をマスク/ブロック
  - 拒否トピック: 拒否トピックにて望ましくないトピックを回避

- 解釈可能性（Interpretability）
  - 機械学習モデルに対して、そのモデルが予測を返す仕組みそのものを明らかにできること
- 説明可能性（Explainability）
  - 機械学習モデルの予測結果に対して、なぜその予測を返したのか、その理由を説明できること

| 機能名                    | 機能概要                                                                               |
| ------------------------- | -------------------------------------------------------------------------------------- |
| SageMaker Canvas          | 機械学習による正確な予測をコード不要（GUI）で⽣成                                      |
| SageMaker JumpStart       | 数クリックでデプロイ可能な機械学習ソリューションを提供                                 |
| SageMaker Feature Store   | 機械学習モデルの特徴量を保存、共有、管理するためのリポジトリ                           |
| SageMaker Ground Truth    | 信頼された⼈間によるデータセットへのラベリングサービス                                 |
| SageMaker Data Wrangler   | データ準備を含め、機械学習⽤のデータに対してトレーニング、テスト、検証の分割を実⾏     |
| SageMaker Model Card      | 機械学習モデルの使⽤⽬的やリスク評価、トレーニングの詳細や推奨事項を⽂書に起こし⼀元化 |
| SageMaker Model Monitor   | 本番環境の機械学習モデルの品質のモニタリング                                           |
| SageMaker Model Dashboard | アカウント内のモデルを表⽰、検索可能な⼀元化されたポータル                             |
| SageMaker Clarify         | データセットや特徴量の影響⼒、予測の偏りなどの解釈や公平性を確認することが可能         |

- Guardrails for Amazon Bedrock: アプリケーション要件と責任ある AI ポリシーに合わせたガードレールを提供
- AWS Audit Manager: AWS の使⽤状況を⾃動的に監視して、リスクやコンプライアンスの評価を⾏うサービス
