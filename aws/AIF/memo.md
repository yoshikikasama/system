# AIF 学習

- AI、機械学習、深層学習、⽣成 AI の関係
  - AI > 機械学習 > 深層学習 > ⽣成 AI
  - AI :⼈間の知的作業を代替する技術
  - 機械学習: 多数の⼊⼒からパターンを学習する
    - 教師あり学習
    - 教師なし学習
    - 強化学習
  - 深層学習: 多層の学習で複雑なパターンを学習する
  - ⽣成 AI: 新たなコンテンツを⽣成する

| 種類         | 教師あり学習                                   | 教師なし学習                               | 強化学習                                 |
| :----------- | :--------------------------------------------- | :----------------------------------------- | :--------------------------------------- |
| 目的         | 未知データの推定                               | データの分類                               | 最善の行動の学習                         |
| データの種類 | 推定したいデータと推定のもとになるデータセット | 分類したいデータ（推定したいデータは不要） | 行動をシミュレートしてデータを集める     |
| 要は...      | 問題と解答をセットで与えて勉強してもらう手法   | 多数のデータから特徴を見出してもらう手法   | 色々試して、結果がよかった行動を学ぶ手法 |

- ニューラルネットワーク:

  - 機械学習を実装するための有名な⼿法の⼀つ
  - ⼈間の脳の働きを模した構造で学習をする⼿法
  - 複数の頂点とそれに接続する辺から成る層状構造をとる
  - 例えば、数字を判別する場合
  - 数字の要素を分解し、当てはまる確率が⾼い数字を出⼒する
    - 9 は、上半分に丸があるな、下半分は右上から左下に向けての直線だな
    - 9 の特徴に当てはまるな。9 の確率 90%。8 の確率 20%
  - ⼊⼒層 → 中間層 → 出⼒層とデータが流れる

- 深層学習:

  - ニューラルネットを深くしたもの
  - 中間層が 2 層以上のものを特にディープラーニングと呼ぶ
  - 層を増やすことで精度が向上した

- 機械学習のパイプライン
  - データ収集: 質の良い学習のためには質の良いデータが必要。偏りのない、信頼できる⼤量のデータを⽤いて学習を⾏う
  - データの前処理: データの不備や重複を修正してデータの品質を向上させること
  - 特徴量エンジニアリング
    - 特徴量とは予測の⼿掛かりとなる変数のこと
    - 機械学習モデルが予測を⾏うためにトレーニングおよび推論中に使⽤する⼊⼒値
    - 天気を予測する場合
      - 時間情報: ⽇付
      - 地理情報: 緯度、経度、標⾼
      - 気象データ: 気温、湿度、気圧
    - 予測モデルを作成する際に特徴量の選択と変換を⾏うプロセス
    - モデルが効率的に学習できるように特徴量を⼯夫することが重要

| ⼯程                    | 内容                                               |
| :---------------------- | :------------------------------------------------- |
| 特徴量作成              | 既存のデータから新しい特徴量を作り出す             |
| 特徴量変換 , ⽋損値処理 | ⽋損値や無効な値を置き換える                       |
| 特徴量選択              | モデルのターゲット予測に強く関連する変数を選択する |
| 特徴量抽出              | 次元削減などにより処理するデータ量を削減           |

- 教師あり学習:
  - 回帰: 連続値のデータから未来の値を予測すること
    - 例: 過去の株価を元に未来を予測
  - 分類: データが属するクラスを予測して分類すること
    - 学習データに正解となるラベルを与えた状態で学習する⼿法
    - 学習したデータに基づいて、新しく与えられた未知データを分類する
- 教師なし学習の⽤途:

  - 次元削減: ⾼次元のデータをなるべく情報量を減らさずに圧縮
    - 計算量の削減、⼈間に理解できる次元数にする、といった効果がある
    - 例
      - ⾞が持つ特徴: 値段,加速性能,最⾼速度,乗り⼼地,燃費,安全性能,乗⾞定員,エコスコア
      - 着⽬指標を設定: 燃費
      - ⾞の良し悪しを少ない条件で判断できる
  - クラスタリング: 与えられたデータを⼀定の基準に従ってカテゴライズ
    - ⽝や⿃という概念は認識していないため、結果を⾒て⼈間が判断する

- 強化学習:
  - 環境が複雑で動的に変化する状況下での意思決定は⼤変
  - 明確な正解がない（計算できない）→ 結果を評価して⾏動を修正する
  - 例) ゲーム攻略
    - 試⾏錯誤しながらデータを収集し学習する
    - ⼈間の試⾏錯誤に似ている（やってみてデータを集める）
    - データの代わりに試⾏錯誤ができる環境・シミュレーションが必要

|              | 教師あり学習                                                                                                     | 教師なし学習                                                                                                               | 強化学習                                                                 |
| ------------ | ---------------------------------------------------------------------------------------------------------------- | -------------------------------------------------------------------------------------------------------------------------- | ------------------------------------------------------------------------ |
| ⽬的         | 未知データの推定                                                                                                 | データの分類                                                                                                               | 最善の⾏動の学習                                                         |
| データの種類 | 推定したいデータと、推定のもとになるデータセット                                                                 | 分類したいデータ（推定したいデータは不要）                                                                                 | ⾏動をシミュレートしてデータを集める                                     |
| ⼿法の例     | - 回帰: 蓄積された過去のデータを学習して株価や天気を予測<br>- 分類: 動物の画像データから⽝、猫、⿃などを分類する | - クラスタリング: データ間の類似度に基づいてデータをグルーピングする⼿法<br>- 次元削減: データセット内の特徴数を減らす⽅法 | - ゲーム攻略: 良し悪しの基準を与えて試⾏錯誤を⾏い、最適な攻略⼿順を学習 |

- モデルの評価

  - 分類モデル
    - 分類の正確性を評価する指標
    - 混同⾏列: 機械学習を⽤いた分類の性能評価に利⽤する⾏列。機械学習による予測結果と実際の分類を表にしたもの
    - F1 スコア
    - ROC 曲線
  - ⽂章⽣成モデル
    - 出⼒⽂の品質を評価する指標
    - ROUGE: 要約の指標。⽣成された要約⽂と参照要約（⼈⼒で要約した正解データ）を⽤意する。類似度を計算する。
    - BLEU: 翻訳の指標。⽣成された翻訳⽂と参照翻訳（⼈⼒で翻訳した正解データ）を⽤意する。類似度を計算する。
    - BERTScore: 翻訳・画像⾒出しの指標。⾔語モデルを⽤いた評価。⽣成⽂と参照⽂を BERT モデルにインプットする。ベクトル埋め込みを⽤いて類似度を計算。

- 機械学習アプリケーションの例: ランキング
  - ある基準に従って対象を順位付けし、順位が⾼いものを優先的に表⽰
  - クリック率などのユーザーの⾏動、⼈気度を元にアルゴリズムを最適化
- 機械学習アプリケーションの例: レコメンド
  - ユーザーの嗜好や類似ユーザーの⾏動などを基に、興味を持ちそうな対象を表⽰
  - コンテンツや商品の発⾒を容易にし、ユーザー体験を向上
- 機械学習アプリケーションの例: 分類
  - 分類対象がどのクラスに属するかを理解して判別する
  - 分類の⽬的は、与えられたデータを正しいクラスに割り当てること
  - スパムメールフィルター、画像診断
- 機械学習アプリケーションの例: 回帰
  - 現時点までの連続的な値のデータを基に、未来の結果を予測
  - 株価や気温といった数値的な出⼒を予測
- 機械学習アプリケーションの例: クラスタリング。教師なし

  - 類似したデータをグループ化して、⾃然に形成されたクラスター（集団）を発⾒する
  - データは事前にラベル付けされておらず、データの特徴に基づいてグルーピングを⾏う
  - 顧客セグメンテーション、ドキュメント分類。

- ⾃然⾔語処理（NLP）:
  - 機械学習を⽤いて⼈間の⾔語を解釈・操作・理解する技術
  - ⼤量の⾳声・テキストデータから NLP ソフトウェアを使って意図・感情を分析し、リアルタイムに応答できる

| ユースケース   | 使⽤例                                                                     |
| -------------- | -------------------------------------------------------------------------- |
| 機械翻訳       | 外国語がわからない旅⾏者に対し多⾔語対応の案内やサポートを提供             |
| 感情分析       | 顧客からのレビューやフィードバックを⾃動分析してクレーム時の対応に役⽴てる |
| テキスト要約   | 時間のない読者に対し⻑い記事を要約して重要な要素のみ抽出                   |
| ⾳声認識       | 医師の診察中の会話を記録して⾃動的に電⼦カルテに変換                       |
| チャットボット | 24 時間対応可能な⾃動応答システムを提供                                    |

- 固有表現抽出（Named Entity Recognition: NER）
  - ⾮構造化テキストから固有名詞や重要語句を抽出し、あらかじめ定義したカテゴリ(⼈名、組織名、地名など)に分類する
  - 深層学習による⼿法が主流で、テキスト⾃動要約、質問応答システムなど様々な⾃然⾔語処理に関わる課題の基盤として活⽤されている
  - 例) ⼊⼒テキスト︓東京オリンピックで堀⽶悠⽃が⾦メダルを獲得した。
    - 抽出・分類
      - Location・東京
      - Event・オリンピック
      - Person・堀⽶悠⽃
      - Product・⾦メダル
- インテリジェントドキュメント処理（IDP）
  - 紙ベースのドキュメントやその画像から⼿動でデータを⼊⼒する
  - プロセスを⾃動化して、他のデジタル・ビジネス・プロセスと統合する処理
- オーバーフィッティング（過学習）
  - 学習データに過剰に適合し、実際のデータを利⽤した予測が不正確になること
  - 対策としては学習回数を減らす（過剰な適合を抑える）
- ハイパーパラメータ
  - 機械学習モデルのトレーニングを管理するために使⽤する外部設定変数
  - パラメータのチューニングは⼀般的に⼈間が⼿動で調節する
  - モデル構造や機能、パフォーマンスを直接的に制御可能

| ハイパーパラメータ項⽬ | 概要                                                                                               |
| ---------------------- | -------------------------------------------------------------------------------------------------- |
| 学習率                 | アルゴリズムが推定値を更新する率のこと                                                             |
| 学習減衰率             | 学習を⾼速化するために、時間の経過と共に学習率を徐々に低下させていく率のこと                       |
| エポック数             | トレーニングデータセット全体をトレーニング中にモデルに学習させた回数                               |
| ミニバッチサイズ       | トレーニングデータのバッチサイズ、トレーニングセットをいくつかのグループに分割する際のサイズのこと |

- RNN（Recurrent Neural Network）: 時系列データや⾃然⾔語処理に利⽤。過去の株価を元に未来を予測など。
- CNN（Convolutional Neural Network）: 主に画像認識の分野で利⽤。特徴量マップを使用。

- 近年の⽣成 AI:
  - 基盤モデルと呼ばれる
  - 事前トレーニングされた巨⼤なニューラルネットワークを利⽤
  - LLM : Large Language Model, ⼤規模⾔語モデル
    - ⼤規模⾔語モデルのできること。⽂章の続きの単語の予測

-　埋め込み: 各トークンを意味を反映する数値列（ベクトル）で表したもの

- LLM の推論に利⽤されるパラメータ

  - Top K: 単語の確率値が⾼い順に K 個までの単語を候補とする
  - Top P: 単語の確率値が⾼い順に、確率の合計値が P% までの単語を候補とする
  - 温度: モデルが出⼒する回答の多様性を調整するパラメータ。温度をあげると多様性が上昇。

- Fine-tuning: 課題に適したモデルにするためにラベル付きデータで再訓練する
  - Instruction Fine-tuning
    - 特定の指⽰に従う能⼒を向上させる⼿法
    - 指⽰と対応する出⼒のペアを含むラベル付きデータセットで Fine-tuning する
  - Domain adaptation Fine-tuning:
    - 特定分野の回答性能を向上させる⼿法
    - 特定のドメインに特化したデータセットを⽤いてモデルを Fine-tuning する
- 継続事前学習 (Continual Pre-training)
  - 基盤モデルに不⾜している⾔語やドメイン知識を習得させるために、⼤量のラベルなしデータを⽤いて追加の事前学習を⾏う
  - メリット: 幅広い精度向上が望める
  - デメリット: ⼤きなコストがかかる
- プロンプトインジェクション: 意図的に作成されたプロンプトを使⽤してモデルを操作して、モデルに設定されている制約を無視させたり、意図しないアクションを実⾏させる

- 責任ある AI の実現に向けてガードレール

  - コンテンツフィルター: 有害な内容にフィルタリングをかけることで安全な出⼒を担保
  - ワードフィルター: ユーザー⼊⼒と基盤モデルからの応答に対してブロックするカスタムの単語のセットを定義
  - 機密情報フィルター: ユーザーのプライバシーを保護するため、基盤モデルの回答に含まれる個⼈情報 (PII) をマスク/ブロック
  - 拒否トピック: 拒否トピックにて望ましくないトピックを回避

- 解釈可能性（Interpretability）
  - 機械学習モデルに対して、そのモデルが予測を返す仕組みそのものを明らかにできること
- 説明可能性（Explainability）
  - 機械学習モデルの予測結果に対して、なぜその予測を返したのか、その理由を説明できること

| 機能名                    | 機能概要                                                                               |
| ------------------------- | -------------------------------------------------------------------------------------- |
| SageMaker Canvas          | 機械学習による正確な予測をコード不要（GUI）で⽣成                                      |
| SageMaker JumpStart       | 数クリックでデプロイ可能な機械学習ソリューションを提供                                 |
| SageMaker Feature Store   | 機械学習モデルの特徴量を保存、共有、管理するためのリポジトリ                           |
| SageMaker Ground Truth    | 信頼された⼈間によるデータセットへのラベリングサービス                                 |
| SageMaker Data Wrangler   | データ準備を含め、機械学習⽤のデータに対してトレーニング、テスト、検証の分割を実⾏     |
| SageMaker Model Card      | 機械学習モデルの使⽤⽬的やリスク評価、トレーニングの詳細や推奨事項を⽂書に起こし⼀元化 |
| SageMaker Model Monitor   | 本番環境の機械学習モデルの品質のモニタリング                                           |
| SageMaker Model Dashboard | アカウント内のモデルを表⽰、検索可能な⼀元化されたポータル                             |
| SageMaker Clarify         | データセットや特徴量の影響⼒、予測の偏りなどの解釈や公平性を確認することが可能         |

- Guardrails for Amazon Bedrock: アプリケーション要件と責任ある AI ポリシーに合わせたガードレールを提供
- AWS Audit Manager: AWS の使⽤状況を⾃動的に監視して、リスクやコンプライアンスの評価を⾏うサービス

- AWS のマネージド AI/ML サービス (SageMaker、Amazon Transcribe、Amazon Translate、Amazon Comprehend、Amazon Lex、Amazon Polly など) の機能を説明する。

- ML パイプラインの構成要素 [データ収集、探索的データ分析 (EDA)、データの前処理、特徴量エンジニアリング、モデルトレーニング、ハイパーパラメータのチューニング、評価、デプロイ、モニタリングなど] について説明する。
- ML モデルのソース (オープンソースの事前トレーニング済みモデル、カスタムモデルのトレーニングなど) を理解する。
- 本番環境でモデルを使用する方法 (マネージド API サービス、セルフホスト API など) を説明する。
- ML パイプラインの各ステージに関連する AWS のサービスと機能(SageMaker、Amazon SageMaker Data Wrangler、Amazon SageMakerFeature Store、Amazon SageMaker Model Monitor など) を特定する。
- ML 運用 (MLOps) の基本概念 (実験、反復可能なプロセス、スケーラブルなシステム、技術的負債の管理、本番稼働の準備、モデルモニタリング、モデルの再トレーニングなど) を理解する。
- ML モデルを評価するためのモデルパフォーマンスメトリクス [正解率、ROC 曲線下面積 (AUC)、F1 スコアなど] とビジネスメトリクス [ユーザーあたりのコスト、開発コスト、顧客からのフィードバック、投資収益率(ROI) など] を理解する。
- バイアス、信頼性、真実性を検出およびモニタリングするためのツール[ラベル品質の分析、人間による監査、サブグループ分析、AmazonSageMaker Clarify、SageMaker Model Monitor、Amazon Augmented AI(Amazon A2I) など] について説明する。

- ハイパーパラメータ チューニング: ML アルゴリズムの動作を調整する方法です。ハイパーパラメータ チューニングを使用してアルゴリズムの動作を変更することで、ML モデルに変更を加えることができます。
- 特徴エンジニアリング: 予測モデルを作成するときに変数を選択して変換する方法です。特徴エンジニアリングには、特徴の作成、特徴の変換、特徴の抽出、特徴の選択が含まれます。特徴エンジニアリングは、トレーニング データセット内の変数の数を増やすことでデータを強化して、最終的にモデルのパフォーマンスを向上させます。
- モデル モニタリング: データをキャプチャしてそのデータをトレーニング データと比較する ML ライフサイクルのコンポーネントです。モデル モニタリングを使用すると、データ品質の問題、モデル品質の問題、バイアス ドリフト、および特徴帰属ドリフトを特定できます。

- Amazon Textract: スキャンしたドキュメント、PDF、画像からテキストとデータを抽出するために使用できるサービスです。
- Amazon Rekognition: ディープラーニングによる画像およびビデオ分析サービスです。Amazon Rekognition を使用すると、ビジュアル コンテンツを分析して洞察を抽出できます。Amazon Rekognition のユースケースの 1 つは、カスタム ラベルを使用してモデルをトレーニングし、製品をカテゴリに分類することです。要件を満たすには、トレーニング用のラベル付き画像を提供する必要があります。Amazon Rekognition のユースケースの 1 つは、カスタム ラベルを使用してモデルをトレーニングし、製品をカテゴリに分類することです。モデルをトレーニングするには、ラベル付けされた画像をデータセットに提供する必要があります。さらに、モデルがトレーニングに使用するために、画像にカテゴリ別のラベルを付ける必要があります。
- Amazon Comprehend: 自然言語処理 (NLP) を使用してドキュメントから洞察を抽出するサービスです。Amazon Comprehend でカスタムモデルを構築できます。
- Amazon Personalize: インタラクションデータに基づいて検索結果やユーザーセグメントなどの推奨事項をターゲットとする、フルマネージド ML サービスです。Amazon Personalize を使用して、マーケティングキャンペーンをターゲットにすることができます。たとえば、Amazon Personalize は、プロモーションに反応する可能性が最も高いユーザーのセグメントを推奨できます。
- Amazon Kendra: 意味とコンテキストを理解して検索クエリに適切な応答を提供するインテリジェントな検索サービスです。
- Amazon Lex: アプリケーション用の会話型インターフェイスを作成するために使用できる AI サービスです。Amazon Lex は、自然言語理解と自動音声認識を使用してチャットボットを作成します。
- Amazon Translate: 複数の言語間の翻訳に使用できるサービスです。
- Amazon Transcribe:
  - 音声をテキストに変換するために使用できるサービスです。バッチ言語識別を使用すると、オーディオファイルの言語を自動的に識別できます。バッチ言語識別を使用すると、選択した特定の言語のファイルを変換できます。
  - メディアにドメイン固有または非標準の用語が含まれている場合は、カスタム語彙またはカスタムモデルを使用して文字起こしの精度を向上させることができます。ドメイン固有または非標準の用語の例には、ブランド名、頭字語、技術用語、専門用語などがあります。Amazon Transcribe でカスタム言語モデルを使用するソリューションは、ドメイン固有の音声の文字起こしの精度を向上させることができます。
- Amazon Polly : テキストをリアルな音声に変換できるテキスト読み上げ (TTS) サービスです。

- 強化学習は、目標を達成して累積報酬を最大化するように ML モデルをトレーニングする手法です。強化学習では、試行錯誤のプロセスと報酬ベースのシステムが使用されます。
- F1 スコア: バイナリ分類のモデルの精度を評価できます。F1 スコアは、精度と再現率を使用して、モデルが正しいクラスを正しく分類する精度を評価します。
- ROUGE: テキスト要約とテキスト生成の品質を評価するために使用できるメトリックです。ROUGE を使用して、テキスト生成における FM のパフォーマンスを評価できます。
- 微調整: 企業固有またはドメイン固有のデータセットでモデルを微調整することで FM をカスタマイズできるプロセスです。微調整の目的は、モデルがより適切な予測を行い、特定のビジネス ニーズに合わせて一般化できるようにすることです。
- オーバーフィット: 機械学習モデルがトレーニングデータに対して正確な予測をするが、新しいデータについては正確に予測しないという、望ましくない機械学習の動作です。
  - トレーニングデータのサイズが小さすぎて、考えられるすべての入力データ値を正確に表すのに十分なデータサンプルが含まれていない。
  - 無関係な情報 (ノイズを含むデータと呼ばれます) がトレーニングデータに大量に含まれている。
  - 1 つのサンプルデータセットに対して、モデルのトレーニング時間が長すぎる。
  - モデルの複雑度が高いため、トレーニングデータ内のノイズを学習する。
- アンダーフィット: モデルが入力データと出力データの間に意味のある関係を決定できない場合に発生する別のタイプのエラーです。適切な時間にわたって、多数のデータポイントでトレーニングしなかった場合、モデルはアンダーフィットとなります。

| **機能名**     | **内容**                                                  | **用途**                                                                     |
| -------------- | --------------------------------------------------------- | ---------------------------------------------------------------------------- |
| Rekognition    | 画像や動画を分析するサービス                              | 画像認識（顔認識、モノの数のカウント）、有害な画像の判断                     |
| Personalize    | 履歴に基づいてレコメンドを実施するサービス                | 動画配信サイトや EC サイトのあなたへのオススメ                               |
| Textract       | 画像や PDF からテキストを抽出するサービス                 | 請求書や領収書のデータ化                                                     |
| Comprehend     | テキストを分析するサービス                                | テキストの感情分析、人名など固有名詞等の検出                                 |
| Polly          | テキストを音声に変換するサービス                          | AI アシスタントに喋らせる、自動アナウンス                                    |
| Kendra         | 意味とコンテキストを理解して検索するサービス              | 近年は生成 AI の RAG として需要が高い                                        |
| Lex            | 言語理解・音声認識を行いチャットボットを作成するサービス  | チャットボット                                                               |
| Translate      | 複数言語間でテキストを翻訳するサービス                    | 翻訳                                                                         |
| Transcribe     | 音声をテキストに変換するサービス                          | 会話の自動書き起こし                                                         |
| Macie          | S3 の個人情報や機密データを検出して分類・保護するサービス | コンプライアンス対応                                                         |
| Fraud Detector | 不正行為（詐欺）の検出を自動化するサービス                | クレジットカード詐欺、アカウント乗っ取り、不正な新規アカウント作成などの検出 |

- Amazon SageMaker

  - SageMaker Role Manager: ML アクティビティのユーザー権限を定義できます。
  - SageMaker モデルカード: レコードを作成し、ML モデルの詳細を 1 か所で文書化できます。SageMaker モデルカードは、重要なモデル情報の包括的で不変の文書化を提供することで、透明性と説明性に優れたモデル開発をサポートします。
  - SageMaker モデルダッシュボード: AWS アカウント内のすべてのモデルを表示、検索、探索するための中心的な場所です。モデルのデプロイメント、使用状況、パフォーマンスの追跡、およびモニタリングに関する洞察を提供します。
  - SageMaker Model Monitor: 本番環境の ML モデルとデータの品質を監視します。
  - SageMaker JumpStart: 画像生成用の事前トレーニング済みの基礎モデル (FM) を含む SageMaker の機能です。追加のトレーニングなしで SageMaker でモデルをホストできます。ただし、このソリューションでは、ML モデルをホストする本番エンドポイントを設定および監視する必要があります。
  - SageMaker Canvas: 非技術者向けのノーコードツール
  - SageMaker JumpStart: エンジニア向けのテンプレート
  - SageMaker のその他機能の組み合わせ

- SageMaker の推論タイプ

  - リアルタイム推論
    - 60 秒以内に終わる処理、データサイズも 6MB 以下
    - 裏でサーバーが常時起動するため、デプロイ中ずっと料金が発生（高価）
  - サーバーレス推論
    - 60 秒以内に終わる処理、データサイズも 6MB 以下
    - たまにしか推論しない場合、リクエスト数が予測できない場合に当てはまる
    - レイテンシ要件が厳しい場合、ヨールドスタートがあるため向かないケースも
  - 非同期推論
    - 1 時間以内に終わる処理、データサイズは 1GB まで
  - バッチ推論
    - 数日の処理時間をサポート、データサイズも 1GB 以上に対応（最小でも 100MB 必要

| **機能名**                | **内容**                                                                 | **参考リンク**                                                                                             | **用途**           |
| ------------------------- | ------------------------------------------------------------------------ | ---------------------------------------------------------------------------------------------------------- | ------------------ |
| SageMaker Role Manager    | SageMaker Studio（実行環境）のユーザの権限を定義する機能                 | [リンク](https://docs.aws.amazon.com/sagemaker/latest/dg/role-manager.html)                                | 権限管理           |
| SageMaker Model Card      | 学習したモデルの情報を提供する機能                                       | [リンク](https://docs.aws.amazon.com/sagemaker/latest/dg/model-cards.html)                                 | 説明性と透明性     |
| SageMaker Model Dashboard | SageMaker のリソースの使用状況の確認やパフォーマンスの追跡をする機能     | [リンク](https://docs.aws.amazon.com/sagemaker/latest/dg/model-dashboard.html)                             | リソース管理       |
| SageMaker Model Monitor   | 稼働中の機械学習モデルの品質を監視する機能                               | [リンク](https://docs.aws.amazon.com/sagemaker/latest/dg/jumpstart-foundation-models.html)                 | モデル監視         |
| SageMaker Canvas          | モデル学習からデプロイまでを GUI で行う機能                              | [リンク](https://docs.aws.amazon.com/sagemaker/latest/dg/canvas.html)                                      | ノーコード         |
| SageMaker Data Wrangler   | Canvas 内で使うデータ前処理を GUI で行う機能                             | [リンク](https://docs.aws.amazon.com/sagemaker/latest/dg/canvas-data-prep.html)                            | ノーコード         |
| SageMaker JumpStart       | モデル学習からデプロイまでを行うテンプレート                             | [リンク](https://docs.aws.amazon.com/sagemaker/latest/dg/studio-jumpstart.html)                            | テンプレート学習   |
| SageMaker Feature Store   | モデル学習に使用する特徴量を蓄積する機能（Athena を裏側で使う）          | [リンク](https://docs.aws.amazon.com/sagemaker/latest/dg/feature-store.html)                               | 特徴量管理         |
| Augmented AI              | 機械学習の結果に対して人間によるチェックを含むワークフローを提供する機能 | [リンク](https://docs.aws.amazon.com/sagemaker/latest/dg/a2i-use-augmented-ai-a2i-human-review-loops.html) | 人間のレビュー支援 |

- <img width="1286" alt="image" src="https://github.com/user-attachments/assets/b9af49de-b097-4232-a4ae-b75b599390a5">

  - Feature Store はそのプロセスの過程で特徴量を作成するため、そちらを保存する機能です。
  - モデルの学習には正解データが必要となるケースが多く、その正解ラベル付けに Ground Truth を使用できます。
  - モデル学習後は責任のある AI の透明性の観点からモデルの情報を説明するための Model Card という機能が使用できます。
  - 最終的に稼働するようになった推論エンドポイントの監視のために Model Monitor を使用します。
  - 推論エンドポイントの予測結果の信頼性が高くない場合、人間によるレビューを挟むことができ、これを Augmented AI という機能が担います。
  - こちらは Ground Truth と勘違いしやすいためお気を付けください。
  - Canvas と JumpStart については割愛しますが、Data Wrangler も Canvas に同梱された前処理のノーコードツールという形で機能を担っています。
  - あとは Studio が実行環境を提供し、その実行環境の権限管理に使われるのが Role Manager という機能です。

<img width="989" alt="image" src="https://github.com/user-attachments/assets/87caea73-1909-4998-bc6d-fa5fd240b63b">

- Model Monitor は大きく３つの観点でモデルを監視します。
  - 入力側
    - 入力データの特性や分布が学習時と変化していないか監視します
    - 欠損値や異常な値を監視することも含まれています
  - 出力側
    - 予測の品質が変わっていないことを監視します
    - 予測品質を計算するためには、正解ラベル付けが必要な場合もあります
  - モデル内
    - モデル内の特徴量の使い方などの判断基準が変わってないかを監視します
    - また第 1 回でバイアスについて述べましたが、特定のバイアスに依存して判断をしていないか監視が可能です。
    - 最後のモデル内の機能は、裏側では SageMaker Clarify という別の機能が担っており、これが継続的に実行されることで監視されます。
- プロンプトエンジニアリング

  - ゼロショット学習: タスクに関する説明のみが与えられ、解答例は全く与えられないケース
    - ex) "Classify the following text as either sports, politics, or entertainment: [input text]."
  - 少数ショット学習: タスクに関する説明と少量の解答例を与える方式
    - ex) "[image 1], [image 2], and [image 3] are examples of [target class]. Classify the following image as [target class]"
  - One shot 学習: few-shot において、回答例の数が一つである方式

- 生成 AI のコンテキストにおける基礎モデル (FM) とは

  - FM は、膨大な量のデータで事前トレーニングされ、複数のタスクを実行できる大規模なモデルです。FM は、より小さなデータセットを使用して、下流のタスクに合わせて微調整できます。

- ラベル付きデータとは、各インスタンスまたは例に、目的の出力または分類を表すラベルまたはターゲット変数が付随するデータセットです。これらのラベルは通常、人間の専門家によって提供されるか、信頼できるプロセスを通じて取得されます。
- ラベルなしデータとは、インスタンスまたは例に関連付けられたラベルやターゲット変数がないデータセットです。データは入力機能のみで構成され、対応する出力や分類はありません。

- 深層学習:

  - データの分割: データセットは 3 つに分けられる
    - 学習データ: 深層学習モデル内のパラメータの更新に使用される
    - 検証データ: 学習時に過学習が起きないかどうかを検証するために用いる
    - テストデータ: 学習終了後の評価に使用される

- ミニバッチ（Mini-batch）とは？
  - 定義: 学習データ全体を小さな塊（サブセット）に分割したもの。
  - 目的:
    - 計算の効率化: 大量のデータを一度に処理するのは現実的でないため、部分的に処理します。
    - モデルの更新頻度を高める: 1 つのミニバッチごとにモデルを更新することで、学習が早く進む場合があります。
  - サイズ（バッチサイズ）:
    - 1 つのミニバッチに含まれるデータの数を「バッチサイズ」と呼びます。
    - 例: 学習データが 10,000 件で、バッチサイズを 100 に設定すると、1 エポックで 100 個のミニバッチができます。
- エポック数（Epoch）とは？

  - 定義: 学習データ全体を 1 回すべて使い切るまでの学習の繰り返し回数。
  - 目的:
    - データ全体を繰り返し学習させることで、モデルの予測精度を向上させる。
  - 例:
    - 学習データが 10,000 件、バッチサイズが 100 の場合、1 エポックには 100 回のミニバッチ処理が含まれます。
    - エポック数を 10 に設定した場合、学習データ全体が 10 回繰り返し使われることになります。

- 初期段階では、学習データの損失が十分に下がっていないアンダーフィッティングの状態のため、まだ学習を進める必要があります。
- また学習を進めすぎると、検証データの誤差が増えてしまっており、学習データについて過学習となっています。
- そのため検証データが最小となる点で学習を打ち切ることが多く、この打ち切ることを early-stopping と呼びます。

- Linear Learner
  - 回帰（Regression）と分類（Classification）の両方に使えるモデル。
  - 具体例:
    - 回帰: 家の面積を入力して、予測価格（連続値）を出す。
    - 分類: 画像を見て「猫」か「犬」かを判定する。
  - モデルの種類:
    - 線形回帰: 回帰タスクに使う。
    - ロジスティック回帰: 分類タスクに使う。
- k-近傍法（k-NN）
  - データがどのグループに属するかを近くのデータ（近傍）を見て判断する。
  - 特徴:
    - 分類: 例えば、「新しいデータが猫か犬か」を、近くのデータのラベルを見て決める。
    - 回帰: 例えば、「新しいデータの家の価格」を、近くの家の価格を基に予測する。
  - 注意: k-NN は教師あり学習に分類されます。
- k-means

  - データを自動的にグループ分け（クラスタリング）する。
  - 特徴:
    - 例: 顧客データを「年齢」と「購買金額」でプロットし、顧客を 3 つのグループに分ける。
    - 教師なし学習: 正解ラベルがなくても動作する。

- 勾配ブースティング決定木（XGBoost, LightGBM, CatBoost）
  - 「勾配ブースティング」というアルゴリズムを使った強力なモデル。
  - たくさんの「決定木」を組み合わせて、予測精度を高める。
  - XGBoost: 高い精度で広く使われている。
  - LightGBM: 高速で軽量。大きなデータセットに向いている。
  - CatBoost: カテゴリーデータ（文字データ）の扱いが得意。
- AutoGluon
  - AutoML フレームワーク: モデル作成を自動化してくれるツール。
  - 例えば、「データを渡せば最適なモデルを自動で選んでくれる」イメージ。
- TabTransformer

  - Transformer（AI モデル）をテーブル形式のデータ（CSV など）で使うための仕組み。
  - 例: 売上データや顧客情報のような表形式データを効率よく学習させるためのモデル。

- MXNet: 画像分類や物体検出などのディープラーニングに利用されるフレームワークです。高速で柔軟な特徴を持っており、特にディープラーニングのモデルを効率的に作成・トレーニングするために使われます。
- BlazingText: テキスト分類や埋め込みの生成に特化した Amazon の機械学習ライブラリです。
- Sequence to Sequence（Seq2Seq）: 主に自然言語処理（NLP）タスクに使用されるアーキテクチャです。翻訳や文生成などのシーケンスデータに対して適しています。
- Object2Vec: オブジェクトに関する情報をベクトルとして表現する技術。

- XGBoost:
  - ブースティングという手法を用いて、弱い予測モデルを組み合わせて強力な予測モデルを作る手法です。
  - 機械学習でよく使われるアルゴリズムの一つで、主に分類や回帰といった予測タスクで高い精度を発揮します。基本的には、多くの「弱い」モデル（通常は決定木）を組み合わせて、全体として強いモデルを作るアンサンブル学習の手法の一つです。
  - 大量のデータでも素早く学習できるというメリットも持ち合わせています。
