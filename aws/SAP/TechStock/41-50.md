# Techstock

## 41.

- AWS Resource Access Manager:

  - アカウント間で AWS リソースを簡単に共有するためのサービス。
  - ユーザーは異なる AWS アカウントや AWS Organizations で共有リソースをセキュアに提供できる。

- AWS PrivateLink: クライアントの VPC 内で ENI を使用します。これにより、サービスプロバイダとの IP アドレス競合が発生せず、同一のアドレス範囲を使用した二つの VPC 間でも通信が可能となる。

- Amazon FSx For Lustre:
  - 高パフォーマンスの Lustre ファイルシステムを提供し、大規模なデータセットを処理するために必要なスループットを提供する。
  - 世界最速のコンピュータ向けに設計された広く使用されているファイルシステム。
  - FSx For Lustre は S3 と統合されている。

## 42.

- VPC フローログ: VPC 内のネットワークインターフェースに出入りする IP トラフィックに関する情報を取得するための機能。
- ALB のアクセスログ: クライアント IP アドレス、接続タイプ、ユーザーエージェントなどの詳細情報を含む。

- Amazon RDS for MySQL のクロスリージョンリードレプリカ機能:

  - 複数の region でデータベースの可用性を高めるための仕組み。
  - 主要なデータベースがダウンした際にすぐにリードレプリカをスタンドアロンの DB インスタンスに昇格させることができ、サービスのダウンタイムを最小限に抑えることができる。

- RTO: 災害が発生した後、業務再開にどの位の時間を要するかを表します。
- RPO: 災害が発生した際にどの規模のデータが失われるかを表します。例えば、RPO が 1 時間であるということは、災害の発生により 1 時間分に相当するデータが失われる可能性があるという意味です。

- Amazon RDS の DR 機能:

  - ![Screenshot 2023-07-17 at 11 39 40](https://github.com/yoshikikasama/network-and-server/assets/61643054/ddd88e72-1a09-4da4-8337-437a9098e643)

- AWS Global Accelerator:

  - 世界中の顧客に提供するアプリケーションの可用性とパフォーマンスを改善するネットワーキングサービスです。
  - AWS Global Accelerator が提供する静的 IP アドレスを、Network Load Balancer、Application Load Balancer、EC2 インスタンス、Elastic IP アドレスなどのリージョン別 AWS リソースまたはエンドポイントに関連付ける。IP アドレスは AWS エッジロケーションからのエニーキャストであるため、ユーザーに近い AWS グローバルネットワークへのオンボーディングを提供します。
  - ゲーム (UDP)、IoT (MQTT)、Voice over IP などの HTTP 以外のユースケース、およびスタティック IP アドレスまたは確定的な高速地域フェールオーバーを特に必要とする HTTP ユースケースに最適です。

- Cross-Origin Resource Sharing(CORS):

  - 異なるオリジン間でリソース共有を制御するブラウザの機能。
  - これが有効でないとセキュリティポリシーによりリクエストがブロックされる。
  - ブラウザ上のスクリプトが Amazon API Gateway API リクエストを送信するためには CORS を有効にする必要がある。
  - 異なるドメインまたは、オリジンでホストされている API にアクセスする web アプリケーションを構築するために必要。

- EC2 の拡張ネットワーキング: 更なるネットワークパフォーマンス向上に貢献する。

## 43.

- Amazon Macie: S3 Bucket を分析して、public object, public bucket または機密情報が S3 内に存在するかを確認
- AWS Security Hub: AWS 環境全体のセキュリティ体制を包括的に把握し、セキュリティ標準およびベストプラクティスに照らして環境をチェックするのに役立つサービス。
- Amazon CloudFront のオリジングループ: 複数の S3 Bucket を設定することができ、プライマリオリジンが利用できない場合に自動的にセカンダリーオリジンに切り替えることができる。

- Event Bridge lambda 失敗: 処理試行に失敗すると Lambda は呼び出しレコードを標準 Amazon SQS Queue に送信する。
- S3 event 通知 lambda 失敗: S3 はその lambda 関数の呼び出しを再試行しない、また S3 event 通知は関数が失敗した場合や特定のエラーが発生した場合のコールバックメカニズムを提供しない。

## 44.

- Transit Gateway アタッチメント: VPC や VPN 接続などのリソースを Transit Gateway に接続するために使用される。
- Transit Gateway ピアリング アタッチメント: 異なる Transit Gateway 間での接続を確立するために使用される。
- AWS Application Discovery Service: オンプレミスサーバーの使用状況と構成データを収集することで AWS クラウドへの移行計画を支援する。
- Migration Hub: 各アプリケーションの移行ステータス情報を集約
- AWS Application Discovery Agent: 静的構成データ、詳細な時系列システムパフォーマンス情報などを収集する。Windows, Linux OS で利用できる。

- Amazon Timestream:
  - 高速でスケーラブルなサーバレスの時系列データベース。
  - 最近のデータ用のメモリストアと履歴データ用の磁気ストアを使用してデータライフサイクル管理を簡素化する。
  - クエリを定期的かつ自動的にスケジュールし、受信データに対してリアルタイム分析が実行できる。

## 45.

- EC2 バーストパフォーマンス:

  - T インスタンスファミリーは、ベースラインの CPU パフォーマンスを提供しながら、いつでも必要な時間だけ、能力をベースライン以上にバーストさせる機能を備えている。
  - T インスタンスでは、コンピューティング、メモリ、ネットワークリソースがバランスしているので、CPU 使用率が低〜中程度の広範な汎用アプリケーションを実行するための費用対効果が最も高い方法。

- Route53 インバウンドリゾルバーエンドポイント: オンプレミスシステムから VPC 内のリソースへ DNS クエリが可能になる。
- Route53 インバウンドリゾルバーエンドポイント: VPC 内のリソースからオンプレミスシステム へ DNS クエリが可能になる。

- Amazon S3 Transfer Acceleration: クライアントと S3 Bucket 間での Upload パフォーマンスを改善できる。

## 46.

- AWS DataSync: オンプレミス環境と AWS クラウド間のデータ転送を容易にし、スケジュール可能なタスクを生成する。

- AWS Cost Categories: 各アプリケーションのコストカテゴリを作成し、アプリケーションごとのコストを分類し、詳細なレポートや分析が可能に。
- Cost Explorer: 過去 12 ヶ月分のコストを比較し、次の 12 ヶ月分のコストを予測する。

- ssm での ec2 ログイン

- 手動で作成した AWS リソースを CloudFormation 化する方法:
  - AWS CloudFormation Console を使用して既存のリソースを import し、新しいスタックを作成できる。

## 47.

- コストと使用状況レポート: AWS レポートを送信する Amazon S3 Bucket も所有している必要がある。

- クロスアカウントアクセスの標準的なガイドライン:

  - 本番環境:
    - 共有 IAM Role を作成
      - 開発アカウントの信頼ポリシー追加
  - 開発環境:
    - 開発 IAM Group: アプリケーションインフラを作成および削除できる
    - Operation IAM Group: 共有ロールを引き受けることができる
    - 開発者用の IAM ユーザーを作成し、開発 IAM Group に割り当てる
    - Operation 用の IAM ユーザーを作成し、開発 IAM Group と Operation IAM Group に割り当てる

- Amazon WorkSpaces のクロスリージョンリダイレクト:

  - WorkSpaces の登録コードとして完全修飾ドメイン名(FQDN)を使用できる。
  - WorkSpaces の接続エイリアスを使用して、Amazon Route53 位置情報ルーティングを行える。

- AWS WAF:
  - クロスサイトスクリプティングを含む一般的な攻撃手法を防止し、ボリューム型サービス拒否から保護するために Amazon CloudFront と関連づけることができる。
  - ALB はカスタムヘッダーを追加することで CloudFront からのトラフィックのみを許可するように設定することができる。
  - ユーザーが Application Load Balancer (ALB) に直接アクセスすることを制限し、AWS WAF を使用して Amazon CloudFront からのみアクセスを許可:
    - CloudFront が ALB に送信するリクエストにシークレット値を持つカスタム HTTP ヘッダーを追加するように CloudFront を設定する。
    - ALB に関連付けられた AWS WAF ウェブ ACL で、カスタム HTTP ヘッダーシークレット値を含まないリクエストをブロックするルールを作成する。

## 48.

- AWS DataSync: データ移行を簡素化し、ファイルまたはオブジェクトデータをストレージサービスへ、ストレージサービスから、AWS またはストレージサービス間で迅速、簡単、安全に転送できるようにするオンラインデータ移動および検出サービスです。

- DynamoDB Auto Scaling: AWS Application Auto Scaling サービスを使用し、実際のトラフィックパターンに応じてプロビジョンドスループット性能をユーザーに代わって動的に調節します。これにより、テーブルまたはグローバルセカンダリインデックスで、プロビジョンされた読み込みおよび書き込み容量が拡張され、トラフィックの急激な増加をスロットリングなしに処理できるようになります。ワークロードが減ると、Application Auto Scaling はスループットを低下させ、未使用のプロビジョンされた容量に料金が発生しないようにします。

- DynamoDB Accelerator(DAX): 読み取り速度を向上させるためのキャッシュ層。

- Amazon DynamoDB 読み取り/書き込みキャパシティモード:

  - オンデマンド:
    - 容量計画なしで 1 秒あたりに数千ものリクエストを処理できる柔軟な請求オプションです。DynamoDB オンデマンドには、読み取りおよび書き込みリクエストのリクエストごとの支払い料金が用意されているため、使用した分だけ課金されます。
    - アプリケーションで実行することが予測される読み込みおよび書き込みスループットを指定する必要はありません。
  - プロビジョニングモード:
    - アプリケーションに必要な 1 秒あたりの読み込みと書き込みの回数を指定します。Auto Scaling を使用すると、トラフィックの変更に応じて、テーブルのプロビジョンドキャパシティーを自動的に調整できます。これにより、コストの予測可能性を得るため、定義されたリクエストレート以下に維持されるように DynamoDB を制御することができます。

- Amazon Elasticsearch Service:

  - AWS Cloud の Elasticsearch クラスターを簡単にデプロイ、運用、スケールする Managed Service
  - 検索に特化したクエリを投げることができる DB のようなもの。
  - Elasticsearch はログ分析、リアルタイムのアプリケーションモニタリング、クリックストリーム分析などのユースケース向けのオープンソース検索および分析エンジン。

- Amazon API Gateway で API キャッシュ:
  - API キャッシュを有効にして、エンドポイントのレスポンスがキャッシュされるようにできます。キャッシュを有効にすると、エンドポイントへの呼び出しの数を減らすことができ、また、API へのリクエストのレイテンシーを短くすることもできます。
  - API Gateway は、秒単位で指定した有効期限 (TTL(Time To Live)) が切れるまで、エンドポイントからのレスポンスをキャッシュします。その後、API Gateway は、エンドポイントへのリクエストを行う代わりに、キャッシュからのエンドポイントのレスポンスを調べます。API キャッシュのデフォルトの TTL 値は 300 秒です。最大の TTL 値は 3600 秒です。TTL=0 は、キャッシュが無効なことを意味します。

## 49.

- AWS Global Accelerator: AWS のグローバルインフラストラクチャを利用してユーザーのトラフィックのパフォーマンスを最大 60%向上させるネットワーキングサービス。

  - ![Screen Shot 2022-08-26 at 15 48 33](https://user-images.githubusercontent.com/61643054/186840253-0a1a1860-6e4f-42a5-a65f-9e0f10aeb3b6.png)

- オンデマンドキャパシティー予約: 特定の AZ で任意の所有時間だけ、EC2 のコンピューティング能力を予約できる。
- Saving Plans: 1 年または 3 年の固定契約でコストを削減する。

- Amazon Aurora Global Database: 複数の AWS リージョン にまたがり配置されます。これにより、低レイテンシーのグローバル読み取りを実現し、AWS リージョン 全体に影響が及ぶ可能性のある停止がまれに起きても、すばやい復旧を可能にします。Aurora Global Database には、1 つのリージョンにプライマリ DB クラスターがあり、異なるリージョンに最大 5 つのセカンダリ DB クラスターがあります。

## 50.

- AWS Application Discovery Service:

  - vCenter 管理下の VM の設定と使用状況データを収集することができる。
  - VMware vCenter Server 環境で稼働している Windows と Linux の仮想マシンに対応。
  - エージェントベースとエージェントレスがある
  - エージェントベース:
    - 物理サーバーにエージェントをインストールし情報を収集します。サーバー上の詳細な情報を取得することができます。パッケージ、プロセス、ネットワーク通信などの情報を取得することができます。
    - エージェントレスで一度アセスメントを実施し、そのあと必要であればエージェントベースでのアセスメントを実施する流れが推奨のようです。
    - AWS Application Discovery Service Agent:
      - 検出と移行の対象となるオンプレミスサーバーと VM にインストールするソフトウェアです。エージェントは、システム設定、システムパフォーマンス、実行中のプロセス、およびシステム間のネットワーク接続の詳細をキャプチャします。エージェントは、Linux および Windows オペレーティングシステムの大半をサポートし、物理的なオンプレミスサーバー、Amazon EC2 インスタンス、および仮想マシンにデプロイできます。
  - エージェントレス:
    - VMware vVenter Server 利用時の推奨。VM 上に AWS Agentless Discovery Connector(OVA 提供)をダウンロードして ADS 用の仮想マシンを起動することで情報を収集します。 各サーバーにエージェントをインストールする必要がない、OS タイプ(バージョンなど)に依存せず収集が可能というメリットがあります。その半面、VMware から取得可能な情報のみを収集します。(OS パッケージなどは取得できない)
    - AWSAgentless Discovery Connector (Discovery Connector) :
      - VMware 仮想マシン (VM) に関する情報のみを収集できる VMware アプライアンスです。Open Virtualization Archive (OVA) ファイルを使用して VMware vCenter Server 環境に VM として Discovery Connector をインストールします。Discovery Connector は、オペレーティングシステムの種類を問わず、VMware メタデータに基づいてサーバー情報を収集するため、オンプレミスインフラストラクチャの初回評価の所要時間を最小限に抑えます。

- AWS Migration Hub: AWS Application Discovery Service を使用してデータを収集。

- EC2 のプレイスメントグループ:

  - クラスター: アベイラビリティーゾーン内でインスタンスをまとめます。この戦略により、ワークロードは、ハイパフォーマンスコンピューティング (HPC) アプリケーションで典型的な緊密に組み合わされたノード間通信に必要な低レイテンシーネットワークパフォーマンスを実現できます。
  - パーティション: インスタンスを複数の論理パーティションに分散させ、1 つのパーティション内のインスタンスのグループが基盤となるハードウェアを別のパーティション内のインスタンスのグループと共有しないようにします。この戦略は、Hadoop、Cassandra、Kafka などの大規模な分散および複製ワークロードで一般的に使用されます。
  - スプレッド: 相関性のエラーを減らすために、少数のインスタンスを基盤となるハードウェア全体に厳密に配置します。

- Amazon EFS のレプリケーション:
  - クロスリージョンレプリケーションをサポートしており、セカンダリーリージョンに EFS のバックアップを取得できる。
- Amazon Kinesis Data Firehose:

  - ストリーミングデータをデータストアや分析ツールにロードする最も簡単な方法です。Kinesis Data Firehose は、フルマネージドサービスです。このサービスでは数十万ものソースからの膨大なボリュームのストリーミングデータを簡単にキャプチャして変換し、Amazon S3、Amazon Redshift、Amazon OpenSearch Service、Kinesis Data Analytics、汎用 HTTP エンドポイント、および Datadog、New Relic、MongoDB、Splunk などのサービスプロバイダーにロードできます。データをほぼリアルタイムで分析し、深いインサイトを得ることが可能です。

- Amazon Kinesis Data Streams: データ取得。最大の特徴は「レイテンシの速さ」です。Kinesis Firehose がデータロードまで 60 秒を見ているのに対し Kinesis Streams は sub-1、つまり 1 秒以下でのデータロードにて設計されています。次々に上がってくるデータの内容をリアルタイムに加工、表示させる。
- Amazon Kinesis Data Firehose: データ変換+データ格納処理。「Zero Administration(ゼロ管理)」というのが挙げられます。Kinesis Streams とは違い、EC2 からポーリングしたり Lambda のコードを書く必要は一切ありません。設定を行うだけで S3 や Redshift にデータがそのまま流れます。 S3 や Redshift に大量のデータを溜める目的は何か。それはズバリ「分析用途」です。各種 BI ツールでデータをわかりやすく表示し、様々なクエリをかけて多様な切り口からデータを分析するために Redshift のような DWH は存在します。 分析するのにデータが put されてから処理するまでのスピードはそれほど求められません。逆に求められるのは大量のデータを効率よく格納する圧縮技術やいかにセキュアにデータを保持するか、という暗号化技術です。 Firehose は GZIP や SNAPPY といった圧縮アルゴリズムが使えますし、KMS を使った暗号化も可能になっています。

- AWS Database Migration Service(AWS DMS): データの継続的なレプリケーションに使用。
- Amazon RDS Proxy: Amazon RDS データベースとアプリケーションの間に位置し、データベースへの接続を管理するフルマネージドのデータベースプロキシサービスです。以下のような機能を提供するため、このシナリオでは Amazon RDS Proxy を使用することが推奨されます。

  - 接続の再利用: Amazon RDS Proxy は、複数のアプリケーションからの接続をプールし、データベースへの新規接続のオーバーヘッドを削減します。これにより、大量の並行リクエストを効率的に処理できます。
  - スケーラビリティ: Amazon RDS Proxy は、接続の数と時間を効率的に管理し、高負荷の状況でのパフォーマンスとスケーラビリティを改善します。AWS Lambda から RDS データベースへの接続時に特に有用です。なぜなら、Lambda がスケールアウトすると、大量の新規接続が一度に発生し、データベースがオーバーロードする可能性があるからです。
  - レジリエンシーとフェールオーバー: Amazon RDS Proxy は、データベースへの接続を維持し、データベースエンジンが再起動したりフェールオーバーしたりした場合でも、トランザクションとセッションの状態を維持することができます。これにより、アプリケーションの中断を最小限に抑えることができます。
  - セキュリティ: Amazon RDS Proxy は、IAM ロールやセキュリティグループを使用してアクセスを制御し、Secrets Manager を通じてデータベースの認証情報を安全に管理します。これにより、アプリケーションのセキュリティを強化することができます。
  - 以上の理由から、このシナリオではデータ収集の Lambda 関数と Aurora MySQL データベース間に Amazon RDS Proxy を使用します。

- 接続プーリング: データベースとの接続を再利用する手法の一つです。これは、アプリケーションとデータベース間の新規接続の確立には時間とリソースが必要であり、アプリケーションが短時間で多数の接続を必要とする場合に特に有効です。
  - 接続プーリングの仕組みは以下の通りです：
    - アプリケーションがデータベースに接続を要求すると、接続プールマネージャー（この場合は Amazon RDS Proxy）は、既存の接続プールから利用可能な接続を探します。
    - 利用可能な接続があれば、その接続をアプリケーションに提供します。アプリケーションはその接続を使用してデータベースと通信します。
    - アプリケーションが接続を閉じると、実際には接続は閉じずに接続プールに戻され、再利用が可能となります。これにより、新たな接続を確立するための時間とリソースを節約することができます。
    - これらの理由から、接続プーリングは頻繁にデータベースとの短期間の接続を必要とするアプリケーション、特に Web アプリケーションやマイクロサービスなどで広く利用されています。
