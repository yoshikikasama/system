# Amazon Bedroock 生成 AI アプリ開発入門

## 前提

[ソースコード](https://github.com/minorun365/bedrock-book)

## 第 1 章 生成 AI とは

- 人工知能(AI): 知能を持った人間だからこそ行えるような高度な作業(文書の作成やデータの分析など)を人工的に実現する技術や研究分野
- 生成 AI: 様々なコンテンツを生成できる AI の総称
- 機械学習: 与えられたデータを機械(コンピュータ)が自動で学習し、データの背景にある法則を見つけ出します。こうして学習した法則を元にデータを分類したり、未知のデータを予測したりできます。
- 深層学習: 人間の脳の神経回路を模した仕組みを用いて学習を行う手法。データの入力と出力を直接関係づけるのではなく、その間に中間層という構造を多く設けることから深層学習と呼ばれている。コンピューターがあるデータを学習する上で手掛かり(特徴量)を人間が設定する必要がありました。深層学習ではこの特徴量を自動で見つけることができます。
- 基盤モデル: 大量のデータで事前にトレーニングされた汎用的なモデル。
- ファインチューニング: データの微調整。
- 大規模言語モデル(LLM): 基盤モデルの一つで、言語ベースの処理を汎用的にこなすもの。LLM は入力されたテキストの単語の組み合わせをもとにして、その後に続く確率が高い次の単語を予測します。
- パラメーター: 深層学習におけるモデルの挙動を決定するための変数。パラメーターの数が大きいほど推論性能が上がります。(例；70B= 70 billion、700 億パラメータを表す)
  - 小さすぎると十分な性能が出ない一方で大きすぎると学習や推論に必要な計算リソースが増大するなどのデメリットもあります。
- トークン:　生成 AI のモデルがデータを処理する単位。
- 埋め込み(Embedding): 機械学習の用語でテキストや画像などのデータをベクトル(大きさと向きを持つ量)で表現したものを指す。ベクトル数値を用いた回答により自然言語での意味検索ができる。
- チャンク: 生成 AI のモデルに入力として渡すドキュメントの塊。チャンクが大きすぎると複数のトピックを含む長い文章をベクトルに変換する過程でニュアンスが失われる。Microsft の研究では 512 トークンで分割した場合に検索精度が最も高くなったという検証結果もある。
